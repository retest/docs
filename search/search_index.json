{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to retest docs This is the documentation for various retest products. Products recheck : An open source Java API that implements Difference Testing. recheck-web : An open source Java API to replace existing or create new Selenium Tests with (unbreakable) Difference Testing. recheck.cli : An open source solution to view the reports and maintain your Golden Masters generated by recheck .","title":"Home"},{"location":"#welcome-to-retest-docs","text":"This is the documentation for various retest products.","title":"Welcome to retest docs"},{"location":"#products","text":"recheck : An open source Java API that implements Difference Testing. recheck-web : An open source Java API to replace existing or create new Selenium Tests with (unbreakable) Difference Testing. recheck.cli : An open source solution to view the reports and maintain your Golden Masters generated by recheck .","title":"Products"},{"location":"contributing/code-of-conduct/","text":"Contributor Covenant Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at info [AT] retest [DOT] de . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of Conduct"},{"location":"contributing/code-of-conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"contributing/code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"contributing/code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"contributing/code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"contributing/code-of-conduct/#scope","text":"This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"contributing/code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at info [AT] retest [DOT] de . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"contributing/code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"contributing/guidelines/","text":"Contributing Guidelines Thank you for taking interest in contributing to our repositories. You are invited to change or improve any part of the documentation or other open source products with features, bug fixes or issues. Please check back regularly as we potentially make changes without notice. Contributor License Agreement We require all contributors who submit pull requests to have read and accepted the CLA . To do so, please refer to our clabot-config . If you create a pull request and you have not yet agreed to the CLA, you will be asked to do so. Submission Guidelines Before submitting an issue or pull request, please make sure that no similar issues or pull request have been exist are either open or have been closed. For that, simply perform a search with some keywords related to your problem and quickly go through the issues and pull requests. If prompted, please try to stick to the issue or pull request template provided. This is to ensure descriptive issues, avoid duplicates and simplify the process on our side. However, please feel not forced to answer or provide every bit of detail. You are very welcome to ask a maintainer for help by submitting a work in progress issues or pull request. For the latter, please consider creating a draft pull request instead. Creating an Issue We want to resolve all bugs as quickly as possible. To do that, however, we need to reproduce and confirm it. In order to reproduce bugs, we ask you to create a minimal reproduction scenario. Please stick to the given template. Similarly, we want to understand your ideas and requested features. Therefore, please provide a clear and concise problem that you are trying to solve, ideally providing a solution. This solution does not have to be perfect and written in code; we are able to help and guide towards an optimal solution. Unfortunately, we are unable to investigate/fix errors without a minimum reproduction scenario, so if we do hear back from you we might close the issue. Creating a Pull Request You are invited to create a pull request. Please note that not all features will make it into the master. If you are unsure or want some help, please consider opening an issue before, so that your idea can be discussed before. Development : Please fork the project and make the changes in a separate branch. We prefer the feature/${branch-name} model. Please try to add descriptive commit messages. Build : Make sure that you can build your branch. We have integrated Travis to perform the build step; refer to the Travis documentation on how to get started. Pull Request : Create a pull request for retest/${repository}:master . Several checks will run and your pull request will be built automatically; if there are any errors, please try to fix them or allow edits by maintainers. If we suggest changes, discuss or perform them, and lastly, rebase and push your branch. Note that your pull request will be rebased automatically onto the master. If you see unexpected changes, you will either have to pull (with rebase) the changes or force push your changes. After your pull request is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.","title":"Guidelines"},{"location":"contributing/guidelines/#contributing-guidelines","text":"Thank you for taking interest in contributing to our repositories. You are invited to change or improve any part of the documentation or other open source products with features, bug fixes or issues. Please check back regularly as we potentially make changes without notice.","title":"Contributing Guidelines"},{"location":"contributing/guidelines/#contributor-license-agreement","text":"We require all contributors who submit pull requests to have read and accepted the CLA . To do so, please refer to our clabot-config . If you create a pull request and you have not yet agreed to the CLA, you will be asked to do so.","title":"Contributor License Agreement"},{"location":"contributing/guidelines/#submission-guidelines","text":"Before submitting an issue or pull request, please make sure that no similar issues or pull request have been exist are either open or have been closed. For that, simply perform a search with some keywords related to your problem and quickly go through the issues and pull requests. If prompted, please try to stick to the issue or pull request template provided. This is to ensure descriptive issues, avoid duplicates and simplify the process on our side. However, please feel not forced to answer or provide every bit of detail. You are very welcome to ask a maintainer for help by submitting a work in progress issues or pull request. For the latter, please consider creating a draft pull request instead.","title":"Submission Guidelines"},{"location":"contributing/guidelines/#creating-an-issue","text":"We want to resolve all bugs as quickly as possible. To do that, however, we need to reproduce and confirm it. In order to reproduce bugs, we ask you to create a minimal reproduction scenario. Please stick to the given template. Similarly, we want to understand your ideas and requested features. Therefore, please provide a clear and concise problem that you are trying to solve, ideally providing a solution. This solution does not have to be perfect and written in code; we are able to help and guide towards an optimal solution. Unfortunately, we are unable to investigate/fix errors without a minimum reproduction scenario, so if we do hear back from you we might close the issue.","title":"Creating an Issue"},{"location":"contributing/guidelines/#creating-a-pull-request","text":"You are invited to create a pull request. Please note that not all features will make it into the master. If you are unsure or want some help, please consider opening an issue before, so that your idea can be discussed before. Development : Please fork the project and make the changes in a separate branch. We prefer the feature/${branch-name} model. Please try to add descriptive commit messages. Build : Make sure that you can build your branch. We have integrated Travis to perform the build step; refer to the Travis documentation on how to get started. Pull Request : Create a pull request for retest/${repository}:master . Several checks will run and your pull request will be built automatically; if there are any errors, please try to fix them or allow edits by maintainers. If we suggest changes, discuss or perform them, and lastly, rebase and push your branch. Note that your pull request will be rebased automatically onto the master. If you see unexpected changes, you will either have to pull (with rebase) the changes or force push your changes. After your pull request is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.","title":"Creating a Pull Request"},{"location":"contributing/ide-settings/","text":"IDE Settings Please import the following settings (Eclipse format) in your IDE: Formatter Clean up Import order Unfortunately, it is currently not possible to export save actions. Therefore, please set them up as follows: If you are using IntelliJ, check out the Eclipse code formatter plugin .","title":"IDE Settings"},{"location":"contributing/ide-settings/#ide-settings","text":"Please import the following settings (Eclipse format) in your IDE: Formatter Clean up Import order Unfortunately, it is currently not possible to export save actions. Therefore, please set them up as follows: If you are using IntelliJ, check out the Eclipse code formatter plugin .","title":"IDE Settings"},{"location":"recheck/files/report/","text":"Test Report A report is the result of the comparison of two states with one or multiple steps and contains all differences between these two states. It is a static artifact and can be viewed without the corresponding Golden Master. However, in order to approve changes, a Golden Master must be present. A report can be viewed with either user interface review or recheck.cli . Warning The report is bound to the recheck version used during comparison. We currently offer no compatibility support between versions. If you need a report in a newer version, simply execute the test again with the new recheck version. Location Per default, reports are located under target/test-classes/retest/recheck/ , which can be changed with some configuration . Tip If you execute your tests on a remote system such as a CI server, you can enable the recheck 's report upload . This will upload your report to rehub , so that it can be accessed and downloaded to view it. Structure A report is structured to represent the lifecycle of Recheck . Report +-- Suite (1..n) +-- Test (1..n) +-- Check (1..n) +-- Difference (0..n) This structure is also displayed in the generated output after a test execution to make it easy to identify the failing check and therefore the steps taken which lead to the reported differences. Furthermore, all attribute differences are tied to an element , which is displayed with some important attributes: type (retestId) at 'xpath' ... (some attribute differences) The type of the element checked. For recheck-web , this is equal to the HTML tag attribute. The generated retestId for that element to be used as a stable, virtual identifier . The xpath of the element. This is the recheck -compatible path of the element. For recheck-web , this is equal to the fully specified XPath and can be used within a browser to lookup the element in question. Differences There are several types of differences that can be encountered. Note that the example output is based of the recheck.cli . Attribute Differences An attribute difference indicates that an element's attribute has changed. This is the most common difference and may include every attribute that is extracted through a extension. For example, this could include text changes or changes from/to the default value of the respective attribute. p (recheck) at 'html[1]/body[1]/header[1]/nav[1]/div[1]': text: expected=\"recheck\", actual=\"Recheck\" font-weight: expected=\"(default or absent)\", actual=\"700\" Element Differences An inserted difference indicates that a new element has been added. p (recheck) at 'html[1]/body[1]/header[1]/nav[1]/div[1]': was inserted A deleted difference indicates that an element has been removed. p (recheck) at 'html[1]/body[1]/header[1]/nav[1]/div[1]': was deleted Metadata Difference A metadata difference indicates changes in the metadata of a state. This is most likely due to the state being created on a different system or at a different time. These differences have no effect on the report and will be applied automatically. For a list of metadata, please refer to the state page. os.name: expected=\"Windows 10\", actual=\"Ubuntu\" Filtering We capture every difference that occurs. This is to retain the changes history. However, too many changes can be overwhelming, so you can apply filters to ignore them. A filter is used for all captured differences, both element and metadata differences. Tip Easily import some provided filters for your recheck.ignore , for example: import: metadata.filter to ignore some volatile metadata. Note Filtering does not get rid of the differences, we still capture them. However, filtered difference do not cause tests to fail and will be ignored by the user interfaces. Maintaining Differences Warning A Golden Master must be present to approve changes from a report. If the Golden Master cannot be found (as indicated by the user interface), please make sure that the report is within the same project root as the Golden Master. Differences can be maintained in two ways. Please refer to the respective documentation for the user interface on how to do so. Accept : The difference is expected or can be explained by changes done to the object under test. This will update the Golden Master with the new value(s). Ignore : If the element or attribute is dynamic or you do not care about these differences, they can be ignored and will be saved in the projects recheck.ignore .","title":"Test Report"},{"location":"recheck/files/report/#test-report","text":"A report is the result of the comparison of two states with one or multiple steps and contains all differences between these two states. It is a static artifact and can be viewed without the corresponding Golden Master. However, in order to approve changes, a Golden Master must be present. A report can be viewed with either user interface review or recheck.cli . Warning The report is bound to the recheck version used during comparison. We currently offer no compatibility support between versions. If you need a report in a newer version, simply execute the test again with the new recheck version.","title":"Test Report"},{"location":"recheck/files/report/#location","text":"Per default, reports are located under target/test-classes/retest/recheck/ , which can be changed with some configuration . Tip If you execute your tests on a remote system such as a CI server, you can enable the recheck 's report upload . This will upload your report to rehub , so that it can be accessed and downloaded to view it.","title":"Location"},{"location":"recheck/files/report/#structure","text":"A report is structured to represent the lifecycle of Recheck . Report +-- Suite (1..n) +-- Test (1..n) +-- Check (1..n) +-- Difference (0..n) This structure is also displayed in the generated output after a test execution to make it easy to identify the failing check and therefore the steps taken which lead to the reported differences. Furthermore, all attribute differences are tied to an element , which is displayed with some important attributes: type (retestId) at 'xpath' ... (some attribute differences) The type of the element checked. For recheck-web , this is equal to the HTML tag attribute. The generated retestId for that element to be used as a stable, virtual identifier . The xpath of the element. This is the recheck -compatible path of the element. For recheck-web , this is equal to the fully specified XPath and can be used within a browser to lookup the element in question.","title":"Structure"},{"location":"recheck/files/report/#differences","text":"There are several types of differences that can be encountered. Note that the example output is based of the recheck.cli .","title":"Differences"},{"location":"recheck/files/report/#attribute-differences","text":"An attribute difference indicates that an element's attribute has changed. This is the most common difference and may include every attribute that is extracted through a extension. For example, this could include text changes or changes from/to the default value of the respective attribute. p (recheck) at 'html[1]/body[1]/header[1]/nav[1]/div[1]': text: expected=\"recheck\", actual=\"Recheck\" font-weight: expected=\"(default or absent)\", actual=\"700\"","title":"Attribute Differences"},{"location":"recheck/files/report/#element-differences","text":"An inserted difference indicates that a new element has been added. p (recheck) at 'html[1]/body[1]/header[1]/nav[1]/div[1]': was inserted A deleted difference indicates that an element has been removed. p (recheck) at 'html[1]/body[1]/header[1]/nav[1]/div[1]': was deleted","title":"Element Differences"},{"location":"recheck/files/report/#metadata-difference","text":"A metadata difference indicates changes in the metadata of a state. This is most likely due to the state being created on a different system or at a different time. These differences have no effect on the report and will be applied automatically. For a list of metadata, please refer to the state page. os.name: expected=\"Windows 10\", actual=\"Ubuntu\"","title":"Metadata Difference"},{"location":"recheck/files/report/#filtering","text":"We capture every difference that occurs. This is to retain the changes history. However, too many changes can be overwhelming, so you can apply filters to ignore them. A filter is used for all captured differences, both element and metadata differences. Tip Easily import some provided filters for your recheck.ignore , for example: import: metadata.filter to ignore some volatile metadata. Note Filtering does not get rid of the differences, we still capture them. However, filtered difference do not cause tests to fail and will be ignored by the user interfaces.","title":"Filtering"},{"location":"recheck/files/report/#maintaining-differences","text":"Warning A Golden Master must be present to approve changes from a report. If the Golden Master cannot be found (as indicated by the user interface), please make sure that the report is within the same project root as the Golden Master. Differences can be maintained in two ways. Please refer to the respective documentation for the user interface on how to do so. Accept : The difference is expected or can be explained by changes done to the object under test. This will update the Golden Master with the new value(s). Ignore : If the element or attribute is dynamic or you do not care about these differences, they can be ignored and will be saved in the projects recheck.ignore .","title":"Maintaining Differences"},{"location":"recheck/files/state/","text":"Golden Master The RecheckAdapter which is provided by an extension is responsible for the conversion of the object to recheck 's data model. The conversion process extracts all noteworthy attributes and its children, which are saved as elements into a state . A state may contain multiple elements, if the adapter decides to split up the object (e.g. if it is made of several parts). An example for recheck-web would be that a WebDriver may hold multiple open tabs and each tab would be converted into an element. When checking via Recheck#check , a state is generated and (if present) compared with another state. If this state is not present, the checked state is assumed the Golden Master. The difference found between these states are saved into a report . State vs Golden Master The Golden Master is a special form of the state. While, technically, there is no difference, we distinguish between a state and a Golden Master to refer to the state of the object that has been approved by the tester (i.e. the state that is tested against). When doing a comparison the expected state refers to the Golden Master (which is saved on disk) and the actual state refers to the current version of the object under test (which is saved in RAM). Location Per default, Golden Masters are located in src/test/resources/retest/recheck/ and can be changed with some configuration . Currently they are saved as a ${state-name}.recheck folder with a XML file and metadata such as screenshots. Data Additionally to all captured elements and their attributes, recheck captures some more data (i.e. screenshots , metadata ) to make it easier for the user to identify and verify changes to the Golden Master. Elements & Attributes An element is one of the key objects within a report. It is contains multiple attributes which represent its state and can be used for identification. Each attribute saved will contribute to the difference checking and it is up to the report processor to filter unwanted attributes. Tip The more attributes an element contains, the easier it is to solve the element identification problem . Optimizations An extension can consider to do the following optimizations to save on disk space: Prevent default values: Do not save attributes which are considered default as specified by the DefaultValueFinder . It is up to the extension to decide which attributes are considered default based on the object or element being tested. Usually, there is a list of global defaults and then each object (e.g. Browser) or element (e.g. Button) defines their own default attributes on top of that. Use value inheritance (if supported by the underlaying technology): Consider not to save attributes which are inherited from the parent. For example, the font of a text is specified in the <body> element and therefore is not added to each text element (as long as it is equal to the parent). The extension must carefully choose the balance of default values and inheritance, as those systems cancel each other out. Taking the above example, a <body> element specifies a non-default font. However, a child element then reverts the font back to the default (thus overwriting the attribute of the parent). As a consequence, the extension then considers this value default and removes it, leaving inheritance to falsely inherit the <body> font. Secondly, default values cannot be reverse engineered as there might be multiple default values for a specific attribute. Thus filtering may be limited, if the filter needs to know the saved value (e.g. to calculate deltas). Virtual Identifier Elements can be identified with any attribute. However, since most attributes cannot be used as a unique identifier or because these attributes change regularly (e.g. random generated id ), it proves to be difficult to identify an element without it breaking. To solve this, recheck generates a constant, virtual identifier, called retestId . This is a special attribute and is therefore not affected by the standard attribute algorithms (optimization, differences, maintenance), and can be considered hidden . As such, while a generator, initially, can take the elements' attributes into account, subsequent changes to these attributes will not change the persisted identifier within a Golden Master. Simply speaking, the identifier is only generated once and never modified to ensure that it stays the same for the same element. Note The virtual identifier generation can be configured via the RecheckOptions . Generation A virtual identifier is generated for each element within a state and must be unique within that state. This rule does not apply for different states or Golden Masters. Generators are indeterministic and thus are allowed to return a different identifier for the same element. Specifically, this does neither guarantee that elements with the same identifier are equal, nor that the same element should expect the same identifier. This is especially the case if the virtual identifier is not tied to any attributes of the element (i.e. may be randomly generated). Type An element must have a type to identify the possible attributes it has. This usually corresponds to the same type of object (e.g. <button> ) or respective sub-element (e.g. text ). XPath The XPath describes the tree path within a Golden Master. However, depending on the extension and the object used to create the Golden Master, the XPath can also refer to the originally tested object (e.g. an element within a website). Warning The XPath generated for the elements only partially supports the XPath specification at the moment. Screenshots The Golden Master may contain screenshots of the object under test. However, these are not required for comparison and are only created for debugging purposes. Tip Screenshots may slow down your test execution. An extension, which is responsible for capturing the screenshots, may allow to adapt (e.g. resolution) or disable screenshots to improve performance. For more details, please refer to the respective configuration page of the extension. Metadata We capture some metadata that is related to the Golden Master, which is supposed to make it easier for you to identify how and where the Golden Master was created. Please note that the discovered metadata differences are not part of the final difference count. This metadata will not capture any sensitive data and is not analyzed but for strict difference reporting. Key Value (Example) machine.name WORK_PC os.arch amd64 os.name Windows 10 os.version 10.0 time.date 2019-12-03 time.time 16:07:37.551 time.offset +01:00 time.zone Europe/Berlin vcs.branch master vcs.commit 617bc4f26995bedce222b6ca8181291f68fc91e0 vcs.name git Further metadata will follow over time. Additionally, recheck-web captures the following metadata. Note, that it will overwrite the above metadata if the same keys are specified. Key Value (Example) check.type driver browser.name chrome browser.version 78.0.3904.108 driver.type UnbreakableDriver window.width 1200 window.height 800 os.name XP os.version 10.0","title":"Golden Master"},{"location":"recheck/files/state/#golden-master","text":"The RecheckAdapter which is provided by an extension is responsible for the conversion of the object to recheck 's data model. The conversion process extracts all noteworthy attributes and its children, which are saved as elements into a state . A state may contain multiple elements, if the adapter decides to split up the object (e.g. if it is made of several parts). An example for recheck-web would be that a WebDriver may hold multiple open tabs and each tab would be converted into an element. When checking via Recheck#check , a state is generated and (if present) compared with another state. If this state is not present, the checked state is assumed the Golden Master. The difference found between these states are saved into a report .","title":"Golden Master"},{"location":"recheck/files/state/#state-vs-golden-master","text":"The Golden Master is a special form of the state. While, technically, there is no difference, we distinguish between a state and a Golden Master to refer to the state of the object that has been approved by the tester (i.e. the state that is tested against). When doing a comparison the expected state refers to the Golden Master (which is saved on disk) and the actual state refers to the current version of the object under test (which is saved in RAM).","title":"State vs Golden Master"},{"location":"recheck/files/state/#location","text":"Per default, Golden Masters are located in src/test/resources/retest/recheck/ and can be changed with some configuration . Currently they are saved as a ${state-name}.recheck folder with a XML file and metadata such as screenshots.","title":"Location"},{"location":"recheck/files/state/#data","text":"Additionally to all captured elements and their attributes, recheck captures some more data (i.e. screenshots , metadata ) to make it easier for the user to identify and verify changes to the Golden Master.","title":"Data"},{"location":"recheck/files/state/#elements-attributes","text":"An element is one of the key objects within a report. It is contains multiple attributes which represent its state and can be used for identification. Each attribute saved will contribute to the difference checking and it is up to the report processor to filter unwanted attributes. Tip The more attributes an element contains, the easier it is to solve the element identification problem .","title":"Elements &amp; Attributes"},{"location":"recheck/files/state/#optimizations","text":"An extension can consider to do the following optimizations to save on disk space: Prevent default values: Do not save attributes which are considered default as specified by the DefaultValueFinder . It is up to the extension to decide which attributes are considered default based on the object or element being tested. Usually, there is a list of global defaults and then each object (e.g. Browser) or element (e.g. Button) defines their own default attributes on top of that. Use value inheritance (if supported by the underlaying technology): Consider not to save attributes which are inherited from the parent. For example, the font of a text is specified in the <body> element and therefore is not added to each text element (as long as it is equal to the parent). The extension must carefully choose the balance of default values and inheritance, as those systems cancel each other out. Taking the above example, a <body> element specifies a non-default font. However, a child element then reverts the font back to the default (thus overwriting the attribute of the parent). As a consequence, the extension then considers this value default and removes it, leaving inheritance to falsely inherit the <body> font. Secondly, default values cannot be reverse engineered as there might be multiple default values for a specific attribute. Thus filtering may be limited, if the filter needs to know the saved value (e.g. to calculate deltas).","title":"Optimizations"},{"location":"recheck/files/state/#virtual-identifier","text":"Elements can be identified with any attribute. However, since most attributes cannot be used as a unique identifier or because these attributes change regularly (e.g. random generated id ), it proves to be difficult to identify an element without it breaking. To solve this, recheck generates a constant, virtual identifier, called retestId . This is a special attribute and is therefore not affected by the standard attribute algorithms (optimization, differences, maintenance), and can be considered hidden . As such, while a generator, initially, can take the elements' attributes into account, subsequent changes to these attributes will not change the persisted identifier within a Golden Master. Simply speaking, the identifier is only generated once and never modified to ensure that it stays the same for the same element. Note The virtual identifier generation can be configured via the RecheckOptions .","title":"Virtual Identifier"},{"location":"recheck/files/state/#type","text":"An element must have a type to identify the possible attributes it has. This usually corresponds to the same type of object (e.g. <button> ) or respective sub-element (e.g. text ).","title":"Type"},{"location":"recheck/files/state/#xpath","text":"The XPath describes the tree path within a Golden Master. However, depending on the extension and the object used to create the Golden Master, the XPath can also refer to the originally tested object (e.g. an element within a website). Warning The XPath generated for the elements only partially supports the XPath specification at the moment.","title":"XPath"},{"location":"recheck/files/state/#screenshots","text":"The Golden Master may contain screenshots of the object under test. However, these are not required for comparison and are only created for debugging purposes. Tip Screenshots may slow down your test execution. An extension, which is responsible for capturing the screenshots, may allow to adapt (e.g. resolution) or disable screenshots to improve performance. For more details, please refer to the respective configuration page of the extension.","title":"Screenshots"},{"location":"recheck/files/state/#metadata","text":"We capture some metadata that is related to the Golden Master, which is supposed to make it easier for you to identify how and where the Golden Master was created. Please note that the discovered metadata differences are not part of the final difference count. This metadata will not capture any sensitive data and is not analyzed but for strict difference reporting. Key Value (Example) machine.name WORK_PC os.arch amd64 os.name Windows 10 os.version 10.0 time.date 2019-12-03 time.time 16:07:37.551 time.offset +01:00 time.zone Europe/Berlin vcs.branch master vcs.commit 617bc4f26995bedce222b6ca8181291f68fc91e0 vcs.name git Further metadata will follow over time. Additionally, recheck-web captures the following metadata. Note, that it will overwrite the above metadata if the same keys are specified. Key Value (Example) check.type driver browser.name chrome browser.version 78.0.3904.108 driver.type UnbreakableDriver window.width 1200 window.height 800 os.name XP os.version 10.0","title":"Metadata"},{"location":"recheck/introduction/","text":"Introduction recheck is an API which implements Difference Testing to check objects across multiple versions and collect differences. It therefore defines a domain model specific to recheck so that it can do Difference Testing. That means, however, that there needs to be a conversion from the passed object to the domain model. While recheck itself cannot convert those objects, there is the possibility to use available extensions or expand recheck via own extensions as described under installation . Difference Testing The idea of Difference Testing is derived from the idea of Golden Master Testing (a.k.a. Characterization Testing ). Based on these practices, it describes the complete state of the object under test, where the complete state is determined by the extension of a particular technology used. By observing said state, it essentially differs from the classical approach to software testing by removing the need for assertions and eliminating the use of specifications. That's because observing does not mean verification ; Difference Testing accepts every output it encounters, saves it and compares upon re-execution. Difference Testing is basically described with four steps: Define a Golden Master based upon an evaluated version of the object under test. Convert and save the object as a Golden Master by initially executing the test. Compare to a newer version of the SUT by re-executing the test. If difference occur: Let a human decide if these differences should be accepted (update the Golden Master), ignored (update an ignore file similar to .gitignore ), or rejected (hooray, you've found a bug!). Advantages There is no need to define individual assertions as the state is captured completely. Changed elements can still be found by identifying them with other attributes. Always changing elements can be ignored. The automation and collection of differences allows for a One-Click-Maintenance . Disadvantages Since an algorithm cannot decide the correctness of a change, human verification is necessary. Bugs can pass through multiple versions as long as no changes occur.","title":"Introduction"},{"location":"recheck/introduction/#introduction","text":"recheck is an API which implements Difference Testing to check objects across multiple versions and collect differences. It therefore defines a domain model specific to recheck so that it can do Difference Testing. That means, however, that there needs to be a conversion from the passed object to the domain model. While recheck itself cannot convert those objects, there is the possibility to use available extensions or expand recheck via own extensions as described under installation .","title":"Introduction"},{"location":"recheck/introduction/#difference-testing","text":"The idea of Difference Testing is derived from the idea of Golden Master Testing (a.k.a. Characterization Testing ). Based on these practices, it describes the complete state of the object under test, where the complete state is determined by the extension of a particular technology used. By observing said state, it essentially differs from the classical approach to software testing by removing the need for assertions and eliminating the use of specifications. That's because observing does not mean verification ; Difference Testing accepts every output it encounters, saves it and compares upon re-execution. Difference Testing is basically described with four steps: Define a Golden Master based upon an evaluated version of the object under test. Convert and save the object as a Golden Master by initially executing the test. Compare to a newer version of the SUT by re-executing the test. If difference occur: Let a human decide if these differences should be accepted (update the Golden Master), ignored (update an ignore file similar to .gitignore ), or rejected (hooray, you've found a bug!).","title":"Difference Testing"},{"location":"recheck/introduction/#advantages","text":"There is no need to define individual assertions as the state is captured completely. Changed elements can still be found by identifying them with other attributes. Always changing elements can be ignored. The automation and collection of differences allows for a One-Click-Maintenance .","title":"Advantages"},{"location":"recheck/introduction/#disadvantages","text":"Since an algorithm cannot decide the correctness of a change, human verification is necessary. Bugs can pass through multiple versions as long as no changes occur.","title":"Disadvantages"},{"location":"recheck/introduction/installation/","text":"Installation Info You should only need to define the dependency if you plan to extend recheck yourself. You may use an already implemented extension. Extensions recheck is usually used with extensions that provide the capability for converting the objects of a specific technology into the domain model of recheck . Available extensions: recheck-web : Testing websites and web applications based on Selenium . More to come Alpha extensions (proof of concept): recheck-logs : Verify text-based logs. recheck-xml : Verify xml files. Tip If you are developing an extension for recheck , we would be happy if you contact us or add your extension with a short description here. Tip Extensions, but also frontends such as the recheck.cli or review, are supposed to be compatible across minor versions . That is, you can view reports from, e.g., recheck-web 1.5.1 with recheck.cli 1.5.0 as they both share the minor version 5, which means they use recheck 1.5.x under the hood. Build tools You can add recheck as an external dependency to your project. It is available in Maven central or via the release-page , which allows you to include it into your favorite build tool. For the current version, please refer to the release-page. Maven <dependency> <groupId> de.retest </groupId> <artifactId> recheck </artifactId> <version> ${LATEST_VERSION_FROM_ABOVE_LINK} </version> </dependency> Gradle compile 'de.retest:recheck:${LATEST_VERSION_FROM_ABOVE_LINK}'","title":"Installation"},{"location":"recheck/introduction/installation/#installation","text":"Info You should only need to define the dependency if you plan to extend recheck yourself. You may use an already implemented extension.","title":"Installation"},{"location":"recheck/introduction/installation/#extensions","text":"recheck is usually used with extensions that provide the capability for converting the objects of a specific technology into the domain model of recheck . Available extensions: recheck-web : Testing websites and web applications based on Selenium . More to come Alpha extensions (proof of concept): recheck-logs : Verify text-based logs. recheck-xml : Verify xml files. Tip If you are developing an extension for recheck , we would be happy if you contact us or add your extension with a short description here. Tip Extensions, but also frontends such as the recheck.cli or review, are supposed to be compatible across minor versions . That is, you can view reports from, e.g., recheck-web 1.5.1 with recheck.cli 1.5.0 as they both share the minor version 5, which means they use recheck 1.5.x under the hood.","title":"Extensions"},{"location":"recheck/introduction/installation/#build-tools","text":"You can add recheck as an external dependency to your project. It is available in Maven central or via the release-page , which allows you to include it into your favorite build tool. For the current version, please refer to the release-page.","title":"Build tools"},{"location":"recheck/introduction/installation/#maven","text":"<dependency> <groupId> de.retest </groupId> <artifactId> recheck </artifactId> <version> ${LATEST_VERSION_FROM_ABOVE_LINK} </version> </dependency>","title":"Maven"},{"location":"recheck/introduction/installation/#gradle","text":"compile 'de.retest:recheck:${LATEST_VERSION_FROM_ABOVE_LINK}'","title":"Gradle"},{"location":"recheck/introduction/usage/","text":"Usage The basic entrance point is Recheck with its implementation RecheckImpl . Methods The essential methods are called check . Upon first execution, the object is converted to a Golden Master and saved, identified by the name passed. Subsequent executions convert the object to the domain model to compare it against the existing Golden Master. Failure If there is no extension present that can handle the passed object, an exception is thrown. As described in installation , you need to have an extension available that is able to do the conversion. Lifecycle To locate the Golden Master (if present), Recheck uses a lifecycle so that differences can be identified. The lifecycle of Recheck can be described with three phases, where the earlier stages surround one or more of the directly following stage: Report: This is independent of the actual Recheck instance. It will simply collect all generated reports into one tests.report , while preserving the individual report per suite. This phase is usually bound to the JVM. Suite: Defined by the Recheck instance (e.g. a test class within JUnit). It is started by creating a new instance and ended by Recheck#cap() , which will save the individual report containing all the differences encountered. Test: Defined by a test execution (e.g. a test method in JUnit). It is started by Recheck#startTest() and ended by Recheck#capTest() , which will produce an AssertionError if there are differences or if the Golden Master could not be found (e.g. initial execution). Within the test phase you can execute multiple checks. The created Golden Masters are then associated with the running suite and test phase. Warning You should make sure to call the methods in their respective order. While Recheck will try its best to keep the lifecycle intact, it may still produce unexpected results or even errors. Tip You can use the corresponding extension for the test framework of your choice to administer the lifecycle so that the lifecycle methods will be called at the appropriate times. recheck-junit-jupiter-extension recheck-junit-4-extension recheck-testng-extension Modifying the Lifecycle A phase of the lifecycle is identified by a name that is either identified using the NamingStrategy or you can overwrite it by passing a String into the respective starting methods. If nothing is specified, Recheck will try to automatically identify a name based on a valid test annotation for a class. If this fails or produces an incorrect name, a custom name must be specified. Reuse Golden Master Files This naming mechanism basically allows you to share Golden Masters. This can be used to test different setups for your object. A common use case would check if an operation was undone successfully (see example below). re . startTest ( \"custom-name\" ); // By defining the name, a golden master with the corresponding name will be created re . check ( object , \"initial\" ); // Perform an operation that changes the object object . do (); // Verify the changed operation re . check ( object , \"modified\" ); // Undo the operation object . undo (); // Instead of creating a new golden master, the exisiting is used and compared against re . check ( object , \"initial\" ); re . capTest (); An advanced use case would check different platforms, operating systems, languages, etc., and verify that those are the same. Ideally this would not happen within a single test phase (depending on your test framework), but encompass multiple test phases or even suite phases. Tip You may use the filtering mechanism to ignore expected differences. As an example for a language change you would ignore the text, because it changes as you would expect. Thus, you manipulate the definition of same by ignoring expected differences, while still allowing for other differences to be captured. Integration in Test Frameworks and Plain Java JUnit 4 (Vintage) The following examples use JUnit 4 as test framework. Using plain JUnit 4 public class JUnit4ExampleRecheckTest { private Recheck re ; @Before public void setUp () { // Create your instance re = new RecheckImpl (); } @After public void tearDown () { // Save the report re . cap (); } @Test public void check_simple_string () { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } } Using recheck's JUnit 4 rule Recheck's JUnit 4 extension can be found at recheck-junit-4-extension . It automatically ensures the lifecycle of recheck tests in JUnit 4 . public class JUnit4ExampleRecheckUsingExtensionTest { // Will start and cap the test @Rule public final RecheckRule recheckRule = new RecheckRule (); private Recheck re ; @Before public void setUp () { // Create your instance re = new RecheckImpl (); // Ensure the rule knows your Recheck instance recheckRule . use ( re ); } @Test public void check_simple_string () { // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); } } JUnit 5 (Jupiter) The following examples use JUnit 5 as test framework. Using plain JUnit 5 class JUnit5ExampleRecheckTest { Recheck re ; @BeforeEach void setUp () { // Create your instance re = new RecheckImpl (); } @AfterEach void tearDown () { // Save the report re . cap (); } @Test void check_simple_string () { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } } Using recheck's JUnit 5 extension Recheck's JUnit Jupiter extension can be found at recheck-junit-jupiter-extension . It automatically ensures the lifecycle of recheck tests in JUnit 5 . // Will start and cap the test @ExtendWith ( RecheckExtension . class ) class JUnit5ExampleRecheckUsingExtensionTest { Recheck re ; @BeforeEach void setUp () { // Create your instance re = new RecheckImpl (); } @Test void check_simple_string () { // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); } } TestNG The following examples use JUnit 5 as test framework. Using plain TestNG class TestNGExampleRecheckTest { Recheck re ; @BeforeMethod ( alwaysRun = true ) void setUp () { // Create your instance re = new RecheckImpl (); } @AfterMethod ( alwaysRun = true ) void tearDown () { // Save the report re . cap (); } @Test void check_simple_string () { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } } Using recheck's TestNG hook // Will start and cap the test @Listener ( RecheckHook . class ) class TestNGExampleRecheckUsingExtensionTest { Recheck re ; @Test void check_simple_string () { // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); } } Plain Java class PlainJavaExampleRecheckTest { public static void main ( String [] args ) { // Create your instance var re = new RecheckImpl (); try { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } finally { // Save the report re . cap (); } } }","title":"Usage"},{"location":"recheck/introduction/usage/#usage","text":"The basic entrance point is Recheck with its implementation RecheckImpl .","title":"Usage"},{"location":"recheck/introduction/usage/#methods","text":"The essential methods are called check . Upon first execution, the object is converted to a Golden Master and saved, identified by the name passed. Subsequent executions convert the object to the domain model to compare it against the existing Golden Master. Failure If there is no extension present that can handle the passed object, an exception is thrown. As described in installation , you need to have an extension available that is able to do the conversion.","title":"Methods"},{"location":"recheck/introduction/usage/#lifecycle","text":"To locate the Golden Master (if present), Recheck uses a lifecycle so that differences can be identified. The lifecycle of Recheck can be described with three phases, where the earlier stages surround one or more of the directly following stage: Report: This is independent of the actual Recheck instance. It will simply collect all generated reports into one tests.report , while preserving the individual report per suite. This phase is usually bound to the JVM. Suite: Defined by the Recheck instance (e.g. a test class within JUnit). It is started by creating a new instance and ended by Recheck#cap() , which will save the individual report containing all the differences encountered. Test: Defined by a test execution (e.g. a test method in JUnit). It is started by Recheck#startTest() and ended by Recheck#capTest() , which will produce an AssertionError if there are differences or if the Golden Master could not be found (e.g. initial execution). Within the test phase you can execute multiple checks. The created Golden Masters are then associated with the running suite and test phase. Warning You should make sure to call the methods in their respective order. While Recheck will try its best to keep the lifecycle intact, it may still produce unexpected results or even errors. Tip You can use the corresponding extension for the test framework of your choice to administer the lifecycle so that the lifecycle methods will be called at the appropriate times. recheck-junit-jupiter-extension recheck-junit-4-extension recheck-testng-extension","title":"Lifecycle"},{"location":"recheck/introduction/usage/#modifying-the-lifecycle","text":"A phase of the lifecycle is identified by a name that is either identified using the NamingStrategy or you can overwrite it by passing a String into the respective starting methods. If nothing is specified, Recheck will try to automatically identify a name based on a valid test annotation for a class. If this fails or produces an incorrect name, a custom name must be specified.","title":"Modifying the Lifecycle"},{"location":"recheck/introduction/usage/#reuse-golden-master-files","text":"This naming mechanism basically allows you to share Golden Masters. This can be used to test different setups for your object. A common use case would check if an operation was undone successfully (see example below). re . startTest ( \"custom-name\" ); // By defining the name, a golden master with the corresponding name will be created re . check ( object , \"initial\" ); // Perform an operation that changes the object object . do (); // Verify the changed operation re . check ( object , \"modified\" ); // Undo the operation object . undo (); // Instead of creating a new golden master, the exisiting is used and compared against re . check ( object , \"initial\" ); re . capTest (); An advanced use case would check different platforms, operating systems, languages, etc., and verify that those are the same. Ideally this would not happen within a single test phase (depending on your test framework), but encompass multiple test phases or even suite phases. Tip You may use the filtering mechanism to ignore expected differences. As an example for a language change you would ignore the text, because it changes as you would expect. Thus, you manipulate the definition of same by ignoring expected differences, while still allowing for other differences to be captured.","title":"Reuse Golden Master Files"},{"location":"recheck/introduction/usage/#integration-in-test-frameworks-and-plain-java","text":"","title":"Integration in Test Frameworks and Plain Java"},{"location":"recheck/introduction/usage/#junit-4-vintage","text":"The following examples use JUnit 4 as test framework.","title":"JUnit 4 (Vintage)"},{"location":"recheck/introduction/usage/#using-plain-junit-4","text":"public class JUnit4ExampleRecheckTest { private Recheck re ; @Before public void setUp () { // Create your instance re = new RecheckImpl (); } @After public void tearDown () { // Save the report re . cap (); } @Test public void check_simple_string () { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } }","title":"Using plain JUnit 4"},{"location":"recheck/introduction/usage/#using-rechecks-junit-4-rule","text":"Recheck's JUnit 4 extension can be found at recheck-junit-4-extension . It automatically ensures the lifecycle of recheck tests in JUnit 4 . public class JUnit4ExampleRecheckUsingExtensionTest { // Will start and cap the test @Rule public final RecheckRule recheckRule = new RecheckRule (); private Recheck re ; @Before public void setUp () { // Create your instance re = new RecheckImpl (); // Ensure the rule knows your Recheck instance recheckRule . use ( re ); } @Test public void check_simple_string () { // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); } }","title":"Using recheck's JUnit 4 rule"},{"location":"recheck/introduction/usage/#junit-5-jupiter","text":"The following examples use JUnit 5 as test framework.","title":"JUnit 5 (Jupiter)"},{"location":"recheck/introduction/usage/#using-plain-junit-5","text":"class JUnit5ExampleRecheckTest { Recheck re ; @BeforeEach void setUp () { // Create your instance re = new RecheckImpl (); } @AfterEach void tearDown () { // Save the report re . cap (); } @Test void check_simple_string () { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } }","title":"Using plain JUnit 5"},{"location":"recheck/introduction/usage/#using-rechecks-junit-5-extension","text":"Recheck's JUnit Jupiter extension can be found at recheck-junit-jupiter-extension . It automatically ensures the lifecycle of recheck tests in JUnit 5 . // Will start and cap the test @ExtendWith ( RecheckExtension . class ) class JUnit5ExampleRecheckUsingExtensionTest { Recheck re ; @BeforeEach void setUp () { // Create your instance re = new RecheckImpl (); } @Test void check_simple_string () { // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); } }","title":"Using recheck's JUnit 5 extension"},{"location":"recheck/introduction/usage/#testng","text":"The following examples use JUnit 5 as test framework.","title":"TestNG"},{"location":"recheck/introduction/usage/#using-plain-testng","text":"class TestNGExampleRecheckTest { Recheck re ; @BeforeMethod ( alwaysRun = true ) void setUp () { // Create your instance re = new RecheckImpl (); } @AfterMethod ( alwaysRun = true ) void tearDown () { // Save the report re . cap (); } @Test void check_simple_string () { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } }","title":"Using plain TestNG"},{"location":"recheck/introduction/usage/#using-rechecks-testng-hook","text":"// Will start and cap the test @Listener ( RecheckHook . class ) class TestNGExampleRecheckUsingExtensionTest { Recheck re ; @Test void check_simple_string () { // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); } }","title":"Using recheck's TestNG hook"},{"location":"recheck/introduction/usage/#plain-java","text":"class PlainJavaExampleRecheckTest { public static void main ( String [] args ) { // Create your instance var re = new RecheckImpl (); try { re . startTest (); // Create your object to check. An appropriate adapter must be present final var object = ...; // Create a golden master or check against, does not throw re . check ( object , \"check-name\" ); // Will fail if there are differences to the golden master re . capTest (); } finally { // Save the report re . cap (); } } }","title":"Plain Java"},{"location":"recheck/usage/configuration/","text":"Configuration We use convention over configuration to configure the behavior of recheck . Thus unless your setup does not fit to the default mechanism, you should not have to configure anything. Tools we use for code development, and thus are configured as the default: Git Maven JUnit5 Tools we do not (actively) use, but support: Gradle JUnit4 TestNG 1 Tip If you feel that the tools you are using are not supported or lack support, you are welcome to implement or improve the support for the respective tool and create a pull request or create an issue . RecheckOptions The RecheckOptions are used to configure the behavior of Recheck or similar classes that may use a Recheck instance internally. They use the builder pattern and cannot be changed, once they are created (i.e. they are immutable). RecheckOptions options = RecheckOptions . builder () // Do your configuration here . build () Warning If the default or automatic systems does not fit your needs or produce the wrong results, you must specify the respective options manually. Usage The options can be easily passed to the RecheckImpl . Recheckoptions opts = RecheckOptions . builder () // Do your configuration here . build (); Recheck re = new RecheckImpl ( opts ); Note All available Recheck instances should honor all available options from RecheckOptions . Options Below is a list of the available options you may configure with corresponding methods on RecheckOptionsBuilder . Please refer to the detailed sections below. All options annotated with \"Evaluate\" below will be queried with the creation of the RecheckOptions instance, either retrieving (by the methods described), instantiating or loading the proper value. Option Default Description Evaluate namingStrategy ClassAndMethodBasedNamingStrategy Defines the name for the phase of the lifecycle . projectLayout null ( ProjectLayout ) Defines where the Golden Masters and reports are located. If null recheck will try to automatically detect the respective layout (e.g. maven or gradle). true suiteName null Overwrite the name for the suite. If null , NamingStrategy#getSuiteName() is used. true reportUploadEnabled null ( boolean ) Upload reports to rehub . If null , the property de.retest.recheck.rehub.reportUploadEnabled is read. true ignore recheck.ignore Set the filter used for reporting the differences after a test phase. See examples below . true retestIdProvider DefaultRetestIdProvider Defines the generator of the virtual identifier . Example This is an example using all available options. Note that the classes used may not be present and therefore need to be created manually. RecheckOptions . builder () . namingStrategy ( new ClassAndMethodBasedShortNamingStrategy () ) . projectLayout ( new GradleProjectLayout () ) . suiteName ( \"my-custom-suite-name\" ) . enableReportUpload () . addIgnore ( \"MyCustomIgnore.filter\" ) . retestIdProvider ( new UUIDRetestIdProvider () ) . build (); Locating Files Per default, we assume a Maven project with JUnit. The files are located under the following folders: Golden Masters: src/test/resources/retest/recheck/ Reports: target/test-classes/retest/recheck/ You may change the location of files using a custom ProjectLayout or define the name using a custom NamingStrategy as described in the lifecycle . Warning The suiteName is evaluated to provide a consistent name for the RecheckOptions . The automatic system does not work with some usages (e.g. inheritance) and thus require a custom suiteName to be defined. Upload Reports to rehub When executing your tests on a CI, it may not be straightforward to access the created reports. For this we offer a way to upload your reports to rehub so that you can easily update your Golden Masters. If the upload of the report fails (e.g connectivity issues, timeout, ...), recheck will restart the upload, favoring reports with differences. If there are no differences: The upload is only attempted once, ignoring any errors so that they do not lead to test failures. If there are differences: The report upload is restarted if any errors occur during the upload. If the upload fails repeatedly, the causing error is logged and reported to the test framework, causing the test to fail. The maximum upload attempts can be controlled with the property de.retest.recheck.rehub.upload.attempts . Warning The upload or re-upload of the report is aborted after 5 minutes after the initial upload request. Using Filters Per default, we load the recheck.ignore files as specified in filters . Thus, the suiteName is a required dependency to be evaluated before, so that the filters are loaded from the correct Golden Master. If you want specify additional filters (e.g. your custom project filters), you may use their full name (e.g. \"MyCustomIgnore.filter\" ). There are several methods to add, update or disable filters: RecheckOptionsBuilder#addIgnore( String ) : Will append a filter. RecheckOptionsBuilder#setIgnore( String ) : Will overwrite the filter. RecheckOptions#ignoreNothing() : Will remove all filters. Properties recheck offers some properties that can be used for configuration. You can either set these via the .retest/retest.properties file or using actual system properties . (Note that the latter overwrites the former.) # If true, reports will be uploaded to rehub. # \"true\" or \"false\". de.retest.recheck.rehub.reportUploadEnabled = false # Retry attempts to upload reports to rehub if initial upload fails # Any positive integer de.retest.recheck.rehub.upload.attempts = 3 # Always ignore these attributes, even if no ignore or filter is active. # Any string, separate values with \";\". de.retest.recheck.ignore.attributes = absolute-outline # If set, recheck will use this path as the project root (containing e.g. the .retest folder). # Any valid absolute path. de.retest.recheck.project.root = null # Minimal match threshold between old and new element to safely assume it's actually the same. # Any double in the interval [0.0, 1.0]. de.retest.recheck.elementMatchThreshold = 0.3 Note that JUnit and TestNG is supported by default through ClassAndMethodBasedNamingStrategy . \u21a9","title":"Configuration"},{"location":"recheck/usage/configuration/#configuration","text":"We use convention over configuration to configure the behavior of recheck . Thus unless your setup does not fit to the default mechanism, you should not have to configure anything. Tools we use for code development, and thus are configured as the default: Git Maven JUnit5 Tools we do not (actively) use, but support: Gradle JUnit4 TestNG 1 Tip If you feel that the tools you are using are not supported or lack support, you are welcome to implement or improve the support for the respective tool and create a pull request or create an issue .","title":"Configuration"},{"location":"recheck/usage/configuration/#recheckoptions","text":"The RecheckOptions are used to configure the behavior of Recheck or similar classes that may use a Recheck instance internally. They use the builder pattern and cannot be changed, once they are created (i.e. they are immutable). RecheckOptions options = RecheckOptions . builder () // Do your configuration here . build () Warning If the default or automatic systems does not fit your needs or produce the wrong results, you must specify the respective options manually.","title":"RecheckOptions"},{"location":"recheck/usage/configuration/#usage","text":"The options can be easily passed to the RecheckImpl . Recheckoptions opts = RecheckOptions . builder () // Do your configuration here . build (); Recheck re = new RecheckImpl ( opts ); Note All available Recheck instances should honor all available options from RecheckOptions .","title":"Usage"},{"location":"recheck/usage/configuration/#options","text":"Below is a list of the available options you may configure with corresponding methods on RecheckOptionsBuilder . Please refer to the detailed sections below. All options annotated with \"Evaluate\" below will be queried with the creation of the RecheckOptions instance, either retrieving (by the methods described), instantiating or loading the proper value. Option Default Description Evaluate namingStrategy ClassAndMethodBasedNamingStrategy Defines the name for the phase of the lifecycle . projectLayout null ( ProjectLayout ) Defines where the Golden Masters and reports are located. If null recheck will try to automatically detect the respective layout (e.g. maven or gradle). true suiteName null Overwrite the name for the suite. If null , NamingStrategy#getSuiteName() is used. true reportUploadEnabled null ( boolean ) Upload reports to rehub . If null , the property de.retest.recheck.rehub.reportUploadEnabled is read. true ignore recheck.ignore Set the filter used for reporting the differences after a test phase. See examples below . true retestIdProvider DefaultRetestIdProvider Defines the generator of the virtual identifier .","title":"Options"},{"location":"recheck/usage/configuration/#example","text":"This is an example using all available options. Note that the classes used may not be present and therefore need to be created manually. RecheckOptions . builder () . namingStrategy ( new ClassAndMethodBasedShortNamingStrategy () ) . projectLayout ( new GradleProjectLayout () ) . suiteName ( \"my-custom-suite-name\" ) . enableReportUpload () . addIgnore ( \"MyCustomIgnore.filter\" ) . retestIdProvider ( new UUIDRetestIdProvider () ) . build ();","title":"Example"},{"location":"recheck/usage/configuration/#locating-files","text":"Per default, we assume a Maven project with JUnit. The files are located under the following folders: Golden Masters: src/test/resources/retest/recheck/ Reports: target/test-classes/retest/recheck/ You may change the location of files using a custom ProjectLayout or define the name using a custom NamingStrategy as described in the lifecycle . Warning The suiteName is evaluated to provide a consistent name for the RecheckOptions . The automatic system does not work with some usages (e.g. inheritance) and thus require a custom suiteName to be defined.","title":"Locating Files"},{"location":"recheck/usage/configuration/#upload-reports-to-rehub","text":"When executing your tests on a CI, it may not be straightforward to access the created reports. For this we offer a way to upload your reports to rehub so that you can easily update your Golden Masters. If the upload of the report fails (e.g connectivity issues, timeout, ...), recheck will restart the upload, favoring reports with differences. If there are no differences: The upload is only attempted once, ignoring any errors so that they do not lead to test failures. If there are differences: The report upload is restarted if any errors occur during the upload. If the upload fails repeatedly, the causing error is logged and reported to the test framework, causing the test to fail. The maximum upload attempts can be controlled with the property de.retest.recheck.rehub.upload.attempts . Warning The upload or re-upload of the report is aborted after 5 minutes after the initial upload request.","title":"Upload Reports to rehub"},{"location":"recheck/usage/configuration/#using-filters","text":"Per default, we load the recheck.ignore files as specified in filters . Thus, the suiteName is a required dependency to be evaluated before, so that the filters are loaded from the correct Golden Master. If you want specify additional filters (e.g. your custom project filters), you may use their full name (e.g. \"MyCustomIgnore.filter\" ). There are several methods to add, update or disable filters: RecheckOptionsBuilder#addIgnore( String ) : Will append a filter. RecheckOptionsBuilder#setIgnore( String ) : Will overwrite the filter. RecheckOptions#ignoreNothing() : Will remove all filters.","title":"Using Filters"},{"location":"recheck/usage/configuration/#properties","text":"recheck offers some properties that can be used for configuration. You can either set these via the .retest/retest.properties file or using actual system properties . (Note that the latter overwrites the former.) # If true, reports will be uploaded to rehub. # \"true\" or \"false\". de.retest.recheck.rehub.reportUploadEnabled = false # Retry attempts to upload reports to rehub if initial upload fails # Any positive integer de.retest.recheck.rehub.upload.attempts = 3 # Always ignore these attributes, even if no ignore or filter is active. # Any string, separate values with \";\". de.retest.recheck.ignore.attributes = absolute-outline # If set, recheck will use this path as the project root (containing e.g. the .retest folder). # Any valid absolute path. de.retest.recheck.project.root = null # Minimal match threshold between old and new element to safely assume it's actually the same. # Any double in the interval [0.0, 1.0]. de.retest.recheck.elementMatchThreshold = 0.3 Note that JUnit and TestNG is supported by default through ClassAndMethodBasedNamingStrategy . \u21a9","title":"Properties"},{"location":"recheck/usage/filter/","text":"Filter In principle, recheck creates a difference for every change that occurred and writes it into the report. Then it is up to the UI ( review or recheck.cli ) to hide ignored differences. This is pretty much in line with how Git works\u2014the diff is there, it just doesn't show up when ignored. The advantages of this approach are as follows: It is inspection / revision safe \u2013 every change is documented. Hidden changes (technical changes that are usually invisible to the user) are treated as any other change and are presented as such. You can change the rules of what to ignore and instantly see the impact. What Are Filters? Filters can be used for different purposes, most notably to reduce the noise mentioned above within a report . They can accept different arguments, which all are accessible using the below syntax : Element : Filter applies to all attributes of an element and all of its child elements. This may look at specific attributes, children or parent element to determine if the filter applies. The element in question can be identified by a wide range of identifying attributes, which are specified by the extensions . Attribute : Filter applies to a single attribute, either globally or for a specific element and all of its child elements. Difference : Filter applies to a difference where the attribute and the value can be retrieved. Multiple filters are additive. If one filter returns true , the result is taken and not further evaluated. Similarly, all filters must return false to ignore a particular difference. Note The filter as such does not define what happens with the output. It just matches a element or a difference. Please note the context in which you use a filter and what the output is used for. Location By default, filters are simple text files, so that they are reusable within different products and stages. The name of the file corresponds with the appropriate name used within recheck . There are several locations where the filter files can be placed, so that they may be referenced within the RecheckOptions . Plain Filters Project filters in ${PROJECT_ROOT}/.retest/filter . User directory in ${USER_HOME}/.retest/filter . Must be created manually . Provided filters from recheck . We ship some categorized filters. Note We are currently experimenting with sensible defaults and may change the provided filters without notice. If you feel that they filter too much or too less within their respective category, please let us know, so that we can change these. Tip You may overwrite filters by using the same name. They are searched top-down. That is, project filters overwrite user filters, which in turn overwrite the provided filters. This allows you to easily overwrite the provided filters so that you can add your customizations. Ignore Filters An ignore filter recheck.ignore is a special kind of filter which (by default) is loaded automatically. It defines that true ignores (i.e. hides) the specified difference, while false continues to use it. In contrast to plain filters, multiple ignore filters do not overwrite each other, despite having the same name. Rather, they are additive and each location contributes to the final ignore filter used by recheck. The following locations are searched: Globally: ${USER_HOME}/.retest/ . Must be created manually . For each Project: ${PROJECT_ROOT}/.retest/ . Will be created on first execution . For each Golden Master individually (i.e. suite). Must be created manually . After using recheck.cli or review to update the ignore filter, only the ignore file for the project will be updated to additionally contain the new ignored differences and all ignores from the global and suite ignore file. Using the default setup, that would be: ${USER_HOME} +-- .retest/ +-- recheck.ignore ${PROJECT_ROOT} +-- .retest/ | +-- recheck.ignore +-- src/test/resources/retest/recheck/ +-- ${SUITE_NAME} +-- recheck.ignore Usage Filters must be specified by name and given to the RecheckOptions as described here . That is, to make them usable within different products such that no information is lost. So, if you configure a filter within RecheckOptions (see below), you may want to use the same filter within review too, such that differences during test and review remain the same. RecheckOptions RecheckOptions . builder () . addIgnore ( \"my-custom-filter.filter\" ) . build (); # my-custom-filter.filter # Define your rules here: matcher : id=foo If you do not specify an ignore like above, Recheck will load the default ignore files. Ignore recheck.ignore This is a filter file which supports rules with the syntax below. They are normal text files and can be opened by any text editor. This file will be updated through the UI ( review or recheck.cli ) if you ignore any elements or differences. We try our best keep your custom-defined rules and respect the existing formatting. recheck.ignore.js This is a filter file which supports dynamic rules in JavaScript, using Mozilla's Rhino engine . This allows users to specify ignore rules very flexibly by using the following method: matches ( element , diff ); Method description Arguments : element ( Element ) : The element on which the difference occurred. diff ( AttributeDifference ) : The difference, may be null. Returns : bool : Whether the difference should be ignored. Example : An implementation can be found at recheck-web . Syntax You may define filters in a file with the .filter extension that is located in one of the two locations above. Since filters are additive, evaluated top to bottom, each line represents a separate filter. Thus, a file may represent a group of filters that can be combined to one topic (e.g. color differences). Warning If a filter (i.e. line) does not represent a valid syntax or comment, an error will be logged and the line is ignored. Comments # This is a comment. It starts with a '#' and encompasses the full line foo # Comment lines must start with a '#' and do not have leading whitespaces # ^ You may define empty lines Expressions Each line represents a filter, which itself can be made up by one or more expressions. Those expressions are separated with a comma and a whitespace , . When writing expressions, it is important to understand that filters are additive. Take the example below where each filter refers to a different element. Please refer to the individual expressions below to lookup their usage in detail. # Matches all elements and their attributes within a form element matcher : type=form # Matches the text attribute for all elements within body matcher : type=body, attribute=text If a filter refers to the same element, care must be taken, so that each filter is evaluated. # Matches all elements and their attributes within a body element matcher : type=body # Matches the text attribute for all elements within body # Will not be evaluated, because the above filter already matches matcher : type=body, attribute=text Since filters are evaluated top to bottom, we could switch both lines around. But since the body will be matched completely, regardless of the order, the more specific attribute is unnecessary. Thus it should be taken care, that each filter line references a unique scope , so that each line is evaluated and contributes to the filter as a whole. Scope Each expression applies to a specific scope. By default, a global scope is assumed (i.e. the report or state ) to which the resulting filter is applied. By chaining multiple expression within a single line, the following expression acts only upon the scope of the previous expression, while the last expression ultimately decides which final scope the filter applies. A filter executes its expressions lazily (left to right) and aborts as soon as the scope is empty. Consequently, it will only match, if the last scope analyzed is not empty. Thus, an expression is only evaluated, if the applying scope is not empty. State Consider the element structure as represented by the state : A collection of elements, where each element contains attributes which are assigned to values. For that the following scopes can be defined: State (i.e. collection of elements): This is the global scope . Element: Select an element, e.g. type button . Attribute: Select an attribute, e.g. background-color . Value: Select the value, e.g. rgb(125, 125, 125) . In words: The above example selects all button elements with the attribute background-color=rgb(125, 125, 125) . Report Although the structure of a report is quite different, ultimately, the scope is fairly similar to the scope of a state. Report (i.e. collection of element differences): This is the global scope . Element: Select an element, e.g. type button . The element difference is not exposed directly . Attribute Difference: Select an attribute, e.g. background-color , Value: Depending on the filter, this will select either the expected or actual value, e.g. rgb(125, 125, 125) . In words: The above example selects all button elements with the attribute difference background-color: actual=rgb(125, 125, 125) . Tip When chaining multiple expressions, scopes may be omitted. For example, omitting the element scope for the above example would result in a selection of all elements with the respective background color. Examples We currently support these individual expressions. Please refer to the more in detail descriptions below: # Import filters $import # Match any element $element # Match any attribute $attribute # Match any value $value # Match inserted changes (for elements) $inserted # Match deleted changes (for elements) $deleted # Match some pixel fluctuations (for attributes) $pixel-diff # Match some pixel fluctuations (for attributes) $color-diff You may chain them in the following way for elements: # Match an attribute for a specific element $element, $attribute # Match a specific value of an elements' attribute $element, $attribute, $value # Match some pixel fluctuations for an elements' attribute $element, $attribute, $pixel-diff # Match some color fluctuations for an elements' attribute $element, $attribute, $color-diff # Match a specific value for all attributes of an element $element, $value # Match some pixel fluctuations for all attributes of an element $element, $pixel-diff # Match the element only if it is inserted $element, $inserted # Match the element only if it is removed $element, $deleted # Exclude child elements or specific attributes $element, $exclude You may chain them in the following way for attributes: # Match a specific value of an attribute for all elements $attribute, $value # Match some pixel fluctuation of an attribute for all elements $attribute, $pixel-diff # Match some color fluctuation of an attribute for all elements $attribute, $color-diff Tip By combining element, attribute and value matching, you are able to match certain differences very specifically. Matching Elements Elements are identified by one special attribute $key , so called identifying attributes . # Match the element and its children where its attribute $key fully matches the $value. matcher : $key=$value This attribute can be any HTML attribute of the element. Fairly typical examples are given below, but it can really be any attribute. This is especially helpful if you define your own non-standard attributes, by which you want to identify the elements to ignore. $key $value (Example) Description retestid div-b4f23 A unique, stable ID for an element, that is generated by recheck . This is the default mechanism. xpath html[1]/body[1]/div[1] Note that this does only supports absolute XPaths. id myId HTML id attribute (supplied by recheck-web ) class my-class or my-class other-class HTML class attribute (supplied by recheck-web ) type button HTML tag name (supplied by recheck-web ) 1 Matching inserted or deleted elements If you are not interested in inserted or deleted elements, but still want to get notified if the attributes of the specified elements change, you can ignore those changes. This is useful for lists similar where you do not care if an element is inserted, but do care if the font or color changes. # Globally ignore insertions or deletions change = inserted change = deleted # Ignore only insertions deletions within the element matcher : $key=$value, change=inserted matcher : $key=$value, change=deleted Matching Attributes You can filter specific attributes that occur in differences by their respective name. Note An extension specifies which attributes (as well as identifying attributes ) it creates for an element. Their name is displayed in the corresponding difference. Please refer to extensions' documentation for that information. By Attribute If you are searching for a specific attribute, you may define the attribute expression. The value specified must match fully in order to let the filter return true . # Match the attribute outline only on the elements of type input matcher : type=input, attribute=outline # Match the attribute outline on all elements, thus removing this difference completely attribute = outline By Regular Expression Similarly, you can also use Java's regex mechanism and ignore attributes by a given pattern. # Match the attribute border-.*-color (e.g. border-bottom-color) on the elements of type input matcher : type=input, attribute-regex=border-.*-color # Match the attribute border-.*-color (e.g. border-bottom-color) on all elements attribute-regex = border-.*-color Matching Values If you want to ignore a specific value while still being notified about any other changes, you can specify a value-regex . This is helpful if you want to ensure that the value has a specific patter (e.g. date format) but do not care about the concrete value (because it is changing each day). # Match all attributes that look like a date format (dd.MM.yyyy) value-regex = \\d\\d.\\d\\d.\\d\\d\\d\\d Matching Pixel Differences Minor visual differences (e.g. between different browser types or browser versions) can make traditional, pixel-based approaches fail, which means more manual maintenance effort. In recheck , one can easily ignore pixel differences that are unimportant from a user's point of view: pixel-diff = 5px pixel-diff = 5.5px This would ignore every pixel difference (position- or size change) up to 5 pixels. You can either specify an integer or a float. Matching Color Differences Similarly to the pixel differences, it is possible to ignore small color differences. This is most useful to ignore small differences for color animations. color-diff = 5% Each color component (red, green, blue) is reviews in isolation. Changing only the red component from 255 to 127 would result in a color difference of 50%. Importing Filters To avoid having huge filter or ignore files and to avoid redundancy, you can create smaller, specialized filters which you can import. The import is specified by the filter name (i.e. the file name), which will look at the global scope of all filters to find the most specific one. For example using the below example, will search all available locations for the file name and choose the most specific filter to load. This way, the importing filter will always pick up any changes made to the imported filter. # Import other filters based on the name import : content.filter Warning Be careful not to use cyclic imports where a.filter imports b.filter and vice versa (same goes for longer cyclic chains). Secondly, only import filters from the same or a broader scope (e.g. filters within the user home should only import filters present in the user home or provided locations). If need be, you can always overwrite these filters within the project directory and the importing filter will use the project filter if available. Excluding Filters Excluding filters can be used to negate an expression, so that an expression returns the inverse, i.e. true instead of false and vice versa. If used inside a recheck.ignore , exclusions allows to revert an ignore (e.g. for sub elements). These expressions must be attached to a scope and can be used to revert this scope using an expression. The exact application is limited by which scope the exclusion is bound to. For example, attaching an exclusion to an element allows to exclude both sub-elements and individual attributes. Tip Excluding filters can only be applied to elements. We would love to hear possible use cases for other rules by creating an issue . Exclusion Syntax Excluding a filter takes a child expression. The child expression can accept the same expression as the scope to where the exclusion is attached. For example, attaching an exclusion to a matcher allows to also specify a matcher as a child expression. exclude($child) Here are some examples: # Match all div elements (including all attributes), except of the element .card matcher : type=div, exclude(matcher: class=card) # Match all p elements (including all attributes), except of the attribute p matcher : type=p, exclude(attribute=text) Chaining exclusions It is important to understand that filters are additive , where each line must represent a complete filter. The same applies for excluding filters. If a exclusion binds to the same scope (e.g. a form element), they must be chained together. # Match all elements within a form, except buttons matcher : type=form, exclude(type=button) # Match all elements within a form, except input elements # Will not be evaluated, because the above filter already matches matcher : type=form, exclude(type=input) You can chain multiple exclusions together the same way you can chain standard expressions . Contrary to expression chaining, exclusions will always only bind to the first non-exclusion scope . # All exclusions will bind to the matcher scope (i.e. all div elements) matcher : type=div, exclude(attribute=text), exclude(attribute=color) # Match all elements within a form, except buttons and inputs matcher : type=form, exclude(type=button), exclude(type=input) Warning Once an exclusion has been defined, only further exclusions may be defined. Currently, an exclusion cannot be mixed with other expressions. Importing exclusions Because exclusion expressions can become quite complex, you can also use the import statement to reference another filter. This filter is the same to each line wrapped into an exclusion. # exclude.filter matcher : type=input, attribute=text matcher : type=button # recheck.ignore matcher : type=form, exclude(import: exclude.filter) # Will be resolved to the following: matcher : type=form, exclude(matcher: type=input, attribute=text), exclude(matcher: type=button) Warning Care must be taken to ensure that the imported filter only specifies expressions that are valid as a child expression (i.e. within the same scope ). Otherwise the expression is considered invalid and will never match. Complex exclusion example Excluding filters can both be chained and nested, if the scope allows for it. Take a look at the example below. You can use exclusion expression chaining: matcher : id=body, exclude(attribute=text), exclude(matcher: id=btn-subscribe), exclude(matcher: id=div, exclude(matcher: id=form)) Or use imports from your filter of choice: # exclude.filter attribute = text matcher : id=btn-subscribe matcher : id=div, exclude(matcher: id=form) # global.filter matcher : id=body, exclude(import: exclude.filter) Elements to be matched (green) or ignored (red). Note that when using this example inside a recheck.ignore the respective element is inverted. +<body> - <div id=\"div\"> + <form id=\"form\"> + <label for=\"email\"> - Email + </label> + <input id=\"email\" type=\"email\"> + </form> - </div> + <div> - <button id=\"btn-subscribe\"> - Subscribe - </button> + </div> +</body> While the HTML tag name is mapped to type and part of the identifying attributes, the actual HTML type is put into the ordinary attributes that define an element's state. \u21a9","title":"Filter"},{"location":"recheck/usage/filter/#filter","text":"In principle, recheck creates a difference for every change that occurred and writes it into the report. Then it is up to the UI ( review or recheck.cli ) to hide ignored differences. This is pretty much in line with how Git works\u2014the diff is there, it just doesn't show up when ignored. The advantages of this approach are as follows: It is inspection / revision safe \u2013 every change is documented. Hidden changes (technical changes that are usually invisible to the user) are treated as any other change and are presented as such. You can change the rules of what to ignore and instantly see the impact.","title":"Filter"},{"location":"recheck/usage/filter/#what-are-filters","text":"Filters can be used for different purposes, most notably to reduce the noise mentioned above within a report . They can accept different arguments, which all are accessible using the below syntax : Element : Filter applies to all attributes of an element and all of its child elements. This may look at specific attributes, children or parent element to determine if the filter applies. The element in question can be identified by a wide range of identifying attributes, which are specified by the extensions . Attribute : Filter applies to a single attribute, either globally or for a specific element and all of its child elements. Difference : Filter applies to a difference where the attribute and the value can be retrieved. Multiple filters are additive. If one filter returns true , the result is taken and not further evaluated. Similarly, all filters must return false to ignore a particular difference. Note The filter as such does not define what happens with the output. It just matches a element or a difference. Please note the context in which you use a filter and what the output is used for.","title":"What Are Filters?"},{"location":"recheck/usage/filter/#location","text":"By default, filters are simple text files, so that they are reusable within different products and stages. The name of the file corresponds with the appropriate name used within recheck . There are several locations where the filter files can be placed, so that they may be referenced within the RecheckOptions .","title":"Location"},{"location":"recheck/usage/filter/#plain-filters","text":"Project filters in ${PROJECT_ROOT}/.retest/filter . User directory in ${USER_HOME}/.retest/filter . Must be created manually . Provided filters from recheck . We ship some categorized filters. Note We are currently experimenting with sensible defaults and may change the provided filters without notice. If you feel that they filter too much or too less within their respective category, please let us know, so that we can change these. Tip You may overwrite filters by using the same name. They are searched top-down. That is, project filters overwrite user filters, which in turn overwrite the provided filters. This allows you to easily overwrite the provided filters so that you can add your customizations.","title":"Plain Filters"},{"location":"recheck/usage/filter/#ignore-filters","text":"An ignore filter recheck.ignore is a special kind of filter which (by default) is loaded automatically. It defines that true ignores (i.e. hides) the specified difference, while false continues to use it. In contrast to plain filters, multiple ignore filters do not overwrite each other, despite having the same name. Rather, they are additive and each location contributes to the final ignore filter used by recheck. The following locations are searched: Globally: ${USER_HOME}/.retest/ . Must be created manually . For each Project: ${PROJECT_ROOT}/.retest/ . Will be created on first execution . For each Golden Master individually (i.e. suite). Must be created manually . After using recheck.cli or review to update the ignore filter, only the ignore file for the project will be updated to additionally contain the new ignored differences and all ignores from the global and suite ignore file. Using the default setup, that would be: ${USER_HOME} +-- .retest/ +-- recheck.ignore ${PROJECT_ROOT} +-- .retest/ | +-- recheck.ignore +-- src/test/resources/retest/recheck/ +-- ${SUITE_NAME} +-- recheck.ignore","title":"Ignore Filters"},{"location":"recheck/usage/filter/#usage","text":"Filters must be specified by name and given to the RecheckOptions as described here . That is, to make them usable within different products such that no information is lost. So, if you configure a filter within RecheckOptions (see below), you may want to use the same filter within review too, such that differences during test and review remain the same.","title":"Usage"},{"location":"recheck/usage/filter/#recheckoptions","text":"RecheckOptions . builder () . addIgnore ( \"my-custom-filter.filter\" ) . build (); # my-custom-filter.filter # Define your rules here: matcher : id=foo If you do not specify an ignore like above, Recheck will load the default ignore files.","title":"RecheckOptions"},{"location":"recheck/usage/filter/#ignore","text":"","title":"Ignore"},{"location":"recheck/usage/filter/#recheckignore","text":"This is a filter file which supports rules with the syntax below. They are normal text files and can be opened by any text editor. This file will be updated through the UI ( review or recheck.cli ) if you ignore any elements or differences. We try our best keep your custom-defined rules and respect the existing formatting.","title":"recheck.ignore"},{"location":"recheck/usage/filter/#recheckignorejs","text":"This is a filter file which supports dynamic rules in JavaScript, using Mozilla's Rhino engine . This allows users to specify ignore rules very flexibly by using the following method: matches ( element , diff ); Method description Arguments : element ( Element ) : The element on which the difference occurred. diff ( AttributeDifference ) : The difference, may be null. Returns : bool : Whether the difference should be ignored. Example : An implementation can be found at recheck-web .","title":"recheck.ignore.js"},{"location":"recheck/usage/filter/#syntax","text":"You may define filters in a file with the .filter extension that is located in one of the two locations above. Since filters are additive, evaluated top to bottom, each line represents a separate filter. Thus, a file may represent a group of filters that can be combined to one topic (e.g. color differences). Warning If a filter (i.e. line) does not represent a valid syntax or comment, an error will be logged and the line is ignored.","title":"Syntax"},{"location":"recheck/usage/filter/#comments","text":"# This is a comment. It starts with a '#' and encompasses the full line foo # Comment lines must start with a '#' and do not have leading whitespaces # ^ You may define empty lines","title":"Comments"},{"location":"recheck/usage/filter/#expressions","text":"Each line represents a filter, which itself can be made up by one or more expressions. Those expressions are separated with a comma and a whitespace , . When writing expressions, it is important to understand that filters are additive. Take the example below where each filter refers to a different element. Please refer to the individual expressions below to lookup their usage in detail. # Matches all elements and their attributes within a form element matcher : type=form # Matches the text attribute for all elements within body matcher : type=body, attribute=text If a filter refers to the same element, care must be taken, so that each filter is evaluated. # Matches all elements and their attributes within a body element matcher : type=body # Matches the text attribute for all elements within body # Will not be evaluated, because the above filter already matches matcher : type=body, attribute=text Since filters are evaluated top to bottom, we could switch both lines around. But since the body will be matched completely, regardless of the order, the more specific attribute is unnecessary. Thus it should be taken care, that each filter line references a unique scope , so that each line is evaluated and contributes to the filter as a whole.","title":"Expressions"},{"location":"recheck/usage/filter/#scope","text":"Each expression applies to a specific scope. By default, a global scope is assumed (i.e. the report or state ) to which the resulting filter is applied. By chaining multiple expression within a single line, the following expression acts only upon the scope of the previous expression, while the last expression ultimately decides which final scope the filter applies. A filter executes its expressions lazily (left to right) and aborts as soon as the scope is empty. Consequently, it will only match, if the last scope analyzed is not empty. Thus, an expression is only evaluated, if the applying scope is not empty.","title":"Scope"},{"location":"recheck/usage/filter/#examples","text":"We currently support these individual expressions. Please refer to the more in detail descriptions below: # Import filters $import # Match any element $element # Match any attribute $attribute # Match any value $value # Match inserted changes (for elements) $inserted # Match deleted changes (for elements) $deleted # Match some pixel fluctuations (for attributes) $pixel-diff # Match some pixel fluctuations (for attributes) $color-diff You may chain them in the following way for elements: # Match an attribute for a specific element $element, $attribute # Match a specific value of an elements' attribute $element, $attribute, $value # Match some pixel fluctuations for an elements' attribute $element, $attribute, $pixel-diff # Match some color fluctuations for an elements' attribute $element, $attribute, $color-diff # Match a specific value for all attributes of an element $element, $value # Match some pixel fluctuations for all attributes of an element $element, $pixel-diff # Match the element only if it is inserted $element, $inserted # Match the element only if it is removed $element, $deleted # Exclude child elements or specific attributes $element, $exclude You may chain them in the following way for attributes: # Match a specific value of an attribute for all elements $attribute, $value # Match some pixel fluctuation of an attribute for all elements $attribute, $pixel-diff # Match some color fluctuation of an attribute for all elements $attribute, $color-diff Tip By combining element, attribute and value matching, you are able to match certain differences very specifically.","title":"Examples"},{"location":"recheck/usage/filter/#matching-elements","text":"Elements are identified by one special attribute $key , so called identifying attributes . # Match the element and its children where its attribute $key fully matches the $value. matcher : $key=$value This attribute can be any HTML attribute of the element. Fairly typical examples are given below, but it can really be any attribute. This is especially helpful if you define your own non-standard attributes, by which you want to identify the elements to ignore. $key $value (Example) Description retestid div-b4f23 A unique, stable ID for an element, that is generated by recheck . This is the default mechanism. xpath html[1]/body[1]/div[1] Note that this does only supports absolute XPaths. id myId HTML id attribute (supplied by recheck-web ) class my-class or my-class other-class HTML class attribute (supplied by recheck-web ) type button HTML tag name (supplied by recheck-web ) 1","title":"Matching Elements"},{"location":"recheck/usage/filter/#matching-inserted-or-deleted-elements","text":"If you are not interested in inserted or deleted elements, but still want to get notified if the attributes of the specified elements change, you can ignore those changes. This is useful for lists similar where you do not care if an element is inserted, but do care if the font or color changes. # Globally ignore insertions or deletions change = inserted change = deleted # Ignore only insertions deletions within the element matcher : $key=$value, change=inserted matcher : $key=$value, change=deleted","title":"Matching inserted or deleted elements"},{"location":"recheck/usage/filter/#matching-attributes","text":"You can filter specific attributes that occur in differences by their respective name. Note An extension specifies which attributes (as well as identifying attributes ) it creates for an element. Their name is displayed in the corresponding difference. Please refer to extensions' documentation for that information.","title":"Matching Attributes"},{"location":"recheck/usage/filter/#by-attribute","text":"If you are searching for a specific attribute, you may define the attribute expression. The value specified must match fully in order to let the filter return true . # Match the attribute outline only on the elements of type input matcher : type=input, attribute=outline # Match the attribute outline on all elements, thus removing this difference completely attribute = outline","title":"By Attribute"},{"location":"recheck/usage/filter/#by-regular-expression","text":"Similarly, you can also use Java's regex mechanism and ignore attributes by a given pattern. # Match the attribute border-.*-color (e.g. border-bottom-color) on the elements of type input matcher : type=input, attribute-regex=border-.*-color # Match the attribute border-.*-color (e.g. border-bottom-color) on all elements attribute-regex = border-.*-color","title":"By Regular Expression"},{"location":"recheck/usage/filter/#matching-values","text":"If you want to ignore a specific value while still being notified about any other changes, you can specify a value-regex . This is helpful if you want to ensure that the value has a specific patter (e.g. date format) but do not care about the concrete value (because it is changing each day). # Match all attributes that look like a date format (dd.MM.yyyy) value-regex = \\d\\d.\\d\\d.\\d\\d\\d\\d","title":"Matching Values"},{"location":"recheck/usage/filter/#matching-pixel-differences","text":"Minor visual differences (e.g. between different browser types or browser versions) can make traditional, pixel-based approaches fail, which means more manual maintenance effort. In recheck , one can easily ignore pixel differences that are unimportant from a user's point of view: pixel-diff = 5px pixel-diff = 5.5px This would ignore every pixel difference (position- or size change) up to 5 pixels. You can either specify an integer or a float.","title":"Matching Pixel Differences"},{"location":"recheck/usage/filter/#matching-color-differences","text":"Similarly to the pixel differences, it is possible to ignore small color differences. This is most useful to ignore small differences for color animations. color-diff = 5% Each color component (red, green, blue) is reviews in isolation. Changing only the red component from 255 to 127 would result in a color difference of 50%.","title":"Matching Color Differences"},{"location":"recheck/usage/filter/#importing-filters","text":"To avoid having huge filter or ignore files and to avoid redundancy, you can create smaller, specialized filters which you can import. The import is specified by the filter name (i.e. the file name), which will look at the global scope of all filters to find the most specific one. For example using the below example, will search all available locations for the file name and choose the most specific filter to load. This way, the importing filter will always pick up any changes made to the imported filter. # Import other filters based on the name import : content.filter Warning Be careful not to use cyclic imports where a.filter imports b.filter and vice versa (same goes for longer cyclic chains). Secondly, only import filters from the same or a broader scope (e.g. filters within the user home should only import filters present in the user home or provided locations). If need be, you can always overwrite these filters within the project directory and the importing filter will use the project filter if available.","title":"Importing Filters"},{"location":"recheck/usage/filter/#excluding-filters","text":"Excluding filters can be used to negate an expression, so that an expression returns the inverse, i.e. true instead of false and vice versa. If used inside a recheck.ignore , exclusions allows to revert an ignore (e.g. for sub elements). These expressions must be attached to a scope and can be used to revert this scope using an expression. The exact application is limited by which scope the exclusion is bound to. For example, attaching an exclusion to an element allows to exclude both sub-elements and individual attributes. Tip Excluding filters can only be applied to elements. We would love to hear possible use cases for other rules by creating an issue .","title":"Excluding Filters"},{"location":"recheck/usage/filter/#exclusion-syntax","text":"Excluding a filter takes a child expression. The child expression can accept the same expression as the scope to where the exclusion is attached. For example, attaching an exclusion to a matcher allows to also specify a matcher as a child expression. exclude($child) Here are some examples: # Match all div elements (including all attributes), except of the element .card matcher : type=div, exclude(matcher: class=card) # Match all p elements (including all attributes), except of the attribute p matcher : type=p, exclude(attribute=text)","title":"Exclusion Syntax"},{"location":"recheck/usage/filter/#chaining-exclusions","text":"It is important to understand that filters are additive , where each line must represent a complete filter. The same applies for excluding filters. If a exclusion binds to the same scope (e.g. a form element), they must be chained together. # Match all elements within a form, except buttons matcher : type=form, exclude(type=button) # Match all elements within a form, except input elements # Will not be evaluated, because the above filter already matches matcher : type=form, exclude(type=input) You can chain multiple exclusions together the same way you can chain standard expressions . Contrary to expression chaining, exclusions will always only bind to the first non-exclusion scope . # All exclusions will bind to the matcher scope (i.e. all div elements) matcher : type=div, exclude(attribute=text), exclude(attribute=color) # Match all elements within a form, except buttons and inputs matcher : type=form, exclude(type=button), exclude(type=input) Warning Once an exclusion has been defined, only further exclusions may be defined. Currently, an exclusion cannot be mixed with other expressions.","title":"Chaining exclusions"},{"location":"recheck/usage/filter/#importing-exclusions","text":"Because exclusion expressions can become quite complex, you can also use the import statement to reference another filter. This filter is the same to each line wrapped into an exclusion. # exclude.filter matcher : type=input, attribute=text matcher : type=button # recheck.ignore matcher : type=form, exclude(import: exclude.filter) # Will be resolved to the following: matcher : type=form, exclude(matcher: type=input, attribute=text), exclude(matcher: type=button) Warning Care must be taken to ensure that the imported filter only specifies expressions that are valid as a child expression (i.e. within the same scope ). Otherwise the expression is considered invalid and will never match.","title":"Importing exclusions"},{"location":"recheck/usage/filter/#complex-exclusion-example","text":"Excluding filters can both be chained and nested, if the scope allows for it. Take a look at the example below. You can use exclusion expression chaining: matcher : id=body, exclude(attribute=text), exclude(matcher: id=btn-subscribe), exclude(matcher: id=div, exclude(matcher: id=form)) Or use imports from your filter of choice: # exclude.filter attribute = text matcher : id=btn-subscribe matcher : id=div, exclude(matcher: id=form) # global.filter matcher : id=body, exclude(import: exclude.filter) Elements to be matched (green) or ignored (red). Note that when using this example inside a recheck.ignore the respective element is inverted. +<body> - <div id=\"div\"> + <form id=\"form\"> + <label for=\"email\"> - Email + </label> + <input id=\"email\" type=\"email\"> + </form> - </div> + <div> - <button id=\"btn-subscribe\"> - Subscribe - </button> + </div> +</body> While the HTML tag name is mapped to type and part of the identifying attributes, the actual HTML type is put into the ordinary attributes that define an element's state. \u21a9","title":"Complex exclusion example"},{"location":"recheck-web/contributor-information/","text":"Contributor Information This page contains information for contributing developers. How to Create/Update the README Video/GIF Create a video e.g. using Eclipse and QuickTime Edit the video (shorten) using iMovie Convert the video using GIF Brewery 3 Click \"Create a new issue\" and insert the video (but do not actually create the issue) Insert the given URL into the readme","title":"Contributor Information"},{"location":"recheck-web/contributor-information/#contributor-information","text":"This page contains information for contributing developers.","title":"Contributor Information"},{"location":"recheck-web/contributor-information/#how-to-createupdate-the-readme-videogif","text":"Create a video e.g. using Eclipse and QuickTime Edit the video (shorten) using iMovie Convert the video using GIF Brewery 3 Click \"Create a new issue\" and insert the video (but do not actually create the issue) Insert the given URL into the readme","title":"How to Create/Update the README Video/GIF"},{"location":"recheck-web/element-identification-problem/","text":"The GUI Element Identification Problem Element identification is a well-known problem for test automation engineers. Both when simulating user interaction (e.g. when clicking a certain button) and when verifying a certain SUT property (e.g. the text value in an input field), it is necessary to reliably identify different elements on the GUI. This is usually done by an unambiguously identifying piece of information, such as the XPath, the label, and internal ID or the x/y coordinates. Now, if the chosen identifying piece of information changes over time (e.g. the button label is changed) or within different environments (e.g. on a screen with a different resolution), the element in question can either not be identified anymore or is identified falsely (e.g. the wrong text field is used). This typically results in annoying false positives, i.e. failing tests where the tested functionality works as expected and merely the test is broken. Depending on when that problem arises, it can even be hard to detect (e.g. when a text is entered in a wrong field early during test execution). AI can be applied to either help identify the correct element using a multitude of identification criteria (e.g. XPath, label, ID, class, x/y coordinates), using the \"looks\" of the element by applying some form of image recognition, or by choosing the historically most stable single identification criterion. All of these approaches have been used in the past, but none addresses the underlying problem: the continuous change of the software. So, if the correct element is identified by a multitude of criteria, the approach is robust against changes to one or even multiple of those criteria. However, if such changes occur, the values of those criteria still need to be updated to reflect those changes. Otherwise, confidence in the identification will decrease after multiple changes occur to different criteria throughout the lifetime of the software. Furthermore, at some point the remaining unchanged criteria will not yield a high enough confidence\u2014thus only postponing the problem, not solving it. The same is true for image recognition: if the past and present image increase in difference, at some point the remaining confidence will not be high enough. Also for choosing the historically most stable single identification criterion\u2014even if it was the most stable one, at some point it might still change. recheck addresses this problem in an interesting and unique way.","title":"The GUI Element Identification Problem"},{"location":"recheck-web/element-identification-problem/#the-gui-element-identification-problem","text":"Element identification is a well-known problem for test automation engineers. Both when simulating user interaction (e.g. when clicking a certain button) and when verifying a certain SUT property (e.g. the text value in an input field), it is necessary to reliably identify different elements on the GUI. This is usually done by an unambiguously identifying piece of information, such as the XPath, the label, and internal ID or the x/y coordinates. Now, if the chosen identifying piece of information changes over time (e.g. the button label is changed) or within different environments (e.g. on a screen with a different resolution), the element in question can either not be identified anymore or is identified falsely (e.g. the wrong text field is used). This typically results in annoying false positives, i.e. failing tests where the tested functionality works as expected and merely the test is broken. Depending on when that problem arises, it can even be hard to detect (e.g. when a text is entered in a wrong field early during test execution). AI can be applied to either help identify the correct element using a multitude of identification criteria (e.g. XPath, label, ID, class, x/y coordinates), using the \"looks\" of the element by applying some form of image recognition, or by choosing the historically most stable single identification criterion. All of these approaches have been used in the past, but none addresses the underlying problem: the continuous change of the software. So, if the correct element is identified by a multitude of criteria, the approach is robust against changes to one or even multiple of those criteria. However, if such changes occur, the values of those criteria still need to be updated to reflect those changes. Otherwise, confidence in the identification will decrease after multiple changes occur to different criteria throughout the lifetime of the software. Furthermore, at some point the remaining unchanged criteria will not yield a high enough confidence\u2014thus only postponing the problem, not solving it. The same is true for image recognition: if the past and present image increase in difference, at some point the remaining confidence will not be high enough. Also for choosing the historically most stable single identification criterion\u2014even if it was the most stable one, at some point it might still change. recheck addresses this problem in an interesting and unique way.","title":"The GUI Element Identification Problem"},{"location":"recheck-web/postpone-test-breakage/","text":"Postponing Test Breakage Element identification is a well-known problem for test automation engineers. recheck addresses this problem in an interesting and unique way. The Golden Master-based Difference Testing approach brings various benefits with it: it basically saves a complete copy of the last working state. Now after a breaking change, that copy can be used as a reference and for comparison. Now, e.g. if the label was used for identification, and the label changed, we can simply have a look in the old version (the Golden Master) and see which element has the given label. Then, using other identifying attributes like its XPath, ID, name, class and others, we can find the corresponding element with a different label in the current state. It is even better: not only do we have redundant information that we can easily keep up to date, thanks to the recheck.cli We also have a much more complete picture, i.e. all other elements that were on the website in the previous state. This allows for an easy 1-on-1 assignment of all elements, enabling a very robust element identification. To use this functionality, we can simply change an explicit checking test in the following way: private RecheckDriver driver ; private RecheckWebImpl re ; @Before public void setUp () { re = new RecheckWebImpl (); driver = new RecheckDriver ( new ChromeDriver () ); } Now instead of using the regular generic RecheckImpl , we use an adapted RecheckWebImpl and wrap the regular Selenium driver into a special RecheckDriver , that also is an instance of RemoteWebDriver . This way, maximal compatibility to other third party tools and test frameworks is ensured. Next, we can create a test that shows the functionality. For that we can use an example page from the Selenium project itself. We can download the formPage.html from the Selenium GitHub repository. Save it into your test resources folder ( src/test/resources ) Let's create a matching test for it. It could look like so: public class MyUnbreakableTest { RecheckDriver driver ; @Before public void setup () { driver = new RecheckDriver ( new ChromeDriver () ); } @Test public void check_order () throws Exception { driver . startTest (); String url = Paths . get ( \"src/test/resources/formPage.html\" ). toUri (). toURL (). toString (); driver . get ( url ); driver . findElement ( By . id ( \"email\" )). sendKeys ( \"Max\" ); driver . findElement ( By . id ( \"age\" )). sendKeys ( \"16\" ); driver . findElement ( By . name ( \"login\" )). submit (); driver . capTest (); } @After public void tearDown () { driver . quit (); } } Now we execute this test twice (using e.g. mvn test ). The first execution will fail as there is no Golden Master to compare against, but recheck will create the Golden Master while doing so. The second time we execute this test, it should pass. We then want to edit the HTML code of the page and change the used identifiers of the elements the test interacts with. So, we edit the formPage.html file and change the lines 15-19 from < form method = \"get\" action = \"resultPage.html\" name = \"login\" > < input type = \"email\" id = \"email\" /> < input type = \"number\" id = \"age\" /> < input type = \"submit\" id = \"submitButton\" value = \"Hello there\" /> </ form > to something like < form method = \"get\" action = \"resultPage.html\" name = \"newLoginName\" > < input type = \"email\" id = \"userEmail\" /> < input type = \"number\" id = \"numberOfLifeYears\" /> < input type = \"submit\" id = \"submit\" value = \"Hello there\" /> </ form > Because these identifiers are used in the test, this would tip of a typical Selenium test and make it fail without an actual problem in the web site-what is usually referred to as \"breaking the test\". To showcase and verify this problem, we can simply change the used driver to the default ChromeDriver and comment out the recheck-specific capTest() method call (using // ). Executing this test with a quick mvn test -Dtest=MyUnbreakableTest results in the dreaded NoSuchElementException . Now let's redo this with our original test using the RecheckDriver and execute it. It will still fail, but this time due to differences in the checks (as you would expect) and not due to elements not being found anymore. You can verify this by simply ignoring all differences. To do so, edit the .retest/recheck.ignore file and add attribute-regex=.* . This will ignore all attribute changes, including changes to id and name . If you re-execute your test, it will now pass. However, if you have a closer look to the log output that is printed to the console during execution, you can see that it will now contain a message similar to the following: *************** recheck warning *************** The HTML name attribute used for element identification changed from 'login' to 'newLoginName'. retest identified the element based on the persisted Golden Master. If you apply these changes to the Golden Master , your test retest.first.steps.FirstOrderTest will break. Use `By.name(\"newLoginName\")` or `By.retestId(\"form-26008\")` to update your test FirstOrderTest.java:30. This means that the RecheckDriver caught the NoSuchElementException . It then loaded the persisted Golden Master and found the element within it on the basis of the old version. Then it created the 1-on-1 assignment as shown above. It was able to correctly associate the new with the old element, used this new element in the test and continued. If you now apply that change to the Golden Master, recheck will no longer be able to identify the element based on the outdated identification criteria so you have to update your test when you apply the change.","title":"Postponing Test Breakage"},{"location":"recheck-web/postpone-test-breakage/#postponing-test-breakage","text":"Element identification is a well-known problem for test automation engineers. recheck addresses this problem in an interesting and unique way. The Golden Master-based Difference Testing approach brings various benefits with it: it basically saves a complete copy of the last working state. Now after a breaking change, that copy can be used as a reference and for comparison. Now, e.g. if the label was used for identification, and the label changed, we can simply have a look in the old version (the Golden Master) and see which element has the given label. Then, using other identifying attributes like its XPath, ID, name, class and others, we can find the corresponding element with a different label in the current state. It is even better: not only do we have redundant information that we can easily keep up to date, thanks to the recheck.cli We also have a much more complete picture, i.e. all other elements that were on the website in the previous state. This allows for an easy 1-on-1 assignment of all elements, enabling a very robust element identification. To use this functionality, we can simply change an explicit checking test in the following way: private RecheckDriver driver ; private RecheckWebImpl re ; @Before public void setUp () { re = new RecheckWebImpl (); driver = new RecheckDriver ( new ChromeDriver () ); } Now instead of using the regular generic RecheckImpl , we use an adapted RecheckWebImpl and wrap the regular Selenium driver into a special RecheckDriver , that also is an instance of RemoteWebDriver . This way, maximal compatibility to other third party tools and test frameworks is ensured. Next, we can create a test that shows the functionality. For that we can use an example page from the Selenium project itself. We can download the formPage.html from the Selenium GitHub repository. Save it into your test resources folder ( src/test/resources ) Let's create a matching test for it. It could look like so: public class MyUnbreakableTest { RecheckDriver driver ; @Before public void setup () { driver = new RecheckDriver ( new ChromeDriver () ); } @Test public void check_order () throws Exception { driver . startTest (); String url = Paths . get ( \"src/test/resources/formPage.html\" ). toUri (). toURL (). toString (); driver . get ( url ); driver . findElement ( By . id ( \"email\" )). sendKeys ( \"Max\" ); driver . findElement ( By . id ( \"age\" )). sendKeys ( \"16\" ); driver . findElement ( By . name ( \"login\" )). submit (); driver . capTest (); } @After public void tearDown () { driver . quit (); } } Now we execute this test twice (using e.g. mvn test ). The first execution will fail as there is no Golden Master to compare against, but recheck will create the Golden Master while doing so. The second time we execute this test, it should pass. We then want to edit the HTML code of the page and change the used identifiers of the elements the test interacts with. So, we edit the formPage.html file and change the lines 15-19 from < form method = \"get\" action = \"resultPage.html\" name = \"login\" > < input type = \"email\" id = \"email\" /> < input type = \"number\" id = \"age\" /> < input type = \"submit\" id = \"submitButton\" value = \"Hello there\" /> </ form > to something like < form method = \"get\" action = \"resultPage.html\" name = \"newLoginName\" > < input type = \"email\" id = \"userEmail\" /> < input type = \"number\" id = \"numberOfLifeYears\" /> < input type = \"submit\" id = \"submit\" value = \"Hello there\" /> </ form > Because these identifiers are used in the test, this would tip of a typical Selenium test and make it fail without an actual problem in the web site-what is usually referred to as \"breaking the test\". To showcase and verify this problem, we can simply change the used driver to the default ChromeDriver and comment out the recheck-specific capTest() method call (using // ). Executing this test with a quick mvn test -Dtest=MyUnbreakableTest results in the dreaded NoSuchElementException . Now let's redo this with our original test using the RecheckDriver and execute it. It will still fail, but this time due to differences in the checks (as you would expect) and not due to elements not being found anymore. You can verify this by simply ignoring all differences. To do so, edit the .retest/recheck.ignore file and add attribute-regex=.* . This will ignore all attribute changes, including changes to id and name . If you re-execute your test, it will now pass. However, if you have a closer look to the log output that is printed to the console during execution, you can see that it will now contain a message similar to the following: *************** recheck warning *************** The HTML name attribute used for element identification changed from 'login' to 'newLoginName'. retest identified the element based on the persisted Golden Master. If you apply these changes to the Golden Master , your test retest.first.steps.FirstOrderTest will break. Use `By.name(\"newLoginName\")` or `By.retestId(\"form-26008\")` to update your test FirstOrderTest.java:30. This means that the RecheckDriver caught the NoSuchElementException . It then loaded the persisted Golden Master and found the element within it on the basis of the old version. Then it created the 1-on-1 assignment as shown above. It was able to correctly associate the new with the old element, used this new element in the test and continued. If you now apply that change to the Golden Master, recheck will no longer be able to identify the element based on the outdated identification criteria so you have to update your test when you apply the change.","title":"Postponing Test Breakage"},{"location":"recheck-web/run-your-first-test/","text":"Run your first test Prerequisites Have Java 8 or higher installed. Install it from here Install Eclipse or IntelliJ editor. Download and extract review from here . Install ChromeDriver on your machine and make sure it's is in the PATH. Install on Mac Install on Windows Tip On Mac and Linux, place the chromedriver executable in /usr/local/bin folder so Eclipse and IntelliJ can find it. Install Maven. You can download the Maven binary Zip file from here Follow the installation instructions from here to add it to the PATH. Run the existing demo app Get the code: Option 1: Create a new maven project in your IDE and use the de.retest:recheck-web-archetype archetype as project prototype. Option 2: Run mvn archetype:generate -Dfilter=de.retest: and follow the interactive mode. Then import the created folder in your IDE as maven project You more information in the recheck-web-archetype github project . Run the test In Eclipse: Right click on the Project (or anywhere in the code) > Run As > JUnit Test In Command line, run the following Maven command: mvn test After you run one set of tests, you now have verified that the Golden Master is correct. Run the same test but change loginFormUrl in src/test/java/my/test/util/DemoApp.java to: https://assets.retest.org/demos/app/demo-app.html . static public String loginFormUrl () throws MalformedURLException { return \"https://assets.retest.org/demos/app/demo-app.html\" ; } This version of the demo app has some visual bugs so you can see how it all works. Start review and start exploring your report You find it in your project folder under this path ./target/test-classes/retest/recheck/tests.report .","title":"Run your first Test"},{"location":"recheck-web/run-your-first-test/#run-your-first-test","text":"","title":"Run your first test"},{"location":"recheck-web/run-your-first-test/#prerequisites","text":"Have Java 8 or higher installed. Install it from here Install Eclipse or IntelliJ editor. Download and extract review from here . Install ChromeDriver on your machine and make sure it's is in the PATH. Install on Mac Install on Windows Tip On Mac and Linux, place the chromedriver executable in /usr/local/bin folder so Eclipse and IntelliJ can find it. Install Maven. You can download the Maven binary Zip file from here Follow the installation instructions from here to add it to the PATH.","title":"Prerequisites"},{"location":"recheck-web/run-your-first-test/#run-the-existing-demo-app","text":"Get the code: Option 1: Create a new maven project in your IDE and use the de.retest:recheck-web-archetype archetype as project prototype. Option 2: Run mvn archetype:generate -Dfilter=de.retest: and follow the interactive mode. Then import the created folder in your IDE as maven project You more information in the recheck-web-archetype github project . Run the test In Eclipse: Right click on the Project (or anywhere in the code) > Run As > JUnit Test In Command line, run the following Maven command: mvn test After you run one set of tests, you now have verified that the Golden Master is correct. Run the same test but change loginFormUrl in src/test/java/my/test/util/DemoApp.java to: https://assets.retest.org/demos/app/demo-app.html . static public String loginFormUrl () throws MalformedURLException { return \"https://assets.retest.org/demos/app/demo-app.html\" ; } This version of the demo app has some visual bugs so you can see how it all works. Start review and start exploring your report You find it in your project folder under this path ./target/test-classes/retest/recheck/tests.report .","title":"Run the existing demo app"},{"location":"recheck-web/unbreakable-selenium/","text":"Unbreakable Selenium As shown here , recheck can easily postpone that a test brakes. But it can even go one step further and make the test almost \"unbreakable\". If you have a look at one of the Golden Master files (e.g. /src/test/resources/retest/recheck/com.mycompany.MyUnbreakableTest/check_order.00.recheck/retest.xml ), you can see that every element has an attribute called retestId . You can regard this retestId to be a virtual and constant identifying attribute. We call it virtual, because it never actually shows up on the GUI\u2014and therefore it is never affected by GUI changes, making it constant. recheck uses the RetestIdProvider configured in the RecheckOptions that are passed to the RecheckDriver to generate that retestId . It can be any value, as long as it is unique within the Golden Master. When you update your test after such a breaking change, you can now refer to the retestId instead of other volatile identifying attributes, such as the HTML ID or name, XPath or the like. Now we can adapt the above test as suggested by the log output to be similar to the following (use the values of your log output): @Test public void check_order () throws Exception { driver . startTest (); String url = Paths . get ( \"src/test/resources/formPage.html\" ). toUri (). toURL (). toString (); driver . get ( url ); driver . findElement ( By . retestId ( \"input\" )). sendKeys ( \"Max\" ); driver . findElement ( By . retestId ( \"input-e3f18\" )). sendKeys ( \"16\" ); driver . findElement ( By . retestId ( \"form\" )). submit (); driver . capTest (); } Make sure to also import the correct By (i.e. import de.retest.web.selenium.By ). When we execute this test, it passes. Now we can remove the attribute=.* again from our recheck.ignore file to make the test fail as expected\u2014because there actually was a difference.","title":"Unbreakable Selenium"},{"location":"recheck-web/unbreakable-selenium/#unbreakable-selenium","text":"As shown here , recheck can easily postpone that a test brakes. But it can even go one step further and make the test almost \"unbreakable\". If you have a look at one of the Golden Master files (e.g. /src/test/resources/retest/recheck/com.mycompany.MyUnbreakableTest/check_order.00.recheck/retest.xml ), you can see that every element has an attribute called retestId . You can regard this retestId to be a virtual and constant identifying attribute. We call it virtual, because it never actually shows up on the GUI\u2014and therefore it is never affected by GUI changes, making it constant. recheck uses the RetestIdProvider configured in the RecheckOptions that are passed to the RecheckDriver to generate that retestId . It can be any value, as long as it is unique within the Golden Master. When you update your test after such a breaking change, you can now refer to the retestId instead of other volatile identifying attributes, such as the HTML ID or name, XPath or the like. Now we can adapt the above test as suggested by the log output to be similar to the following (use the values of your log output): @Test public void check_order () throws Exception { driver . startTest (); String url = Paths . get ( \"src/test/resources/formPage.html\" ). toUri (). toURL (). toString (); driver . get ( url ); driver . findElement ( By . retestId ( \"input\" )). sendKeys ( \"Max\" ); driver . findElement ( By . retestId ( \"input-e3f18\" )). sendKeys ( \"16\" ); driver . findElement ( By . retestId ( \"form\" )). submit (); driver . capTest (); } Make sure to also import the correct By (i.e. import de.retest.web.selenium.By ). When we execute this test, it passes. Now we can remove the attribute=.* again from our recheck.ignore file to make the test fail as expected\u2014because there actually was a difference.","title":"Unbreakable Selenium"},{"location":"recheck-web/introduction/usage/","text":"Usage In its core, recheck-web extends recheck and adds the capability to check for: WebDriver : Check the complete page rendered by the browser . WebElement : Check individual page sections with isolated elements . For a basic introduction on how recheck works, please visit the Usage page. Please be sure to understand the files generated: Golden Master , Report . However, recheck-web also provides some additional features building upon the above capabilities. Best Practices Use a fresh driver and recheck instance for each test. This is best done within the @BeforeEach method or similar methods available through your test framework. Use the appropriate test extension for your test framework to handle the lifecycle and use unique suite, test and check names within each lifecycle step, unless you want to reuse Golden Masters . Stabilize your page before checking to minimize differences. Ensure the driver has a fixed window size using driver.manage().window().setSize( size ) . Wait for animations to be done by checking the respective elements and attributes with ExpectedConditions . This may be done best within a page object constructor. Click away any banners or popups (e.g. cookie-banners, subscribe-banners) as this will interfere with scrolling and screenshot creation. Create an initial Golden Master with a WebDriver after the page is loaded and stabilized and before any elements are executed to allow for more advanced features to work. This is not necessary when using implicit checking as this is done for you. WebDriver The most basic way to check the page is to check a WebDriver or any element that implements WrapsDriver . Note The deepest WebDriver must be an instance of a RemoteWebDriver (i.e. JavascripExecutor ) which all common Selenium Drivers are (ChromeDriver, FirefoxDriver, ...). WebDriver driver = // ... Recheck re = // ... // ... re . check ( driver , \"complete-page\" ); // ... WebElement To check isolated elements out of the context of the complete page, you can check a WebElement or any object that implements WrapsElement . Note The deepest WebElement must be an instance of a RemoteWebElement which all elements of a common Selenium Drivers are (ChromeDriver, FirefoxDriver, ...). WebDriver driver = // ... Recheck re = // ... // ... re . check ( driver . findElement ( By . id ( \"#section\" ) ), \"individual-section\" ); // ... Page Objects With the basic types from above, it is possible to check page objects or any arbitrary objects. Just let those objects implement either WrapsElement or WrapsDriver to check for object. Note recheck-web will not check any @FindBy , only the return value of those interfaces are checked. This can be achieved by implementing WrapsElement and returning the respective @FindBy . Warning Due to the way WrapsElement and WrapsDriver works, recheck-web will evaluate WrapsElement before WrapsDriver . Thus it is recommended to only implement one of those interfaces. // LoginForm.java public class LoginForm implements WrapsElement { @FindBy ( id = \"login-form\" ) private WebElement form ; public LoginForm ( final WebDriver driver ) { PageFactory . initElements ( driver , this ); } @Override public WebElement getWrappedElement () { return form ; } } // LoginPage.java public class LoginPage implements WrapsDriver { private final WebDriver driver ; private final LoginForm form ; @FindBy ( id = \"header\" ) private WebElement header ; public LoginPage ( final WebDriver driver ) { this . driver = driver ; this . form = new LoginForm ( driver ); PageFactory . initElements ( driver , this ); } public LoginForm getForm () { return form ; } @Override public WebDriver getWrappedDriver () { return driver ; } } // LoginTest.java @Test void testLoginPage () { // Assuming driver and re is already initialized before LoginPage page = new LoginPage ( driver ); LoginForm form = page . getForm (); re . check ( page , \"login-page\" ); re . check ( form , \"login-form\" ); } This can be used for complex page layouts to test only relevant sections by using elements, or when applicable, return the driver instead to check the whole page. Explicit checking Migrating from your standard Selenium test, using explicit checking is the most straightforward way. Instead of the standard assertions, you explicitly call Recheck#check which then does the assertions for you. Consider the below standard Selenium test (using JUnit5). The test that tries to enter the login form and login to a web application using invalid credentials. The web application is supposed to produce an error message saying that an invalid password has been entered and as a result should clear the user and password fields. class LoginTest { WebDriver driver ; @BeforeEach void setUp () { driver = new ChromeDriver (); // Create your driver } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element user . sendKeys ( \"admin\" ); // Type the user 'admin' final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the login button login . click (); // Press the button to initiate the login process // Wait for login to happen by using WebDriverWait or similar to stabilize your page final WebElement error = driver . findElement ( By . id ( \"error\" ) ); // Find the error text next to the login button assertEquals ( \"Invalid user or password!\" , error . getText () ); // Check if the text contains error message assertEquals ( \"\" , user . getAttribute ( \"value\" ) ); // Check if the user has been cleared assertEquals ( \"\" , password . getAttribute ( \"value\" ) ); // Check if the password has been cleared } } Transforming this test using recheck and the recheck-junit-jupiter-extension is fairly easy, following the basic recheck usage . Just create and configure your Recheck instance and replace all your assertions with the Recheck#check method by passing in your WebDriver and naming the check respectively. For the most deterministic results, ensure that your website is as stable as possible, before doing your checks. @ExtendWith ( RecheckExtension . class ) // Add the extension that will perform the lifecycle class LoginTest { Recheck re ; WebDriver driver ; @BeforeEach void setUp () { re = new RecheckImpl (); // Create the recheck instance driver = new ChromeDriver (); // Create your driver } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { // ... // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"invalid-login\" ); // Check your complete page, previously done by assertions } } Warning Do not forget to call the lifecycle or let a test extension do it for you. Unbreakable tests However, these tests are still brittle and break easily. If any of the identifiers change, specified as By.id( \"user\" ) or similar, Selenium is not able to find the element and your whole test breaks with a NoSuchElementFoundException . In most of the cases, the identifier is irrelevant for the user as, for example, the id is never shown. For more information, please visit this page . - <input type=\"text\" id=\"user\"> + <input type=\"text\" id=\"input-user\"> To make your test nearly unbreakable, use the UnbreakableDriver provided by recheck-web . Be sure to understand the following terms: scope and reference which is used to find broken elements. @BeforeEach void setUp () { re = new RecheckWebImpl (); // Take care that you take the specialized 'RecheckWebImpl' driver = new UnbreakableDriver ( new ChromeDriver () ); // Wrap your driver in a UnbreakableDriver to enable nearly unbreakable tests } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page // Wait for page to be loaded by using WebDriverWait or similar to stabilize your page re . check ( driver , \"initial\" ); // Make sure a Golden Master is present for unbreakable elements // Continue with your test final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element // ... } Warning Be sure to use a Recheck**Web**Impl with a UnbreakableDriver . The standard RecheckImpl is not capable of making your tests unbreakable. Note In order for this feature to work, a Golden Master must have been created before in order to find the element in question. Unbreakable Scopes A Scope is the content of the Golden Master and as such is the available search space for the UnbreakableDriver to find the element in question. The scope gets defined by the driver or element checked. A driver will encompass the whole web application as search space, while the element will encompass only the element itself with its children. For example the test above tests an arbitrary login process. The scope for the element form will contain all necessary elements to complete the login process: user , password and login elements. However, the scope for the element user will only contain the user and not any other element. The UnbreakableDriver will search within the scope available to search for any broken elements. For example, the login button is only available within driver or the form element; it is not available within the user element. Tip The scope for the driver and driver.findElement( By.type( \"html\" ) ) is essentially the same. Unbreakable References A Reference is the location of the Golden Master where the UnbreakableDriver . It is associated with a scope. If Selenium cannot find the element, the UnbreakableDriver will jump in and search the last reference to the Golden Master and within the associated scope. This reference is overwritten with each check, thus it should be verified that elements are searched within the correct reference (see example below). You may have noticed the highlighted line with the initial driver check in the above migration example. Initially, no check was performed and therefore no reference has been defined yet. As such, the unbreakable feature cannot work. In order for it to work, an initial check must be performed for the reference to be set, before any broken elements can be found. This initial reference must have a sufficient scope available to find each element; thus it is recommended to perform it with the driver instance. Warning The unbreakable feature only works, if a Golden Master has been created before (i.e. a full test has been run at least once). Unbreakable example It should be taken care that the correct reference with a sufficient scope is available when searching for elements. The below examples should highlight the issue, when elements are searched with insufficient scopes. @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the \"user\" element in an undefined reference -> will fail user . sendKeys ( \"admin\" ); re . check ( user , \"user\" ); // Create reference \"user\" with scope \"element(user)\" final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the \"password\" element in reference \"user\" -> will fail password . sendKeys ( \"secret\" ); re . check ( user , \"password\" ); // Create reference \"password\" with scope \"element(password)\" final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the \"login\" element in reference \"password\" -> will fail login . click (); // Press the button to initiate the login process // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"login\" ) // Create reference \"login\" with scope \"driver\" } The above example does not work because of both an insufficient scope and an invalid reference. Therefore it is recommended to find the elements with the broadest scope available (e.g. after the initial check). This follows the Page Object Pattern , where the elements are accessed once and reused afterwards. @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"initial\" ); // Create reference \"initial\" with scope \"driver\" final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the \"user\" element in reference \"initial\" final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the \"password\" element in reference \"initial\" final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the \"login\" element in reference \"initial\" user . sendKeys ( \"admin\" ); re . check ( user , \"user\" ); // Create reference \"user\" with scope \"element(user)\" password . sendKeys ( \"secret\" ); re . check ( password , \"password\" ); // Create reference \"password\" with scope \"element(password)\" login . click (); // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"login\" ) // Create reference \"login\" with scope \"driver\" } Tip From each driver.findElement look at the lines above for a re.check to identify the reference used. Then decide if this reference with its associated scope contains the element you are searching for. Tip Use the Page Object Pattern to ensure correct and properly resolved elements. An example to make Page Objects work with recheck-web can be found above . Implicit checking The above example\u2014by design\u2014has a major flaw: while it checks the end result to see if the login has been denied due to a wrong password, you don't know what happens up until your actual check. You could go ahead and do an explicit check after each action, but this is where implicit checking comes in handy. It does the same, but without writing code. Just perform the action and recheck-web will perform the checking in the background. This removes not only the need for assertions, but moreover does the checking transparently. Consider the example above where an invalid login is performed with the following actions: Type user \"admin\". Type password \"invalid\". Click login. This will create three checks after each action has been executed. @ExtendWith ( RecheckExtension . class ) // Add the extension that will perform the lifecycle class LoginTest { WebDriver driver ; @BeforeEach void setUp () { driver = new AutocheckingRecheckDriver ( new ChromeDriver () ); // Wrap your driver in a AutocheckingRecheckDriver to enable implicit checking } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page, this will perform a check final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element user . sendKeys ( \"admin\" ); // Type the user 'admin', this will perform a check final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password, this will perform a check final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the login button login . click (); // Press the button to initiate the login process, this will perform a check } } Warning Do not forget to call the lifecycle or let a test extension do it for you. For that, you may need to change the field driver to the respective wrapped driver. Warning Do not mix implicit and explicit checking as this will produce unexpected results. Thus be sure to remove the Recheck instance from your test code. Skipping checks It is possible to skip an implicit check by using the skipCheck() method on either AutocheckingRecheckDriver or AutocheckingWebElement which will not create a Golden Master for any actions performed on the driver or element. AutocheckingRecheckDriver driver = ... WebDriver skipping = driver . skipCheck (); // This will disable checks for the returned driver skipping . get ( \"https://example.com\" ); // Go to your login page, this will not perform a check final WebElement user = driver . findElement ( By . id ( \"user\" ) ). skipCheck (); // Find the user input element, disabling checks for the returned element user . sendKeys ( \"admin\" ); // Type the user 'admin', this will not perform a check final WebElement password = skipping . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password, this will not perform a check RecheckDriver RecheckDriver combines all the above mentioned recheck-web features: No assertions. Unbreakable tests. Implicit checking. Use this class if you automatically want to incorporate new features without changing your existing test class. @ExtendWith ( RecheckExtension . class ) // Add the extension that will perform the lifecycle class LoginTest { WebDriver driver ; @BeforeEach void setUp () { driver = new RecheckDriver ( new ChromeDriver () ); // Wrap your driver in a RecheckDriver to enable all recheck-web features } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element user . sendKeys ( \"admin\" ); // Type the user 'admin' final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the login button login . click (); // Press the button to initiate the login process } } Warning Do not forget to call the lifecycle or let a test extension do it for you. For that, you may need to change the field driver to the respective wrapped driver. Warning Do not mix implicit and explicit checking as this will produce unexpected results. Thus be sure to remove the Recheck instance from your test code. To summarize: WebDriver Checks Recheck Ordinary driver (e.g. ChromeDriver ) Explicit RecheckImpl UnbreakableDriver Explicit RecheckWebImpl AutocheckingRecheckDriver Implicit Integrated (i.e. not needed) RecheckDriver Implicit Integrated (i.e. not needed) For further information you can check out the Javadoc of the corresponding classes and refer to our integration tests , which demonstrate the usage.","title":"Usage"},{"location":"recheck-web/introduction/usage/#usage","text":"In its core, recheck-web extends recheck and adds the capability to check for: WebDriver : Check the complete page rendered by the browser . WebElement : Check individual page sections with isolated elements . For a basic introduction on how recheck works, please visit the Usage page. Please be sure to understand the files generated: Golden Master , Report . However, recheck-web also provides some additional features building upon the above capabilities.","title":"Usage"},{"location":"recheck-web/introduction/usage/#best-practices","text":"Use a fresh driver and recheck instance for each test. This is best done within the @BeforeEach method or similar methods available through your test framework. Use the appropriate test extension for your test framework to handle the lifecycle and use unique suite, test and check names within each lifecycle step, unless you want to reuse Golden Masters . Stabilize your page before checking to minimize differences. Ensure the driver has a fixed window size using driver.manage().window().setSize( size ) . Wait for animations to be done by checking the respective elements and attributes with ExpectedConditions . This may be done best within a page object constructor. Click away any banners or popups (e.g. cookie-banners, subscribe-banners) as this will interfere with scrolling and screenshot creation. Create an initial Golden Master with a WebDriver after the page is loaded and stabilized and before any elements are executed to allow for more advanced features to work. This is not necessary when using implicit checking as this is done for you.","title":"Best Practices"},{"location":"recheck-web/introduction/usage/#webdriver","text":"The most basic way to check the page is to check a WebDriver or any element that implements WrapsDriver . Note The deepest WebDriver must be an instance of a RemoteWebDriver (i.e. JavascripExecutor ) which all common Selenium Drivers are (ChromeDriver, FirefoxDriver, ...). WebDriver driver = // ... Recheck re = // ... // ... re . check ( driver , \"complete-page\" ); // ...","title":"WebDriver"},{"location":"recheck-web/introduction/usage/#webelement","text":"To check isolated elements out of the context of the complete page, you can check a WebElement or any object that implements WrapsElement . Note The deepest WebElement must be an instance of a RemoteWebElement which all elements of a common Selenium Drivers are (ChromeDriver, FirefoxDriver, ...). WebDriver driver = // ... Recheck re = // ... // ... re . check ( driver . findElement ( By . id ( \"#section\" ) ), \"individual-section\" ); // ...","title":"WebElement"},{"location":"recheck-web/introduction/usage/#page-objects","text":"With the basic types from above, it is possible to check page objects or any arbitrary objects. Just let those objects implement either WrapsElement or WrapsDriver to check for object. Note recheck-web will not check any @FindBy , only the return value of those interfaces are checked. This can be achieved by implementing WrapsElement and returning the respective @FindBy . Warning Due to the way WrapsElement and WrapsDriver works, recheck-web will evaluate WrapsElement before WrapsDriver . Thus it is recommended to only implement one of those interfaces. // LoginForm.java public class LoginForm implements WrapsElement { @FindBy ( id = \"login-form\" ) private WebElement form ; public LoginForm ( final WebDriver driver ) { PageFactory . initElements ( driver , this ); } @Override public WebElement getWrappedElement () { return form ; } } // LoginPage.java public class LoginPage implements WrapsDriver { private final WebDriver driver ; private final LoginForm form ; @FindBy ( id = \"header\" ) private WebElement header ; public LoginPage ( final WebDriver driver ) { this . driver = driver ; this . form = new LoginForm ( driver ); PageFactory . initElements ( driver , this ); } public LoginForm getForm () { return form ; } @Override public WebDriver getWrappedDriver () { return driver ; } } // LoginTest.java @Test void testLoginPage () { // Assuming driver and re is already initialized before LoginPage page = new LoginPage ( driver ); LoginForm form = page . getForm (); re . check ( page , \"login-page\" ); re . check ( form , \"login-form\" ); } This can be used for complex page layouts to test only relevant sections by using elements, or when applicable, return the driver instead to check the whole page.","title":"Page Objects"},{"location":"recheck-web/introduction/usage/#explicit-checking","text":"Migrating from your standard Selenium test, using explicit checking is the most straightforward way. Instead of the standard assertions, you explicitly call Recheck#check which then does the assertions for you. Consider the below standard Selenium test (using JUnit5). The test that tries to enter the login form and login to a web application using invalid credentials. The web application is supposed to produce an error message saying that an invalid password has been entered and as a result should clear the user and password fields. class LoginTest { WebDriver driver ; @BeforeEach void setUp () { driver = new ChromeDriver (); // Create your driver } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element user . sendKeys ( \"admin\" ); // Type the user 'admin' final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the login button login . click (); // Press the button to initiate the login process // Wait for login to happen by using WebDriverWait or similar to stabilize your page final WebElement error = driver . findElement ( By . id ( \"error\" ) ); // Find the error text next to the login button assertEquals ( \"Invalid user or password!\" , error . getText () ); // Check if the text contains error message assertEquals ( \"\" , user . getAttribute ( \"value\" ) ); // Check if the user has been cleared assertEquals ( \"\" , password . getAttribute ( \"value\" ) ); // Check if the password has been cleared } } Transforming this test using recheck and the recheck-junit-jupiter-extension is fairly easy, following the basic recheck usage . Just create and configure your Recheck instance and replace all your assertions with the Recheck#check method by passing in your WebDriver and naming the check respectively. For the most deterministic results, ensure that your website is as stable as possible, before doing your checks. @ExtendWith ( RecheckExtension . class ) // Add the extension that will perform the lifecycle class LoginTest { Recheck re ; WebDriver driver ; @BeforeEach void setUp () { re = new RecheckImpl (); // Create the recheck instance driver = new ChromeDriver (); // Create your driver } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { // ... // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"invalid-login\" ); // Check your complete page, previously done by assertions } } Warning Do not forget to call the lifecycle or let a test extension do it for you.","title":"Explicit checking"},{"location":"recheck-web/introduction/usage/#unbreakable-tests","text":"However, these tests are still brittle and break easily. If any of the identifiers change, specified as By.id( \"user\" ) or similar, Selenium is not able to find the element and your whole test breaks with a NoSuchElementFoundException . In most of the cases, the identifier is irrelevant for the user as, for example, the id is never shown. For more information, please visit this page . - <input type=\"text\" id=\"user\"> + <input type=\"text\" id=\"input-user\"> To make your test nearly unbreakable, use the UnbreakableDriver provided by recheck-web . Be sure to understand the following terms: scope and reference which is used to find broken elements. @BeforeEach void setUp () { re = new RecheckWebImpl (); // Take care that you take the specialized 'RecheckWebImpl' driver = new UnbreakableDriver ( new ChromeDriver () ); // Wrap your driver in a UnbreakableDriver to enable nearly unbreakable tests } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page // Wait for page to be loaded by using WebDriverWait or similar to stabilize your page re . check ( driver , \"initial\" ); // Make sure a Golden Master is present for unbreakable elements // Continue with your test final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element // ... } Warning Be sure to use a Recheck**Web**Impl with a UnbreakableDriver . The standard RecheckImpl is not capable of making your tests unbreakable. Note In order for this feature to work, a Golden Master must have been created before in order to find the element in question.","title":"Unbreakable tests"},{"location":"recheck-web/introduction/usage/#unbreakable-scopes","text":"A Scope is the content of the Golden Master and as such is the available search space for the UnbreakableDriver to find the element in question. The scope gets defined by the driver or element checked. A driver will encompass the whole web application as search space, while the element will encompass only the element itself with its children. For example the test above tests an arbitrary login process. The scope for the element form will contain all necessary elements to complete the login process: user , password and login elements. However, the scope for the element user will only contain the user and not any other element. The UnbreakableDriver will search within the scope available to search for any broken elements. For example, the login button is only available within driver or the form element; it is not available within the user element. Tip The scope for the driver and driver.findElement( By.type( \"html\" ) ) is essentially the same.","title":"Unbreakable Scopes"},{"location":"recheck-web/introduction/usage/#unbreakable-references","text":"A Reference is the location of the Golden Master where the UnbreakableDriver . It is associated with a scope. If Selenium cannot find the element, the UnbreakableDriver will jump in and search the last reference to the Golden Master and within the associated scope. This reference is overwritten with each check, thus it should be verified that elements are searched within the correct reference (see example below). You may have noticed the highlighted line with the initial driver check in the above migration example. Initially, no check was performed and therefore no reference has been defined yet. As such, the unbreakable feature cannot work. In order for it to work, an initial check must be performed for the reference to be set, before any broken elements can be found. This initial reference must have a sufficient scope available to find each element; thus it is recommended to perform it with the driver instance. Warning The unbreakable feature only works, if a Golden Master has been created before (i.e. a full test has been run at least once).","title":"Unbreakable References"},{"location":"recheck-web/introduction/usage/#unbreakable-example","text":"It should be taken care that the correct reference with a sufficient scope is available when searching for elements. The below examples should highlight the issue, when elements are searched with insufficient scopes. @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the \"user\" element in an undefined reference -> will fail user . sendKeys ( \"admin\" ); re . check ( user , \"user\" ); // Create reference \"user\" with scope \"element(user)\" final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the \"password\" element in reference \"user\" -> will fail password . sendKeys ( \"secret\" ); re . check ( user , \"password\" ); // Create reference \"password\" with scope \"element(password)\" final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the \"login\" element in reference \"password\" -> will fail login . click (); // Press the button to initiate the login process // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"login\" ) // Create reference \"login\" with scope \"driver\" } The above example does not work because of both an insufficient scope and an invalid reference. Therefore it is recommended to find the elements with the broadest scope available (e.g. after the initial check). This follows the Page Object Pattern , where the elements are accessed once and reused afterwards. @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"initial\" ); // Create reference \"initial\" with scope \"driver\" final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the \"user\" element in reference \"initial\" final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the \"password\" element in reference \"initial\" final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the \"login\" element in reference \"initial\" user . sendKeys ( \"admin\" ); re . check ( user , \"user\" ); // Create reference \"user\" with scope \"element(user)\" password . sendKeys ( \"secret\" ); re . check ( password , \"password\" ); // Create reference \"password\" with scope \"element(password)\" login . click (); // Wait for login to happen by using WebDriverWait or similar to stabilize your page re . check ( driver , \"login\" ) // Create reference \"login\" with scope \"driver\" } Tip From each driver.findElement look at the lines above for a re.check to identify the reference used. Then decide if this reference with its associated scope contains the element you are searching for. Tip Use the Page Object Pattern to ensure correct and properly resolved elements. An example to make Page Objects work with recheck-web can be found above .","title":"Unbreakable example"},{"location":"recheck-web/introduction/usage/#implicit-checking","text":"The above example\u2014by design\u2014has a major flaw: while it checks the end result to see if the login has been denied due to a wrong password, you don't know what happens up until your actual check. You could go ahead and do an explicit check after each action, but this is where implicit checking comes in handy. It does the same, but without writing code. Just perform the action and recheck-web will perform the checking in the background. This removes not only the need for assertions, but moreover does the checking transparently. Consider the example above where an invalid login is performed with the following actions: Type user \"admin\". Type password \"invalid\". Click login. This will create three checks after each action has been executed. @ExtendWith ( RecheckExtension . class ) // Add the extension that will perform the lifecycle class LoginTest { WebDriver driver ; @BeforeEach void setUp () { driver = new AutocheckingRecheckDriver ( new ChromeDriver () ); // Wrap your driver in a AutocheckingRecheckDriver to enable implicit checking } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page, this will perform a check final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element user . sendKeys ( \"admin\" ); // Type the user 'admin', this will perform a check final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password, this will perform a check final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the login button login . click (); // Press the button to initiate the login process, this will perform a check } } Warning Do not forget to call the lifecycle or let a test extension do it for you. For that, you may need to change the field driver to the respective wrapped driver. Warning Do not mix implicit and explicit checking as this will produce unexpected results. Thus be sure to remove the Recheck instance from your test code.","title":"Implicit checking"},{"location":"recheck-web/introduction/usage/#skipping-checks","text":"It is possible to skip an implicit check by using the skipCheck() method on either AutocheckingRecheckDriver or AutocheckingWebElement which will not create a Golden Master for any actions performed on the driver or element. AutocheckingRecheckDriver driver = ... WebDriver skipping = driver . skipCheck (); // This will disable checks for the returned driver skipping . get ( \"https://example.com\" ); // Go to your login page, this will not perform a check final WebElement user = driver . findElement ( By . id ( \"user\" ) ). skipCheck (); // Find the user input element, disabling checks for the returned element user . sendKeys ( \"admin\" ); // Type the user 'admin', this will not perform a check final WebElement password = skipping . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password, this will not perform a check","title":"Skipping checks"},{"location":"recheck-web/introduction/usage/#recheckdriver","text":"RecheckDriver combines all the above mentioned recheck-web features: No assertions. Unbreakable tests. Implicit checking. Use this class if you automatically want to incorporate new features without changing your existing test class. @ExtendWith ( RecheckExtension . class ) // Add the extension that will perform the lifecycle class LoginTest { WebDriver driver ; @BeforeEach void setUp () { driver = new RecheckDriver ( new ChromeDriver () ); // Wrap your driver in a RecheckDriver to enable all recheck-web features } @AfterEach void tearDown () { driver . quit (); // Close your driver after the test } @Test void login_with_invalid_credentials_should_produce_error_message_and_clear_inputs () throws Exception { driver . get ( \"https://example.com\" ); // Go to your login page final WebElement user = driver . findElement ( By . id ( \"user\" ) ); // Find the user input element user . sendKeys ( \"admin\" ); // Type the user 'admin' final WebElement password = driver . findElement ( By . id ( \"password\" ) ); // Find the password input element password . sendKeys ( \"invalid\" ); // Type an invalid password final WebElement login = driver . findElement ( By . id ( \"login\" ) ); // Find the login button login . click (); // Press the button to initiate the login process } } Warning Do not forget to call the lifecycle or let a test extension do it for you. For that, you may need to change the field driver to the respective wrapped driver. Warning Do not mix implicit and explicit checking as this will produce unexpected results. Thus be sure to remove the Recheck instance from your test code. To summarize: WebDriver Checks Recheck Ordinary driver (e.g. ChromeDriver ) Explicit RecheckImpl UnbreakableDriver Explicit RecheckWebImpl AutocheckingRecheckDriver Implicit Integrated (i.e. not needed) RecheckDriver Implicit Integrated (i.e. not needed) For further information you can check out the Javadoc of the corresponding classes and refer to our integration tests , which demonstrate the usage.","title":"RecheckDriver"},{"location":"recheck-web/setup/maven/","text":"Setting Up a Project Using Maven This tutorial assumes you have Java and Maven readily installed on your system. You can verify that by opening a terminal / CMD and running java -version mvn --version The output should contain no error and show a Java version of 8 or above. Now you can create a new folder (e.g. recheck-web-tutorial ) and a simple pom.xml file with the following content: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <groupId> com.mycompany </groupId> <artifactId> recheck-web-tutorial </artifactId> <version> 0.1-SNAPSHOT </version> <properties> <maven.compiler.source> 1.8 </maven.compiler.source> <maven.compiler.target> 1.8 </maven.compiler.target> </properties> <dependencies> <dependency> <groupId> junit </groupId> <artifactId> junit </artifactId> <version> 4.13 </version> <scope> test </scope> </dependency> <dependency> <groupId> de.retest </groupId> <artifactId> recheck-web </artifactId> <version> 1.11.0 </version> <scope> test </scope> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-java </artifactId> <version> 3.141.59 </version> <scope> test </scope> </dependency> </dependencies> </project> With this, you can now turn to your favorite IDE (e.g. mvn eclipse:eclipse ) and create your first test class. Before a Selenium test can be executed correctly, you first need to download a driver/browser executable according to your liking and operating system, e.g. Chrome . Extract the archive to your hard drive. Note that for the ChromeDriver to work, you need the major version to match your Chrome version installed on your system. Now we should be all set up to create your first test . Using recheck in connection with Spring If you plan to use Spring alongside with recheck in the same project, you should know the following: Since Java version 11 javax.xml.bind is replaced by jakarta.xml.bind . recheck already uses the newer version, meaningly jakarta.xml.bind , while Spring is still using javax.xml.bind . To avoid any errors, it is necessary to add the following dependencies to your pom.xml file. <!-- START workaround old jaxb package name --> <dependency> <!-- provide xml api with jakarta package name --> <groupId> jakarta.xml.bind </groupId> <artifactId> jakarta.xml.bind-api </artifactId> <version> [3,3.99) </version> <!--$NO-MVN-MAN-VER$ --> <!-- depends on com.sun.activation:jakarta.activation > 2.0 (package jakarta.activation) --> </dependency> <dependency> <!-- version with old package name exist, so we need to enforce a lower version bound --> <groupId> com.sun.activation </groupId> <artifactId> jakarta.activation </artifactId> <version> [2,2.99) </version> <!--$NO-MVN-MAN-VER$ --> </dependency> <dependency> <!-- provide xml api with javax package name --> <groupId> javax.xml.bind </groupId> <artifactId> jaxb-api </artifactId> <version> [2.3,2.99) </version> <!--$NO-MVN-MAN-VER$ --> <!-- depends on javax.activation:javax.activation-api (package javax.activation) --> </dependency> <!-- END workaround old jaxb package name --> <dependency> <!-- workaround for legacy mail dependency in spring-boot-starter-oauth2-client --> <!-- only needed if spring-boot-starter-oauth2-client < v2.4.12 or < v2.5.5 is used --> <groupId> com.sun.mail </groupId> <artifactId> jakarta.mail </artifactId> <version> 2.0.1 </version> <!--$NO-MVN-MAN-VER$ --> <scope> test </scope> </dependency> Furthermore, Spring defines Selenium version 3 in its POM file whereas recheck (version >= 1.13) is using Selenium version 4. The respective dependencies must therefore be overwritten in your pom.xml file by adding the following block. <dependencyManagement> <dependencies> <!-- START workaround selenium 4 --> <!-- recheck >= 1.13 uses selenium 4, spring defines selenium 3 in parent-pom, so we need to overwrite it. --> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-java </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-api </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-chrome-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v85 </artifactId> <version> 4.1.2 </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v97 </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v98 </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v99 </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-edge-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-firefox-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-ie-driver </artifactId> <version> 4.1.2 </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-opera-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-remote-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-safari-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-support </artifactId> <version> [4,4.99) </version> </dependency> <!-- END workaround selenium 4 --> </dependencies> </dependencyManagement>","title":"Setting Up a Project Using Maven"},{"location":"recheck-web/setup/maven/#setting-up-a-project-using-maven","text":"This tutorial assumes you have Java and Maven readily installed on your system. You can verify that by opening a terminal / CMD and running java -version mvn --version The output should contain no error and show a Java version of 8 or above. Now you can create a new folder (e.g. recheck-web-tutorial ) and a simple pom.xml file with the following content: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <groupId> com.mycompany </groupId> <artifactId> recheck-web-tutorial </artifactId> <version> 0.1-SNAPSHOT </version> <properties> <maven.compiler.source> 1.8 </maven.compiler.source> <maven.compiler.target> 1.8 </maven.compiler.target> </properties> <dependencies> <dependency> <groupId> junit </groupId> <artifactId> junit </artifactId> <version> 4.13 </version> <scope> test </scope> </dependency> <dependency> <groupId> de.retest </groupId> <artifactId> recheck-web </artifactId> <version> 1.11.0 </version> <scope> test </scope> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-java </artifactId> <version> 3.141.59 </version> <scope> test </scope> </dependency> </dependencies> </project> With this, you can now turn to your favorite IDE (e.g. mvn eclipse:eclipse ) and create your first test class. Before a Selenium test can be executed correctly, you first need to download a driver/browser executable according to your liking and operating system, e.g. Chrome . Extract the archive to your hard drive. Note that for the ChromeDriver to work, you need the major version to match your Chrome version installed on your system. Now we should be all set up to create your first test .","title":"Setting Up a Project Using Maven"},{"location":"recheck-web/setup/maven/#using-recheck-in-connection-with-spring","text":"If you plan to use Spring alongside with recheck in the same project, you should know the following: Since Java version 11 javax.xml.bind is replaced by jakarta.xml.bind . recheck already uses the newer version, meaningly jakarta.xml.bind , while Spring is still using javax.xml.bind . To avoid any errors, it is necessary to add the following dependencies to your pom.xml file. <!-- START workaround old jaxb package name --> <dependency> <!-- provide xml api with jakarta package name --> <groupId> jakarta.xml.bind </groupId> <artifactId> jakarta.xml.bind-api </artifactId> <version> [3,3.99) </version> <!--$NO-MVN-MAN-VER$ --> <!-- depends on com.sun.activation:jakarta.activation > 2.0 (package jakarta.activation) --> </dependency> <dependency> <!-- version with old package name exist, so we need to enforce a lower version bound --> <groupId> com.sun.activation </groupId> <artifactId> jakarta.activation </artifactId> <version> [2,2.99) </version> <!--$NO-MVN-MAN-VER$ --> </dependency> <dependency> <!-- provide xml api with javax package name --> <groupId> javax.xml.bind </groupId> <artifactId> jaxb-api </artifactId> <version> [2.3,2.99) </version> <!--$NO-MVN-MAN-VER$ --> <!-- depends on javax.activation:javax.activation-api (package javax.activation) --> </dependency> <!-- END workaround old jaxb package name --> <dependency> <!-- workaround for legacy mail dependency in spring-boot-starter-oauth2-client --> <!-- only needed if spring-boot-starter-oauth2-client < v2.4.12 or < v2.5.5 is used --> <groupId> com.sun.mail </groupId> <artifactId> jakarta.mail </artifactId> <version> 2.0.1 </version> <!--$NO-MVN-MAN-VER$ --> <scope> test </scope> </dependency> Furthermore, Spring defines Selenium version 3 in its POM file whereas recheck (version >= 1.13) is using Selenium version 4. The respective dependencies must therefore be overwritten in your pom.xml file by adding the following block. <dependencyManagement> <dependencies> <!-- START workaround selenium 4 --> <!-- recheck >= 1.13 uses selenium 4, spring defines selenium 3 in parent-pom, so we need to overwrite it. --> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-java </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-api </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-chrome-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v85 </artifactId> <version> 4.1.2 </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v97 </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v98 </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-devtools-v99 </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-edge-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-firefox-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-ie-driver </artifactId> <version> 4.1.2 </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-opera-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-remote-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-safari-driver </artifactId> <version> [4,4.99) </version> </dependency> <dependency> <groupId> org.seleniumhq.selenium </groupId> <artifactId> selenium-support </artifactId> <version> [4,4.99) </version> </dependency> <!-- END workaround selenium 4 --> </dependencies> </dependencyManagement>","title":"Using recheck in connection with Spring"},{"location":"recheck-web/tutorial/explicit-checks/","text":"Using Explicit Checks With recheck, you have multiple options of how to use it. You can use a RecheckDriver , which would make recheck completely transparent to use. For a more obvious and spelled-out usage as pure checking library, you can call the check methods explicitly. A very basic test with Selenium and explicit calls to check could look like this: package com.mycompany ; import org.junit.* ; import org.openqa.selenium.* ; import org.openqa.selenium.chrome.* ; import de.retest.recheck.* ; import de.retest.recheck.persistence.* ; public class MyFirstTest { private WebDriver driver ; private Recheck re ; @Before public void setUp () { re = new RecheckImpl (); System . setProperty ( \"webdriver.chrome.driver\" , \"C:\\\\pathto\\\\chromedriver.exe\" ); ChromeOptions options = new ChromeOptions (); options . addArguments ( \"--headless\" , \"--window-size=1280,720\" ); driver = new ChromeDriver ( options ); } @Test public void google () throws Exception { re . startTest (); driver . get ( \"http://google.com\" ); re . check ( driver , \"open\" ); re . capTest (); } @After public void tearDown () { driver . quit (); re . cap (); } } The @Before annotated method creates both the Recheck instance to use, as well as the ChromeDriver . The @Test annotated method first tells recheck to start the test (calling startTest ), then load the Google start page into Chrome. Then it will recheck the current version of the page against a previous, expected version (called Golden Master ) by invoking check and giving it a semantic and unique identifier. Tip If you only want to test specific GUI elements, you can also pass a single WebElement to the check method instead of the WebDriver to test the entire page. During a typical, more elaborate test, you would call check multiple times, each time with a unique identifier. Since differences are not that uncommon, we do not want our test to fail immediately. So the calls to the check method will gather all differences, but not immediately make the test fail. To make the test fail in case of differences, the capTest method is called at the end of the test. Should you forget to do so, then a message in the log will tell you. After the test finishes, the @After method shuts down Chrome by calling quit on the driver and makes recheck create a summary report file of all encountered changes by calling cap . When you set up Maven correctly , then you can now execute that test case locally .","title":"Using Explicit Checks"},{"location":"recheck-web/tutorial/explicit-checks/#using-explicit-checks","text":"With recheck, you have multiple options of how to use it. You can use a RecheckDriver , which would make recheck completely transparent to use. For a more obvious and spelled-out usage as pure checking library, you can call the check methods explicitly. A very basic test with Selenium and explicit calls to check could look like this: package com.mycompany ; import org.junit.* ; import org.openqa.selenium.* ; import org.openqa.selenium.chrome.* ; import de.retest.recheck.* ; import de.retest.recheck.persistence.* ; public class MyFirstTest { private WebDriver driver ; private Recheck re ; @Before public void setUp () { re = new RecheckImpl (); System . setProperty ( \"webdriver.chrome.driver\" , \"C:\\\\pathto\\\\chromedriver.exe\" ); ChromeOptions options = new ChromeOptions (); options . addArguments ( \"--headless\" , \"--window-size=1280,720\" ); driver = new ChromeDriver ( options ); } @Test public void google () throws Exception { re . startTest (); driver . get ( \"http://google.com\" ); re . check ( driver , \"open\" ); re . capTest (); } @After public void tearDown () { driver . quit (); re . cap (); } } The @Before annotated method creates both the Recheck instance to use, as well as the ChromeDriver . The @Test annotated method first tells recheck to start the test (calling startTest ), then load the Google start page into Chrome. Then it will recheck the current version of the page against a previous, expected version (called Golden Master ) by invoking check and giving it a semantic and unique identifier. Tip If you only want to test specific GUI elements, you can also pass a single WebElement to the check method instead of the WebDriver to test the entire page. During a typical, more elaborate test, you would call check multiple times, each time with a unique identifier. Since differences are not that uncommon, we do not want our test to fail immediately. So the calls to the check method will gather all differences, but not immediately make the test fail. To make the test fail in case of differences, the capTest method is called at the end of the test. Should you forget to do so, then a message in the log will tell you. After the test finishes, the @After method shuts down Chrome by calling quit on the driver and makes recheck create a summary report file of all encountered changes by calling cap . When you set up Maven correctly , then you can now execute that test case locally .","title":"Using Explicit Checks"},{"location":"recheck-web/tutorial/mvn-execute-locally/","text":"Execute the Test with Maven When you set up Maven correctly and created a test case , you should be able to execute this test with mvn test . You should see the following error message the first time you run this test: java.lang.AssertionError: 'com.mycompany.MyFirstTest': No recheck file found. First time test was run? Created recheck file now, don't forget to commit... at de.retest.recheck.RecheckImpl.capTest(RecheckImpl.java:137) at com.mycompany.MyFirstTest.google(MyFirstTest.java:30) at ... some more stack trace ... recheck works by comparing the current state of the software (i.e. the website) against a baseline called Golden Master from an earlier state of the software. If no such Golden Master can be found, recheck throws an error. This is the expected and desired behavior\u2014e.g. imagine you forget to commit your Golden Master into your version control system, or a path changes and the Golden Master cannot be found anymore. In that case you would want your test to fail\u2014not pass. The test has to fail the first time it is executed. But during that first execution, recheck created the Golden Master e.g. at src\\test\\resources\\retest\\recheck\\com.mycompany.MyFirstTest\\google.open.recheck . In that folder you can now find an XML file containing every non-default attribute of every DOM element after rendering the website, together with a screenshot of the website. Now if you run your test again, all of those elements and attributes of the Golden Master are compared against the current DOM elements. Any non-ignored difference of any element makes the test fail. Doing so (again with mvn test ) probably creates an output similar to this: java.lang.AssertionError: A detailed report will be created at 'target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report'. You can review the details by using our GUI from https://retest.de/review/. The following differences have been found in 'com.mycompany.MyFirstTest'(with 1 check(s)): Test 'google' has 37 differences in 1 states: open resulted in: A [About Google] at 'HTML[1]/BODY[1]/DIV[1]/DIV[3]/DIV[1]/DIV[1]/A[1]': ping: expected=\"some gibberish\" ... many more differences ... Of course, you wouldn't want your test to fail that way. Luckily, recheck has a very easy way to setup and use an ignore mechanism .","title":"Execute the Test with Maven"},{"location":"recheck-web/tutorial/mvn-execute-locally/#execute-the-test-with-maven","text":"When you set up Maven correctly and created a test case , you should be able to execute this test with mvn test . You should see the following error message the first time you run this test: java.lang.AssertionError: 'com.mycompany.MyFirstTest': No recheck file found. First time test was run? Created recheck file now, don't forget to commit... at de.retest.recheck.RecheckImpl.capTest(RecheckImpl.java:137) at com.mycompany.MyFirstTest.google(MyFirstTest.java:30) at ... some more stack trace ... recheck works by comparing the current state of the software (i.e. the website) against a baseline called Golden Master from an earlier state of the software. If no such Golden Master can be found, recheck throws an error. This is the expected and desired behavior\u2014e.g. imagine you forget to commit your Golden Master into your version control system, or a path changes and the Golden Master cannot be found anymore. In that case you would want your test to fail\u2014not pass. The test has to fail the first time it is executed. But during that first execution, recheck created the Golden Master e.g. at src\\test\\resources\\retest\\recheck\\com.mycompany.MyFirstTest\\google.open.recheck . In that folder you can now find an XML file containing every non-default attribute of every DOM element after rendering the website, together with a screenshot of the website. Now if you run your test again, all of those elements and attributes of the Golden Master are compared against the current DOM elements. Any non-ignored difference of any element makes the test fail. Doing so (again with mvn test ) probably creates an output similar to this: java.lang.AssertionError: A detailed report will be created at 'target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report'. You can review the details by using our GUI from https://retest.de/review/. The following differences have been found in 'com.mycompany.MyFirstTest'(with 1 check(s)): Test 'google' has 37 differences in 1 states: open resulted in: A [About Google] at 'HTML[1]/BODY[1]/DIV[1]/DIV[3]/DIV[1]/DIV[1]/A[1]': ping: expected=\"some gibberish\" ... many more differences ... Of course, you wouldn't want your test to fail that way. Luckily, recheck has a very easy way to setup and use an ignore mechanism .","title":"Execute the Test with Maven"},{"location":"recheck-web/tutorial/rule-based-ignore/","text":"Rule-Based Ignore Here we introduced you to two simple ignore mechanisms, one that ignores differences based on identifying attributes like xpath , tag , id or retestId , and another that globally ignores irrelevant attributes like jsdata and data-.* . Now we want to introduce a third mechanism that allows you to ignore differences based on rules implemented in code. As you may already have noticed, the generated .retest folder contains three files. One that is the already familiar recheck.ignore . Another one is named recheck.ignore.js , and as the name suggests, it is a JavaScript file. If you open it, you will find documentation that suggests implementing two (or only one) methods: function matches(element) {} function matches(element, diff) {} These methods will be called both from the GUI as well as from the CLI, ignoring any differences to an element for which any of the two methods returns true . Now in the example test case executed on Travis , we had our test executed in a CI environment. One of the differences that was reported was a font change between two equivalent font types . Other reported changes were minimal differences in opacity or outline . A third use case for rule-based ignore is if a href or source attribute differs due to different test systems and, thus, test URLs differ too. It is important to note that we now have all the power of a programming language to permanently ignore any change we like. An example implementation to ignore equivalent classes of fonts could look like so: var fontFamilies = [ [ \"system-ui\", \"Arial\" ], [ \"-apple-system\", \"sans-serif\" ] ]; function matches(element, diff) { if (diff.key == \"font-family\") { for (var i = 0; i < fontFamilies.length; i++) { if (contains(fontFamilies[i], diff.expected)) { return contains(fontFamilies[i], diff.actual); } } } return false; } Likewise, a simple implementation to ignore a difference in opacity that is less than, say 10, could look like so: function matches(element, diff) { if (diff.key == \"opacity\") { return (Math.abs(diff.expected - diff.actual) <= 10); } return false; } And an implementation to ignore irrelevant differences in URL can be implemented like that: var baseUrl = /http[s]?:\\/\\/[\\w.:\\d\\-]*/; function matches(element, diff) { if (diff.expected != null && diff.actual != null) { cleanExpected = diff.expected.replace(baseUrl, ''); cleanActual = diff.actual.replace(baseUrl, ''); return cleanExpected === cleanActual; } return false; } Of course, the three can easily be combined into a single script\u2014a task which we will leave as an exercise for the reader. After adjusting our recheck.ignore.js file as seen above and committing and pushing the changes to GitHub, our Travis build may has no or at least less differences. In order to make the build pass, there might be some more adjustments to do. The easiest way to get there is with review or recheck.cli .","title":"Rule-Based Ignore"},{"location":"recheck-web/tutorial/rule-based-ignore/#rule-based-ignore","text":"Here we introduced you to two simple ignore mechanisms, one that ignores differences based on identifying attributes like xpath , tag , id or retestId , and another that globally ignores irrelevant attributes like jsdata and data-.* . Now we want to introduce a third mechanism that allows you to ignore differences based on rules implemented in code. As you may already have noticed, the generated .retest folder contains three files. One that is the already familiar recheck.ignore . Another one is named recheck.ignore.js , and as the name suggests, it is a JavaScript file. If you open it, you will find documentation that suggests implementing two (or only one) methods: function matches(element) {} function matches(element, diff) {} These methods will be called both from the GUI as well as from the CLI, ignoring any differences to an element for which any of the two methods returns true . Now in the example test case executed on Travis , we had our test executed in a CI environment. One of the differences that was reported was a font change between two equivalent font types . Other reported changes were minimal differences in opacity or outline . A third use case for rule-based ignore is if a href or source attribute differs due to different test systems and, thus, test URLs differ too. It is important to note that we now have all the power of a programming language to permanently ignore any change we like. An example implementation to ignore equivalent classes of fonts could look like so: var fontFamilies = [ [ \"system-ui\", \"Arial\" ], [ \"-apple-system\", \"sans-serif\" ] ]; function matches(element, diff) { if (diff.key == \"font-family\") { for (var i = 0; i < fontFamilies.length; i++) { if (contains(fontFamilies[i], diff.expected)) { return contains(fontFamilies[i], diff.actual); } } } return false; } Likewise, a simple implementation to ignore a difference in opacity that is less than, say 10, could look like so: function matches(element, diff) { if (diff.key == \"opacity\") { return (Math.abs(diff.expected - diff.actual) <= 10); } return false; } And an implementation to ignore irrelevant differences in URL can be implemented like that: var baseUrl = /http[s]?:\\/\\/[\\w.:\\d\\-]*/; function matches(element, diff) { if (diff.expected != null && diff.actual != null) { cleanExpected = diff.expected.replace(baseUrl, ''); cleanActual = diff.actual.replace(baseUrl, ''); return cleanExpected === cleanActual; } return false; } Of course, the three can easily be combined into a single script\u2014a task which we will leave as an exercise for the reader. After adjusting our recheck.ignore.js file as seen above and committing and pushing the changes to GitHub, our Travis build may has no or at least less differences. In order to make the build pass, there might be some more adjustments to do. The easiest way to get there is with review or recheck.cli .","title":"Rule-Based Ignore"},{"location":"recheck-web/tutorial/setup-recheck.ignore/","text":"Setup the recheck.ignore recheck shows you all differences of all attributes. And it does so by comparing the attributes semantically, rather than comparing screenshots. This approach is similar to version control systems like Git . Without configuration, Git also shows you all differences, including log files, binaries and many other temporary files, which you typically don\u2019t want to version control. Luckily, Git allows to easily ignore those differences using .gitignore . recheck works in a very comparable manner. You can simply ignore all of those volatile and non-relevant differences. Conveniently, recheck created a .retest folder upon execution of the first recheck test case in the project root. In there you can find an example recheck.ignore file. To ignore all those volatile elements and make the given test pass, you simply need to edit this plain text file. Putting the following content into the file should e.g. make the example test pass: attribute=ping attribute=jsdata attribute-regex=data-.* attribute=class attribute=outline attribute=transform Note that Google is constantly changing its site, so you might need to add some more attributes. You can find these attributes in the resulting differences of the output, located at the beginning of every line, where the expected vs. actual values are. In our example output it shows the attribute ping . As you can see, this is not difficult, and even wild-card ignore of attributes (using the Java Pattern mechanism ) is possible. The default recheck.ignore file contains examples on how to e.g. ignore whole sub-trees of the DOM or certain attributes of specific elements. More information can also be found in the recheck documentation . This mechanism is very powerful and e.g. allows you to ignore the font of a text, but not the text itself. The semantic ignore mechanism is one of the core features of recheck, and we will explore it in more depth later. Depending on what you specify in the ignore file, different testing scenarios can be realized. The general mechanism of recheck allows you to perform functional testing, cross-browser and cross-device testing, as well as visual regression testing. For these testing purposes, be careful with what you ignore. For pure functional testing, many CSS attributes can easily be ignored. The next step would be to utilize the generated report file and apply actual differences to maintain the Golden Master.","title":"Setup the recheck.ignore"},{"location":"recheck-web/tutorial/setup-recheck.ignore/#setup-the-recheckignore","text":"recheck shows you all differences of all attributes. And it does so by comparing the attributes semantically, rather than comparing screenshots. This approach is similar to version control systems like Git . Without configuration, Git also shows you all differences, including log files, binaries and many other temporary files, which you typically don\u2019t want to version control. Luckily, Git allows to easily ignore those differences using .gitignore . recheck works in a very comparable manner. You can simply ignore all of those volatile and non-relevant differences. Conveniently, recheck created a .retest folder upon execution of the first recheck test case in the project root. In there you can find an example recheck.ignore file. To ignore all those volatile elements and make the given test pass, you simply need to edit this plain text file. Putting the following content into the file should e.g. make the example test pass: attribute=ping attribute=jsdata attribute-regex=data-.* attribute=class attribute=outline attribute=transform Note that Google is constantly changing its site, so you might need to add some more attributes. You can find these attributes in the resulting differences of the output, located at the beginning of every line, where the expected vs. actual values are. In our example output it shows the attribute ping . As you can see, this is not difficult, and even wild-card ignore of attributes (using the Java Pattern mechanism ) is possible. The default recheck.ignore file contains examples on how to e.g. ignore whole sub-trees of the DOM or certain attributes of specific elements. More information can also be found in the recheck documentation . This mechanism is very powerful and e.g. allows you to ignore the font of a text, but not the text itself. The semantic ignore mechanism is one of the core features of recheck, and we will explore it in more depth later. Depending on what you specify in the ignore file, different testing scenarios can be realized. The general mechanism of recheck allows you to perform functional testing, cross-browser and cross-device testing, as well as visual regression testing. For these testing purposes, be careful with what you ignore. For pure functional testing, many CSS attributes can easily be ignored. The next step would be to utilize the generated report file and apply actual differences to maintain the Golden Master.","title":"Setup the recheck.ignore"},{"location":"recheck-web/tutorial/travis-execute-ci/","text":"Execute the Test on a CI Server The simplest way to execute our existing test case in a CI/CD environment is a combination of GitHub and Travis. Follow the previous description , in order to manage your project with Git and push it to GitHub. Now we create an account with Travis at travis-ci.com . Travis is a CI/CD service provider that is free to use for open source projects. Once we log in using our existing GitHub account, we can see our GitHub repository. In order to have Travis execute our test case, we just need to add a .travis.yml text file (note the leading dot) with the following content: language : java dist : trusty addons : chrome : stable apt : packages : - chromium-chromedriver notifications : email : false cache : directories : - \"${HOME}/.m2/\" install : true before_script : # include ChromeDriver in PATH - ln --symbolic /usr/lib/chromium-browser/chromedriver \"${HOME}/bin/chromedriver\" script : mvn clean verify This file contains a simple configuration in YAML format, which tells Travis that we have a Java project that we want to build on a Ubuntu (Trusty) system. It also says that we want Chrome with ChromeDriver installed and in our path. Once we stage this file with git add .travis.yml , commit it via git commit -m \"Add .travis.yml\" and upload it to GitHub with git push , we should see our Travis build fire up. Now we need to remove the following line from our tests: System.setProperty(\"webdriver.chrome.driver\", \"chromedriver\"); As of the Travis configuration, the ChromeDriver is now on the path and thus its location does not need to be set explicitly. Once we again commit and push, the tests are now executed on the Travis. As you can see in the screenshot, the build fails because the test is now executed on a different operating system and a different device, revealing cross-device differences. Likewise, you can execute the test with a different browser, which would reveal cross-browser differences. If you are using Google in your native language and that is not English, expect many differences as Travis will compare to an English Google page. Those differences can be accepted or ignored later on. Alternatively, you can explicitly request Google in English via https://google.com/?hl=en. You can create rules to ignore these differences in a more sophisticated way .","title":"Execute the Test on a CI Server"},{"location":"recheck-web/tutorial/travis-execute-ci/#execute-the-test-on-a-ci-server","text":"The simplest way to execute our existing test case in a CI/CD environment is a combination of GitHub and Travis. Follow the previous description , in order to manage your project with Git and push it to GitHub. Now we create an account with Travis at travis-ci.com . Travis is a CI/CD service provider that is free to use for open source projects. Once we log in using our existing GitHub account, we can see our GitHub repository. In order to have Travis execute our test case, we just need to add a .travis.yml text file (note the leading dot) with the following content: language : java dist : trusty addons : chrome : stable apt : packages : - chromium-chromedriver notifications : email : false cache : directories : - \"${HOME}/.m2/\" install : true before_script : # include ChromeDriver in PATH - ln --symbolic /usr/lib/chromium-browser/chromedriver \"${HOME}/bin/chromedriver\" script : mvn clean verify This file contains a simple configuration in YAML format, which tells Travis that we have a Java project that we want to build on a Ubuntu (Trusty) system. It also says that we want Chrome with ChromeDriver installed and in our path. Once we stage this file with git add .travis.yml , commit it via git commit -m \"Add .travis.yml\" and upload it to GitHub with git push , we should see our Travis build fire up. Now we need to remove the following line from our tests: System.setProperty(\"webdriver.chrome.driver\", \"chromedriver\"); As of the Travis configuration, the ChromeDriver is now on the path and thus its location does not need to be set explicitly. Once we again commit and push, the tests are now executed on the Travis. As you can see in the screenshot, the build fails because the test is now executed on a different operating system and a different device, revealing cross-device differences. Likewise, you can execute the test with a different browser, which would reveal cross-browser differences. If you are using Google in your native language and that is not English, expect many differences as Travis will compare to an English Google page. Those differences can be accepted or ignored later on. Alternatively, you can explicitly request Google in English via https://google.com/?hl=en. You can create rules to ignore these differences in a more sophisticated way .","title":"Execute the Test on a CI Server"},{"location":"recheck-web/tutorial/upload-test-reports-to-rehub/","text":"Upload Test Reports to rehub Set Up Local Build Test reports can be easily uploaded to rehub . For this our existing test case has to be adjusted only slightly. It is possible to upload test reports when we execute the test locally or in a CI/CD environment. For the latter, you can follow this description in order to execute your test with Travis CI. Remember to set the property for the ChromeDriver executable when you want to execute the test locally (and remove it when you push). If you don't want to change this every time you execute your test locally, you can simply add the chromedriver.exe to your path . To upload reports you will need a retest account to gain access to rehub . After the initial registration, you will receive a 14-day trial. The first step is to modify the setUp() method in our existing test case to enable the upload to rehub . There are two ways to achieve this: Set the REHUB_REPORT_UPLOAD_ENABLED_PROPERTY_KEY system property (you have to do this before RecheckImpl is created) @Before void setUp () { System . setProperty ( RecheckProperties . REHUB_REPORT_UPLOAD_ENABLED_PROPERTY_KEY , \"true\" ); re = new RecheckImpl (); // ... } Set the rehub flag via RecheckOptions @Before void setUp () { RecheckOptions options = RecheckOptions . builder (). enableReportUpload (). build (); re = new RecheckImpl ( options ); // ... } If we execute the test locally and the configuration was successful, your browser will pop up and you will be prompted to login. Afterwards, you can find your test reports on rehub dashboard . Enable rehub Globally If you have multiple tests and don't want to adapt all of them to upload to rehub, it is easier to set the system property via the mechanism that triggers your tests. Suppose you use Maven and the Surefire or Failsafe plugin for test execution, you can adapt the plugin configuration as follows to enable rehub globally: <configuration> <systemPropertyVariables> <de.retest.recheck.rehub.reportUploadEnabled> true </de.retest.recheck.rehub.reportUploadEnabled> </systemPropertyVariables> </configuration> Setup Travis CI After the existing test case has been modified, we may also configure our CI/CD environment. First, set the RECHECK_API_KEY environment variable as shown in the Travis CI documentation . We need the RECHECK_API_KEY that is generated when the modified test is executed, which you should find in the log. Alternatively, you can invoke Rehub#getRecheckApiKey() locally and the print the returned string to see your personal token. Keep your RECHECK_API_KEY token secret! Anyone with access to your token can add test reports to rehub . For Travis CI, make sure the Display value in build log toggle is off. When we have completed all settings and executed the test in our CI/CD environment, we should receive the message Successfully uploaded report to rehub in the Travis CI build log. Now that the test has been executed in the CI/CD environment and the test report has been uploaded to rehub, we can maintain the report in different ways. Access Your Reports All your reports can be accessed online. Open rehub , enter your account details, and view/download your reports. Reports can be opened either with review or recheck.cli . With review, it is also possible to load reports directly from rehub .","title":"Upload Test Reports to rehub"},{"location":"recheck-web/tutorial/upload-test-reports-to-rehub/#upload-test-reports-to-rehub","text":"","title":"Upload Test Reports to rehub"},{"location":"recheck-web/tutorial/upload-test-reports-to-rehub/#set-up-local-build","text":"Test reports can be easily uploaded to rehub . For this our existing test case has to be adjusted only slightly. It is possible to upload test reports when we execute the test locally or in a CI/CD environment. For the latter, you can follow this description in order to execute your test with Travis CI. Remember to set the property for the ChromeDriver executable when you want to execute the test locally (and remove it when you push). If you don't want to change this every time you execute your test locally, you can simply add the chromedriver.exe to your path . To upload reports you will need a retest account to gain access to rehub . After the initial registration, you will receive a 14-day trial. The first step is to modify the setUp() method in our existing test case to enable the upload to rehub . There are two ways to achieve this: Set the REHUB_REPORT_UPLOAD_ENABLED_PROPERTY_KEY system property (you have to do this before RecheckImpl is created) @Before void setUp () { System . setProperty ( RecheckProperties . REHUB_REPORT_UPLOAD_ENABLED_PROPERTY_KEY , \"true\" ); re = new RecheckImpl (); // ... } Set the rehub flag via RecheckOptions @Before void setUp () { RecheckOptions options = RecheckOptions . builder (). enableReportUpload (). build (); re = new RecheckImpl ( options ); // ... } If we execute the test locally and the configuration was successful, your browser will pop up and you will be prompted to login. Afterwards, you can find your test reports on rehub dashboard .","title":"Set Up Local Build"},{"location":"recheck-web/tutorial/upload-test-reports-to-rehub/#enable-rehub-globally","text":"If you have multiple tests and don't want to adapt all of them to upload to rehub, it is easier to set the system property via the mechanism that triggers your tests. Suppose you use Maven and the Surefire or Failsafe plugin for test execution, you can adapt the plugin configuration as follows to enable rehub globally: <configuration> <systemPropertyVariables> <de.retest.recheck.rehub.reportUploadEnabled> true </de.retest.recheck.rehub.reportUploadEnabled> </systemPropertyVariables> </configuration>","title":"Enable rehub Globally"},{"location":"recheck-web/tutorial/upload-test-reports-to-rehub/#setup-travis-ci","text":"After the existing test case has been modified, we may also configure our CI/CD environment. First, set the RECHECK_API_KEY environment variable as shown in the Travis CI documentation . We need the RECHECK_API_KEY that is generated when the modified test is executed, which you should find in the log. Alternatively, you can invoke Rehub#getRecheckApiKey() locally and the print the returned string to see your personal token. Keep your RECHECK_API_KEY token secret! Anyone with access to your token can add test reports to rehub . For Travis CI, make sure the Display value in build log toggle is off. When we have completed all settings and executed the test in our CI/CD environment, we should receive the message Successfully uploaded report to rehub in the Travis CI build log. Now that the test has been executed in the CI/CD environment and the test report has been uploaded to rehub, we can maintain the report in different ways.","title":"Setup Travis CI"},{"location":"recheck-web/tutorial/upload-test-reports-to-rehub/#access-your-reports","text":"All your reports can be accessed online. Open rehub , enter your account details, and view/download your reports. Reports can be opened either with review or recheck.cli . With review, it is also possible to load reports directly from rehub .","title":"Access Your Reports"},{"location":"recheck-web/tutorial/using-git-and-github/","text":"Using Git and GitHub Let us use Git as version control system. In combination with GitHub as central repository, we can also manage versions of test cases on different machines, thus also deploying our project to the server. So, using a test case, e.g. from the tutorial , we simply open a CMD in the corresponding folder and do a git init . This initializes the Git repository. You can call git status to see which files were added or changed in that directory. We can add existing files, e.g. from the tutorial. We can simply call git add pom.xml .retest src . This will add the pom.xml file together with the .retest and src folder and all of its subfolders. It should result in an output similar to the following. The remainder of the files, we do not want in our Git repository. .classpath , .project and .settings are generated by Eclipse. The target folder contains the artifacts generated by Maven from the source code. These are all volatile and derived artifacts, for which we do not want to track changes. The chromedriver executable, that can be seen in the output in the screenshot is a binary and system dependent file. We also do not want to add it to our repository. Like we did with recheck in the last tutorial, we need to ignore irrelevant differences. Similar to recheck, you only need to edit a single file. We can create a simple text file and name it .gitignore . To that file we add the following: .classpath .project .settings/ target/ chromedriver If we call git status again, we see that only the .gitignore file itself is marked as an added file. We add it to Git using git add .gitignore and commit the initial status with git commit -m \"Initial state\" . In order to execute the test in a CI/CD environment, we need to create a GitHub account on github.com . GitHub is a code sharing service, that easily lets you collaborate on open source projects. Then we create a repository with the same name as our project and push our current status to that repository. To tell our local repository which remote repository to use, we call git remote add origin https://github.com/yourusername/newrepo.git . Then call git push -u origin master to push it to that repository.","title":"Using Git and GitHub"},{"location":"recheck-web/tutorial/using-git-and-github/#using-git-and-github","text":"Let us use Git as version control system. In combination with GitHub as central repository, we can also manage versions of test cases on different machines, thus also deploying our project to the server. So, using a test case, e.g. from the tutorial , we simply open a CMD in the corresponding folder and do a git init . This initializes the Git repository. You can call git status to see which files were added or changed in that directory. We can add existing files, e.g. from the tutorial. We can simply call git add pom.xml .retest src . This will add the pom.xml file together with the .retest and src folder and all of its subfolders. It should result in an output similar to the following. The remainder of the files, we do not want in our Git repository. .classpath , .project and .settings are generated by Eclipse. The target folder contains the artifacts generated by Maven from the source code. These are all volatile and derived artifacts, for which we do not want to track changes. The chromedriver executable, that can be seen in the output in the screenshot is a binary and system dependent file. We also do not want to add it to our repository. Like we did with recheck in the last tutorial, we need to ignore irrelevant differences. Similar to recheck, you only need to edit a single file. We can create a simple text file and name it .gitignore . To that file we add the following: .classpath .project .settings/ target/ chromedriver If we call git status again, we see that only the .gitignore file itself is marked as an added file. We add it to Git using git add .gitignore and commit the initial status with git commit -m \"Initial state\" . In order to execute the test in a CI/CD environment, we need to create a GitHub account on github.com . GitHub is a code sharing service, that easily lets you collaborate on open source projects. Then we create a repository with the same name as our project and push our current status to that repository. To tell our local repository which remote repository to use, we call git remote add origin https://github.com/yourusername/newrepo.git . Then call git push -u origin master to push it to that repository.","title":"Using Git and GitHub"},{"location":"recheck-web/usage/configuration/","text":"Configuration Additionally to the recheck configuration , you can configure some additional properties within recheck-web . RecheckWebOptions The RecheckWebOptions are an extended form of the plain RecheckOptions . Similarly, they are created using the builder pattern and should be a drop-in replacement for the RecheckOptionsBuilder . RecheckWebOptions options = RecheckWebOptions . builder () // Do your configuration here . build () Usage Same as the RecheckOptions the RecheckWebOptions can be passed to the RecheckImpl . RecheckWebOptions opts = RecheckWebOptions . builder () // Do your configuration here . build (); Recheck re = new RecheckImpl ( opts ); Note The RecheckWebOptions should always be used instead of the RecheckOptions when using recheck-web . Options Below is a list of the available options you may configure with corresponding methods on RecheckWebOptionsBuilder . Please refer to the detailed sections below. Option Default Description checkNamingStrategy CounterCheckNamingStrategy Defines the naming strategy used by the AutocheckingDriver for the naming the checks. screenshotProvider ViewportOnlyScreenshot Defines the screenshot strategy that is used by snapshotting the WebDriver . Example RecheckWebOptions . builder () . checkNamingStrategy ( new CustomAutocheckingCheckNamingStrategy () ) . screenshotProvider ( new ViewPortOnlyScreenshot () ) . namingStrategy ( new ClassAndMethodBasedShortNamingStrategy () ) . projectLayout ( new GradleProjectLayout () ) . suiteName ( \"my-custom-suite-name\" ) . enableReportUpload () . addIgnore ( \"MyCustomIgnore.filter\" ) . build (); Naming Checks Automatically When using the AutocheckingDriver , every action performed will generate a check with a provided Recheck instance. Since those checks require a name, it will be uniquely generated by the provided AutocheckingCheckNamingStrategy . Configuring Screenshots The creation of a check triggers a screenshot capturing of the WebDriver or WebElement supplied. This screenshot is only used for documentation purposes and not the comparison (e.g. pixel differences). Since screenshot are quite slow and large, they may be changed or disabled by using a provided implementation of ScreenshotProvider . There is a global system property available to configure these screenshots. However, they are overwritten by the local option defined. This allows you to e.g. globally disable screenshots during test execution for performance reasons, but enable them locally during Golden Master creation. Properties Additionally to recheck properties , recheck-web provides some more properties to configure. # Configure the strategy of how screenshots are taken. # fullPage | viewportOnly | viewportOnlyMinimal | none de.retest.recheck.web.screenshot.provider = viewportOnlyMinimal","title":"Configuration"},{"location":"recheck-web/usage/configuration/#configuration","text":"Additionally to the recheck configuration , you can configure some additional properties within recheck-web .","title":"Configuration"},{"location":"recheck-web/usage/configuration/#recheckweboptions","text":"The RecheckWebOptions are an extended form of the plain RecheckOptions . Similarly, they are created using the builder pattern and should be a drop-in replacement for the RecheckOptionsBuilder . RecheckWebOptions options = RecheckWebOptions . builder () // Do your configuration here . build ()","title":"RecheckWebOptions"},{"location":"recheck-web/usage/configuration/#usage","text":"Same as the RecheckOptions the RecheckWebOptions can be passed to the RecheckImpl . RecheckWebOptions opts = RecheckWebOptions . builder () // Do your configuration here . build (); Recheck re = new RecheckImpl ( opts ); Note The RecheckWebOptions should always be used instead of the RecheckOptions when using recheck-web .","title":"Usage"},{"location":"recheck-web/usage/configuration/#options","text":"Below is a list of the available options you may configure with corresponding methods on RecheckWebOptionsBuilder . Please refer to the detailed sections below. Option Default Description checkNamingStrategy CounterCheckNamingStrategy Defines the naming strategy used by the AutocheckingDriver for the naming the checks. screenshotProvider ViewportOnlyScreenshot Defines the screenshot strategy that is used by snapshotting the WebDriver .","title":"Options"},{"location":"recheck-web/usage/configuration/#example","text":"RecheckWebOptions . builder () . checkNamingStrategy ( new CustomAutocheckingCheckNamingStrategy () ) . screenshotProvider ( new ViewPortOnlyScreenshot () ) . namingStrategy ( new ClassAndMethodBasedShortNamingStrategy () ) . projectLayout ( new GradleProjectLayout () ) . suiteName ( \"my-custom-suite-name\" ) . enableReportUpload () . addIgnore ( \"MyCustomIgnore.filter\" ) . build ();","title":"Example"},{"location":"recheck-web/usage/configuration/#naming-checks-automatically","text":"When using the AutocheckingDriver , every action performed will generate a check with a provided Recheck instance. Since those checks require a name, it will be uniquely generated by the provided AutocheckingCheckNamingStrategy .","title":"Naming Checks Automatically"},{"location":"recheck-web/usage/configuration/#configuring-screenshots","text":"The creation of a check triggers a screenshot capturing of the WebDriver or WebElement supplied. This screenshot is only used for documentation purposes and not the comparison (e.g. pixel differences). Since screenshot are quite slow and large, they may be changed or disabled by using a provided implementation of ScreenshotProvider . There is a global system property available to configure these screenshots. However, they are overwritten by the local option defined. This allows you to e.g. globally disable screenshots during test execution for performance reasons, but enable them locally during Golden Master creation.","title":"Configuring Screenshots"},{"location":"recheck-web/usage/configuration/#properties","text":"Additionally to recheck properties , recheck-web provides some more properties to configure. # Configure the strategy of how screenshots are taken. # fullPage | viewportOnly | viewportOnlyMinimal | none de.retest.recheck.web.screenshot.provider = viewportOnlyMinimal","title":"Properties"},{"location":"recheck-web/usage/healing/","text":"Automatic Code Healing Tip Code healing is an early feature and might not work for every use case. We would love to hear feedback and suggestions from you as we further improve this feature. The main problem using Selenium is to find the elements you want to interact with. Let it be a button you can click, input field to type text in or other elements on the page. You need to find an identification attribute that finds the element you are looking for\u2014and only the specific element. If you have control over the website, this can be quite simple by specifying an id using By.id( \"your id\" ) . But in case you do not have control of the site (e.g. your id is randomly generated) this often requires either complex XPath queries or CSS selectors. As both approaches only identify the element by a single attribute, resulting tests are brittle and break easily, if the specified attribute changes. Since recheck-web builds on top of Selenium Java and implements Difference Testing , it is able to find elements based on all available attributes, thus preventing test breakage. However, accepting the breaking change still results in the test breaking, thus only postponing the test breakage. Introducing: Code healing. 1 Accepting any breaking change will now try to adjust the used identifier By.id( \"your id\" ) to the new value By.id( \"your changed id\" ) . Unbreakable Tests recheck-web implements Difference Testing where it converts the state of a website or web application into a Golden Master , capturing all HTML and CSS attributes of all elements. It therefore has much more context available than just the single identifying attribute. With this context, it can track changes and perform the following steps to achieve essentially unbreakable tests: Look in the persisted Golden Master, identify the old element and all its available attributes. Use these attributes to find the new element in the current state. Use the found element to continue with the test. Transitioning from your basic Selenium test to a truly unbreakable test is quite easy. Take a look at the below login form. < form > < div class = \"form-group\" > < label for = \"user\" > Username </ label > < input type = \"text\" class = \"form-control\" id = \"user\" placeholder = \"Username\" > </ div > < div class = \"form-group\" > < label for = \"password\" > Password </ label > < input type = \"password\" class = \"form-control\" id = \"password\" placeholder = \"Password\" > </ div > < input id = \"login\" type = \"submit\" class = \"btn btn-primary\" value = \"Login\" > </ form > We execute the following recheck-web Test with JUnit 5 twice, so that the Golden Masters are created. The first execution creates an initial Golden Master which is compared with the second execution. For a guide on how to transition from your standard Selenium Test to a recheck-web test, please refer to the documentation . @ExtendWith ( RecheckExtension . class ) public class FormTest { WebDriver driver ; @BeforeEach void setUp () { final ChromeOptions options = new ChromeOptions (); // Set headless=true to avoid minimal pixel changes or unexpected input options . setHeadless ( true ); final ChromeDriver driver = new ChromeDriver ( options ); // Set window=1280x800 to ensure repeatability driver . manage (). window (). setSize ( new Dimension ( 1280 , 800 ) ); // Wrap in a RecheckDriver to enable unbreakable and auto checking this . driver = new RecheckDriver ( driver ); } @AfterEach void tearDown () { // Close the driver after a test driver . quit (); } @Test void form_should_fill_in_user_and_password_and_redirect_to_dashboard () throws Exception { // 00 Navigate to the web application driver . get ( getClass (). getResource ( \"form.html\" ). toExternalForm () ); // 01 Find the user input by the id and type the username driver . findElement ( By . id ( \"user\" ) ). sendKeys ( \"admin\" ); // 02 Find the password input by the id and type the secret password driver . findElement ( By . id ( \"password\" ) ). sendKeys ( \"secret\" ); // 03 Find login by id and click driver . findElement ( By . id ( \"login\" ) ). submit (); } } This test will create four Golden Masters, each for the respective action: Load the web application. Type user \"admin\". Type password \"secret\". Click Login. However, we do not yet use the unbreakable feature. We just prepared the test in case any changes occur that would break a standard Selenium test. Assume that we are improving the login for the next versions of the web application. The modifications should not alter the look and the user should still see the same GUI as shown above. Thus we only change some invisible attributes\u2014do you spot them all? < form > < div class = \"form-group\" > < label for = \"username\" > Username </ label > < input type = \"text\" class = \"form-control\" id = \"username\" placeholder = \"Username\" > </ div > < div class = \"form-group\" > < label for = \"password\" > Password </ label > < input type = \"password\" class = \"form-control\" id = \"password\" placeholder = \"Password\" > </ div > < button id = \"btn-login\" type = \"submit\" class = \"btn btn-primary\" > Login </ button > </ form > Using standard Selenium, these changes would be quite critical as we changed some ids which we use in the test. This essentially breaks the test (despite the fact that the user would not notice the difference). Luckily enough, we use the unbreakable feature. Instead of throwing a NoSuchElementException , the test still passes and is able to log into the web application. It notes the following differences: Upon encountering the broken element, recheck will print a warning stating what changed and what needs to be done in order to fix it. Note that the retestId is a stable attribute, generated by recheck ; it will never change. *************** recheck warning *************** The HTML id attribute used for element identification changed from 'user' to 'username'. retest identified the element based on the persisted Golden Master. If you apply these changes to the Golden Master , your test de.retest.web.FormTest will break. Use `By.id(\"username\")` or `By.retestId(\"user\")` to update your test FormTest.java:47. 2. The output containing the difference states that the warnings have been encountered. Note the change for the second input element, representing the input user . Accepting this change will break the FormTest.java:47 , thus you should either manually perform the update or use the automatic code healing from review . Although we changed the id for the button \"Login\", it is not noted as breaking change, since this is not relevant for the first check, typing in the username. It is only note in the last step where the button is actually pressed. 4 check(s) in 'de.retest.web.FormTest' found the following difference(s): Test 'form_should_fill_in_user_and_password_and_redirect_to_dashboard' has 10 difference(s) in 4 state(s): 00 resulted in: input (user) at 'html[1]/body[1]/div[1]/div[1]/form[1]/div[1]/input[1]': id: expected=\"user\", actual=\"username\", breaks=\"FormTest.java:47\" input (login) at 'html[1]/body[1]/div[1]/div[1]/form[1]/input[1]': id: expected=\"login\", actual=\"btn-login\" 02 resulted in: input (user) at 'html[1]/body[1]/div[1]/div[1]/form[1]/div[1]/input[1]': id: expected=\"user\", actual=\"username\" input (login) at 'html[1]/body[1]/div[1]/div[1]/form[1]/input[1]': id: expected=\"login\", actual=\"btn-login\", breaks=\"FormTest.java:52\" Still, we are not truly unbreakable. Applying these changes will update the Golden Master and thus still break the test, since recheck is not able to find the old id anymore. Thus we only postponed the test breakage. We could go ahead and ignore the shown differences, making our test green again, but ultimately it would break. Code Healing Code healing is available since recheck-web 1.9.0 together with review 1.9.0 while using at least a standard license. Simply open a report that contains warnings and you will see a similar output as below. Note the selected line displays a warning icon, indicating that this is a breaking change. More information can be read at the feature article for review . After accepting all differences, the breaking changes are collected per file and each affected file is healed by searching for the appropriate line and replacing the value By.id( \"user\" ) to By.id( \"username\" ) . driver.get( getClass().getResource( \"form.html\" ).toExternalForm() ); // Find the user input by the id and type the username - driver.findElement( By.id( \"user\" ) ).sendKeys( \"admin\" ); + driver.findElement( By.id( \"username\" ) ).sendKeys( \"admin\" ); // Find the password input by the id and type the secret password driver.findElement( By.id( \"password\" ) ).sendKeys( \"secret\" ); // Find submit by tag and click - driver.findElement( By.id( \"login\" ) ).submit(); + driver.findElement( By.id( \"btn-login\" ) ).submit(); } } With this feature, you can once again focus on improving your web application, while recheck-web will keep your tests from breaking. If there are breaking changes, review will keep your tests up to date, eliminating the manual work completely. Code healing is only available through review using at least a standard license. \u21a9","title":"Automatic Code Healing"},{"location":"recheck-web/usage/healing/#automatic-code-healing","text":"Tip Code healing is an early feature and might not work for every use case. We would love to hear feedback and suggestions from you as we further improve this feature. The main problem using Selenium is to find the elements you want to interact with. Let it be a button you can click, input field to type text in or other elements on the page. You need to find an identification attribute that finds the element you are looking for\u2014and only the specific element. If you have control over the website, this can be quite simple by specifying an id using By.id( \"your id\" ) . But in case you do not have control of the site (e.g. your id is randomly generated) this often requires either complex XPath queries or CSS selectors. As both approaches only identify the element by a single attribute, resulting tests are brittle and break easily, if the specified attribute changes. Since recheck-web builds on top of Selenium Java and implements Difference Testing , it is able to find elements based on all available attributes, thus preventing test breakage. However, accepting the breaking change still results in the test breaking, thus only postponing the test breakage. Introducing: Code healing. 1 Accepting any breaking change will now try to adjust the used identifier By.id( \"your id\" ) to the new value By.id( \"your changed id\" ) .","title":"Automatic Code Healing"},{"location":"recheck-web/usage/healing/#unbreakable-tests","text":"recheck-web implements Difference Testing where it converts the state of a website or web application into a Golden Master , capturing all HTML and CSS attributes of all elements. It therefore has much more context available than just the single identifying attribute. With this context, it can track changes and perform the following steps to achieve essentially unbreakable tests: Look in the persisted Golden Master, identify the old element and all its available attributes. Use these attributes to find the new element in the current state. Use the found element to continue with the test. Transitioning from your basic Selenium test to a truly unbreakable test is quite easy. Take a look at the below login form. < form > < div class = \"form-group\" > < label for = \"user\" > Username </ label > < input type = \"text\" class = \"form-control\" id = \"user\" placeholder = \"Username\" > </ div > < div class = \"form-group\" > < label for = \"password\" > Password </ label > < input type = \"password\" class = \"form-control\" id = \"password\" placeholder = \"Password\" > </ div > < input id = \"login\" type = \"submit\" class = \"btn btn-primary\" value = \"Login\" > </ form > We execute the following recheck-web Test with JUnit 5 twice, so that the Golden Masters are created. The first execution creates an initial Golden Master which is compared with the second execution. For a guide on how to transition from your standard Selenium Test to a recheck-web test, please refer to the documentation . @ExtendWith ( RecheckExtension . class ) public class FormTest { WebDriver driver ; @BeforeEach void setUp () { final ChromeOptions options = new ChromeOptions (); // Set headless=true to avoid minimal pixel changes or unexpected input options . setHeadless ( true ); final ChromeDriver driver = new ChromeDriver ( options ); // Set window=1280x800 to ensure repeatability driver . manage (). window (). setSize ( new Dimension ( 1280 , 800 ) ); // Wrap in a RecheckDriver to enable unbreakable and auto checking this . driver = new RecheckDriver ( driver ); } @AfterEach void tearDown () { // Close the driver after a test driver . quit (); } @Test void form_should_fill_in_user_and_password_and_redirect_to_dashboard () throws Exception { // 00 Navigate to the web application driver . get ( getClass (). getResource ( \"form.html\" ). toExternalForm () ); // 01 Find the user input by the id and type the username driver . findElement ( By . id ( \"user\" ) ). sendKeys ( \"admin\" ); // 02 Find the password input by the id and type the secret password driver . findElement ( By . id ( \"password\" ) ). sendKeys ( \"secret\" ); // 03 Find login by id and click driver . findElement ( By . id ( \"login\" ) ). submit (); } } This test will create four Golden Masters, each for the respective action: Load the web application. Type user \"admin\". Type password \"secret\". Click Login. However, we do not yet use the unbreakable feature. We just prepared the test in case any changes occur that would break a standard Selenium test. Assume that we are improving the login for the next versions of the web application. The modifications should not alter the look and the user should still see the same GUI as shown above. Thus we only change some invisible attributes\u2014do you spot them all? < form > < div class = \"form-group\" > < label for = \"username\" > Username </ label > < input type = \"text\" class = \"form-control\" id = \"username\" placeholder = \"Username\" > </ div > < div class = \"form-group\" > < label for = \"password\" > Password </ label > < input type = \"password\" class = \"form-control\" id = \"password\" placeholder = \"Password\" > </ div > < button id = \"btn-login\" type = \"submit\" class = \"btn btn-primary\" > Login </ button > </ form > Using standard Selenium, these changes would be quite critical as we changed some ids which we use in the test. This essentially breaks the test (despite the fact that the user would not notice the difference). Luckily enough, we use the unbreakable feature. Instead of throwing a NoSuchElementException , the test still passes and is able to log into the web application. It notes the following differences: Upon encountering the broken element, recheck will print a warning stating what changed and what needs to be done in order to fix it. Note that the retestId is a stable attribute, generated by recheck ; it will never change. *************** recheck warning *************** The HTML id attribute used for element identification changed from 'user' to 'username'. retest identified the element based on the persisted Golden Master. If you apply these changes to the Golden Master , your test de.retest.web.FormTest will break. Use `By.id(\"username\")` or `By.retestId(\"user\")` to update your test FormTest.java:47. 2. The output containing the difference states that the warnings have been encountered. Note the change for the second input element, representing the input user . Accepting this change will break the FormTest.java:47 , thus you should either manually perform the update or use the automatic code healing from review . Although we changed the id for the button \"Login\", it is not noted as breaking change, since this is not relevant for the first check, typing in the username. It is only note in the last step where the button is actually pressed. 4 check(s) in 'de.retest.web.FormTest' found the following difference(s): Test 'form_should_fill_in_user_and_password_and_redirect_to_dashboard' has 10 difference(s) in 4 state(s): 00 resulted in: input (user) at 'html[1]/body[1]/div[1]/div[1]/form[1]/div[1]/input[1]': id: expected=\"user\", actual=\"username\", breaks=\"FormTest.java:47\" input (login) at 'html[1]/body[1]/div[1]/div[1]/form[1]/input[1]': id: expected=\"login\", actual=\"btn-login\" 02 resulted in: input (user) at 'html[1]/body[1]/div[1]/div[1]/form[1]/div[1]/input[1]': id: expected=\"user\", actual=\"username\" input (login) at 'html[1]/body[1]/div[1]/div[1]/form[1]/input[1]': id: expected=\"login\", actual=\"btn-login\", breaks=\"FormTest.java:52\" Still, we are not truly unbreakable. Applying these changes will update the Golden Master and thus still break the test, since recheck is not able to find the old id anymore. Thus we only postponed the test breakage. We could go ahead and ignore the shown differences, making our test green again, but ultimately it would break.","title":"Unbreakable Tests"},{"location":"recheck-web/usage/healing/#code-healing","text":"Code healing is available since recheck-web 1.9.0 together with review 1.9.0 while using at least a standard license. Simply open a report that contains warnings and you will see a similar output as below. Note the selected line displays a warning icon, indicating that this is a breaking change. More information can be read at the feature article for review . After accepting all differences, the breaking changes are collected per file and each affected file is healed by searching for the appropriate line and replacing the value By.id( \"user\" ) to By.id( \"username\" ) . driver.get( getClass().getResource( \"form.html\" ).toExternalForm() ); // Find the user input by the id and type the username - driver.findElement( By.id( \"user\" ) ).sendKeys( \"admin\" ); + driver.findElement( By.id( \"username\" ) ).sendKeys( \"admin\" ); // Find the password input by the id and type the secret password driver.findElement( By.id( \"password\" ) ).sendKeys( \"secret\" ); // Find submit by tag and click - driver.findElement( By.id( \"login\" ) ).submit(); + driver.findElement( By.id( \"btn-login\" ) ).submit(); } } With this feature, you can once again focus on improving your web application, while recheck-web will keep your tests from breaking. If there are breaking changes, review will keep your tests up to date, eliminating the manual work completely. Code healing is only available through review using at least a standard license. \u21a9","title":"Code Healing"},{"location":"recheck.cli/maintain-golden-master/","text":"Maintaining the Golden Master After you correctly installed and setup the recheck.cli , you can use it to apply changes and maintain the Golden Master. To easily generate changes to check for, open a browser and go to Scratchpad.io , a site that lets you edit HTML and CSS in realtime. Opening the page will forward you to a unique URL (e.g. http://scratchpad.io/recheck-45678 ). Now based on a previous test , we can replace the method name \"google\" with \"scratchpad\" and adjust the URL to load your newly created unique URL. The method body should then look similar to this: @Test public void scratchpad () throws Exception { re . startTest (); driver . get ( \"http://scratchpad.io/recheck-45678\" ); re . check ( driver , \"open\" ); re . capTest (); } You can run your test calling mvn test (assuming you correctly set up maven ). As expected, it will fail the first time since recheck cannot find a Golden Master for the test scratchpad. But it will create one under src/test/resources/... . Running this test the second time will also fail, as the site contains a volatile URL. We will later see how you can treat that in a more sophisticated way, but for now we want to use our newly installed recheck.cli. In your CMD, go to the root folder of the project. Then type recheck to see all available commands. It will output something like: C:\\Users\\retest\\Desktop\\recheck-web-tutorial>recheck Usage: recheck [--help] [--version] [COMMAND] Command-line interface for recheck. --help Display this help message. --version Display version info. Commands: account Allows to log into and out of your account and show your API key. help Displays help information about the specified command commit Accept specified differences of given test report. completion Generate and display an auto completion script. diff Compare two Golden Masters. ignore Ignore specified differences of given test report. show Display differences of given test report. version Display version info. Now we want to automatically ignore all irrelevant changes. To do that, simply type something like (using your name and setup) recheck ignore --all target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report (more on reports below). This will automatically add the following line to your recheck.ignore file: matcher: retestId=iframe-1, attribute: src This makes recheck ignore just one attribute of one element, a Twitter API-related IFrame. Re-running your test should show a successful build and a passing test. Next, let\u2019s use your regular browser to go to the URL you open in your test (e.g. http://scratchpad.io/recheck-45678) and edit the displayed content. For instance, replace <h1>Welcome to <span>scratchpad.io</span></h1><br> on the left-hand side of the website with <h1>Welcome to <span>recheck</span></h1><br> . Doing so and re-running the test should result in the following output: The following differences have been found in 'com.mycompany.MyFirstTest'(with 1 check(s)): Test 'scratchpad' has 7 differences in 1 states: open resulted in: textnode [scratchpad.io] at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[3]/DIV[23]/textnode[2]': text: expected=\"scratchpad.io\", actual=\"recheck\" DIV at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[5]/DIV[1]': left: expected=\"210.125px\", actual=\"173.75px\" right: expected=\"252.813px\", actual=\"289.188px\" style: expected=\"left: 210.125px; top: 286px; width: 6.0625px; height: 13px;\", actual=\"left: 173.75px; top: 286px; width: 6.0625px; height: 13px;\" TEXTAREA at 'HTML[1]/BODY[1]/DIV[3]/TEXTAREA[1]': left: expected=\"255.25px\", actual=\"218.875px\" right: expected=\"148.297px\", actual=\"184.672px\" style: expected=\"top: 285px; height: 13px; width: 6.0625px; left: 255.25px;\", actual=\"top: 285px; height: 13px; width: 6.0625px; left: 218.875px;\" at de.retest.recheck.RecheckImpl.capTest(RecheckImpl.java:137) Now we can see that Scratchpad is generating and adapting a style attribute. Interesting enough, since all relevant style information is rendered and thus represented by individual CSS attributes, we can just add style to the ignored attributes. Re-running the test again gives us the expected differences in text and, as a result of that change, also in left and right. Suppose this is an intended change and we want to update our Golden Master. For that, we can open a CMD in the project folder and run a command similar to this: recheck commit --all \\target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report The result of that call should be something like: Updated SUT state file C:\\Users\\retest\\Desktop\\recheck-web-tutorial\\src\\test\\resources\\retest\\recheck\\com.mycompany.MyFirstTest\\scratchpad.open.recheck If there were more than one Golden Master, all of them would be updated. If you had your Golden Master files in a version control system, they would show as changed, and you would need to also commit the changes within e.g. Git. We can rerun the test (e.g. mvn test ) and see whether our update worked\u2014now the test should check whether the site contains \u201cwelcome to recheck\u201d in order to pass. To further show the functionality of the recheck.cli, let\u2019s adapt the content of the Scratchpad again. Open your browser and change the welcome message to recheck-web. Again, re-running the test should again show the difference and produce a test report under target/test-classes/retest/recheck/ . You can use recheck.cli to display the contents of that file by running: recheck show target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report Doing so should result in an output similar to the following: Checking test report in path 'C:\\Users\\retest\\Desktop\\recheck-web-tutorial\\target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report'. Reading JS ignore rules file from C:\\Users\\retest\\Desktop\\recheck-web-tutorial\\.retest\\recheck.ignore.js. Specified JS ignore file has no 'shouldIgnoreAttributeDifference' function. Specified JS ignore file has no 'shouldIgnoreElement' function. Test 'scratchpad' has 5 differences in 1 states: open resulted in: textnode [recheck] at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[3]/DIV[23]/textnode[2]': text: expected=\"recheck\", actual=\"scratchpad.io\" DIV at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[5]/DIV[1]': left: expected=\"173.75px\", actual=\"210.125px\" right: expected=\"289.188px\", actual=\"252.813px\" TEXTAREA at 'HTML[1]/BODY[1]/DIV[3]/TEXTAREA[1]': left: expected=\"218.875px\", actual=\"255.25px\" right: expected=\"184.672px\", actual=\"148.297px\" As you can see, this command reproduces the failure message of the failing test. However, if you now update your recheck.ignore file, this command shows you whether recheck picked up the desired ignores without the need to actually re-run your test.","title":"Maintaining the Golden Master"},{"location":"recheck.cli/maintain-golden-master/#maintaining-the-golden-master","text":"After you correctly installed and setup the recheck.cli , you can use it to apply changes and maintain the Golden Master. To easily generate changes to check for, open a browser and go to Scratchpad.io , a site that lets you edit HTML and CSS in realtime. Opening the page will forward you to a unique URL (e.g. http://scratchpad.io/recheck-45678 ). Now based on a previous test , we can replace the method name \"google\" with \"scratchpad\" and adjust the URL to load your newly created unique URL. The method body should then look similar to this: @Test public void scratchpad () throws Exception { re . startTest (); driver . get ( \"http://scratchpad.io/recheck-45678\" ); re . check ( driver , \"open\" ); re . capTest (); } You can run your test calling mvn test (assuming you correctly set up maven ). As expected, it will fail the first time since recheck cannot find a Golden Master for the test scratchpad. But it will create one under src/test/resources/... . Running this test the second time will also fail, as the site contains a volatile URL. We will later see how you can treat that in a more sophisticated way, but for now we want to use our newly installed recheck.cli. In your CMD, go to the root folder of the project. Then type recheck to see all available commands. It will output something like: C:\\Users\\retest\\Desktop\\recheck-web-tutorial>recheck Usage: recheck [--help] [--version] [COMMAND] Command-line interface for recheck. --help Display this help message. --version Display version info. Commands: account Allows to log into and out of your account and show your API key. help Displays help information about the specified command commit Accept specified differences of given test report. completion Generate and display an auto completion script. diff Compare two Golden Masters. ignore Ignore specified differences of given test report. show Display differences of given test report. version Display version info. Now we want to automatically ignore all irrelevant changes. To do that, simply type something like (using your name and setup) recheck ignore --all target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report (more on reports below). This will automatically add the following line to your recheck.ignore file: matcher: retestId=iframe-1, attribute: src This makes recheck ignore just one attribute of one element, a Twitter API-related IFrame. Re-running your test should show a successful build and a passing test. Next, let\u2019s use your regular browser to go to the URL you open in your test (e.g. http://scratchpad.io/recheck-45678) and edit the displayed content. For instance, replace <h1>Welcome to <span>scratchpad.io</span></h1><br> on the left-hand side of the website with <h1>Welcome to <span>recheck</span></h1><br> . Doing so and re-running the test should result in the following output: The following differences have been found in 'com.mycompany.MyFirstTest'(with 1 check(s)): Test 'scratchpad' has 7 differences in 1 states: open resulted in: textnode [scratchpad.io] at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[3]/DIV[23]/textnode[2]': text: expected=\"scratchpad.io\", actual=\"recheck\" DIV at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[5]/DIV[1]': left: expected=\"210.125px\", actual=\"173.75px\" right: expected=\"252.813px\", actual=\"289.188px\" style: expected=\"left: 210.125px; top: 286px; width: 6.0625px; height: 13px;\", actual=\"left: 173.75px; top: 286px; width: 6.0625px; height: 13px;\" TEXTAREA at 'HTML[1]/BODY[1]/DIV[3]/TEXTAREA[1]': left: expected=\"255.25px\", actual=\"218.875px\" right: expected=\"148.297px\", actual=\"184.672px\" style: expected=\"top: 285px; height: 13px; width: 6.0625px; left: 255.25px;\", actual=\"top: 285px; height: 13px; width: 6.0625px; left: 218.875px;\" at de.retest.recheck.RecheckImpl.capTest(RecheckImpl.java:137) Now we can see that Scratchpad is generating and adapting a style attribute. Interesting enough, since all relevant style information is rendered and thus represented by individual CSS attributes, we can just add style to the ignored attributes. Re-running the test again gives us the expected differences in text and, as a result of that change, also in left and right. Suppose this is an intended change and we want to update our Golden Master. For that, we can open a CMD in the project folder and run a command similar to this: recheck commit --all \\target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report The result of that call should be something like: Updated SUT state file C:\\Users\\retest\\Desktop\\recheck-web-tutorial\\src\\test\\resources\\retest\\recheck\\com.mycompany.MyFirstTest\\scratchpad.open.recheck If there were more than one Golden Master, all of them would be updated. If you had your Golden Master files in a version control system, they would show as changed, and you would need to also commit the changes within e.g. Git. We can rerun the test (e.g. mvn test ) and see whether our update worked\u2014now the test should check whether the site contains \u201cwelcome to recheck\u201d in order to pass. To further show the functionality of the recheck.cli, let\u2019s adapt the content of the Scratchpad again. Open your browser and change the welcome message to recheck-web. Again, re-running the test should again show the difference and produce a test report under target/test-classes/retest/recheck/ . You can use recheck.cli to display the contents of that file by running: recheck show target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report Doing so should result in an output similar to the following: Checking test report in path 'C:\\Users\\retest\\Desktop\\recheck-web-tutorial\\target\\test-classes\\retest\\recheck\\com.mycompany.MyFirstTest.report'. Reading JS ignore rules file from C:\\Users\\retest\\Desktop\\recheck-web-tutorial\\.retest\\recheck.ignore.js. Specified JS ignore file has no 'shouldIgnoreAttributeDifference' function. Specified JS ignore file has no 'shouldIgnoreElement' function. Test 'scratchpad' has 5 differences in 1 states: open resulted in: textnode [recheck] at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[3]/DIV[23]/textnode[2]': text: expected=\"recheck\", actual=\"scratchpad.io\" DIV at 'HTML[1]/BODY[1]/DIV[3]/DIV[2]/DIV[1]/DIV[5]/DIV[1]': left: expected=\"173.75px\", actual=\"210.125px\" right: expected=\"289.188px\", actual=\"252.813px\" TEXTAREA at 'HTML[1]/BODY[1]/DIV[3]/TEXTAREA[1]': left: expected=\"218.875px\", actual=\"255.25px\" right: expected=\"184.672px\", actual=\"148.297px\" As you can see, this command reproduces the failure message of the failing test. However, if you now update your recheck.ignore file, this command shows you whether recheck picked up the desired ignores without the need to actually re-run your test.","title":"Maintaining the Golden Master"},{"location":"recheck.cli/setup/","text":"Setting up the CLI You can download the most recent version from the GitHub releases page . Afterwards, you have to include the CLI into your path to use it from your shell, which heavily depends on your operating system and version thereof. In any case, you can verify whether this worked correctly by typing recheck into a newly started shell. The output should show a help message like this: $ recheck Usage: recheck [--help] [--version] [COMMAND] Command-line interface for recheck. --help Display this help message. --version Display version info. Commands: account Allows to log into and out of your account and show your API key. help Displays help information about the specified command commit Accept specified differences of given test report. completion Generate and display an auto completion script. diff Compare two Golden Masters. ignore Ignore specified differences of given test report. show Display differences of given test report. version Display version info. Linux Unzip the downloaded archive to e.g. /opt/recheck.cli-1.5.0 . Then add the following snippet to your .bash_profile and/or .bashrc : export PATH=\"${PATH}:/path/to/recheck.cli/bin/\" Mac If you use Homebrew , you can simply use our tap and install the CLI from there: $ brew tap retest/tap $ brew install recheck.cli Alternatively, you can also install it manually as described in the Linux section. Windows Unzip the downloaded archive to e.g. C:\\Program Files\\recheck.cli-1.5.0 . To include the CLI into your path, you can follow this tutorial . On Windows 10, for instance, it works like this: Open settings. Enter \"env\" and select \"Edit the system environment variables.\" Click on the tab \"Advanced\" -> \"Environment Variables\" -> \"Path\" -> \"Edit\" -> \"New\". Add the path to the recheck/bin folder. If you installed it like above, that would be C:\\Program Files\\recheck.cli-1.5.0\\bin\\ . Enabling Shell Auto-Completion You can obtain an auto-completion script for Bash and ZSH via the completion command. Simply add the resulting output to your .bash_profile and/or .bashrc , for example: $ echo \"source <(recheck completion)\" >> ~/.bash_profile Please note that this requires Bash version 4+ (macOS currently comes with version 3).","title":"Setting up the CLI"},{"location":"recheck.cli/setup/#setting-up-the-cli","text":"You can download the most recent version from the GitHub releases page . Afterwards, you have to include the CLI into your path to use it from your shell, which heavily depends on your operating system and version thereof. In any case, you can verify whether this worked correctly by typing recheck into a newly started shell. The output should show a help message like this: $ recheck Usage: recheck [--help] [--version] [COMMAND] Command-line interface for recheck. --help Display this help message. --version Display version info. Commands: account Allows to log into and out of your account and show your API key. help Displays help information about the specified command commit Accept specified differences of given test report. completion Generate and display an auto completion script. diff Compare two Golden Masters. ignore Ignore specified differences of given test report. show Display differences of given test report. version Display version info.","title":"Setting up the CLI"},{"location":"recheck.cli/setup/#linux","text":"Unzip the downloaded archive to e.g. /opt/recheck.cli-1.5.0 . Then add the following snippet to your .bash_profile and/or .bashrc : export PATH=\"${PATH}:/path/to/recheck.cli/bin/\"","title":"Linux"},{"location":"recheck.cli/setup/#mac","text":"If you use Homebrew , you can simply use our tap and install the CLI from there: $ brew tap retest/tap $ brew install recheck.cli Alternatively, you can also install it manually as described in the Linux section.","title":"Mac"},{"location":"recheck.cli/setup/#windows","text":"Unzip the downloaded archive to e.g. C:\\Program Files\\recheck.cli-1.5.0 . To include the CLI into your path, you can follow this tutorial . On Windows 10, for instance, it works like this: Open settings. Enter \"env\" and select \"Edit the system environment variables.\" Click on the tab \"Advanced\" -> \"Environment Variables\" -> \"Path\" -> \"Edit\" -> \"New\". Add the path to the recheck/bin folder. If you installed it like above, that would be C:\\Program Files\\recheck.cli-1.5.0\\bin\\ .","title":"Windows"},{"location":"recheck.cli/setup/#enabling-shell-auto-completion","text":"You can obtain an auto-completion script for Bash and ZSH via the completion command. Simply add the resulting output to your .bash_profile and/or .bashrc , for example: $ echo \"source <(recheck completion)\" >> ~/.bash_profile Please note that this requires Bash version 4+ (macOS currently comes with version 3).","title":"Enabling Shell Auto-Completion"},{"location":"review/installation/","text":"Installation You can download the most recent version from our website . Afterwards, extract the archive to a place of your choice. There is no installation necessary. Open on Windows Simply open the executable review.exe application. File Association on Windows Add review to your start applications and get a local test report. Right click on it and go to Open with and search for the review.exe . Now all future test reports should be easy to open via review just by clicking on them. Open on Mac and Linux Run the executable review file and you are good to go. Login / Connect to rehub In order to use review, you are required to login with your retest account . Upon opening review you are prompted to login and your browser should open, redirecting you to rehub . Updating review To use recheck reports with review , they are required to have the same minor version (e.g. 1.6.x), otherwise review might not be able to work correctly anymore. To update review you have to download the new version and replace the folder contents.","title":"Installation"},{"location":"review/installation/#installation","text":"You can download the most recent version from our website . Afterwards, extract the archive to a place of your choice. There is no installation necessary.","title":"Installation"},{"location":"review/installation/#open-on-windows","text":"Simply open the executable review.exe application.","title":"Open on Windows"},{"location":"review/installation/#file-association-on-windows","text":"Add review to your start applications and get a local test report. Right click on it and go to Open with and search for the review.exe . Now all future test reports should be easy to open via review just by clicking on them.","title":"File Association on Windows"},{"location":"review/installation/#open-on-mac-and-linux","text":"Run the executable review file and you are good to go.","title":"Open on Mac and Linux"},{"location":"review/installation/#login-connect-to-rehub","text":"In order to use review, you are required to login with your retest account . Upon opening review you are prompted to login and your browser should open, redirecting you to rehub .","title":"Login / Connect to rehub"},{"location":"review/installation/#updating-review","text":"To use recheck reports with review , they are required to have the same minor version (e.g. 1.6.x), otherwise review might not be able to work correctly anymore. To update review you have to download the new version and replace the folder contents.","title":"Updating review"},{"location":"review/usage/healing/","text":"Automatic Code Healing Tip Code healing is an early feature and might not work for every use case. We would love to hear feedback and suggestions from you as we further improve this feature. Warning This feature is only available with the standard license. If you do not own such a license, please write an email to sales@retest.de. Using recheck-web allows tests to be almost unbreakable . With review you can make them truly unbreakable since it will try to automatically healing any accepted breaking change. Breaking changes, as indicated by recheck-web , are displayed via a warning as seen below in the selected line. When you accept breaking changes, they are saved until you press \"Apply changes\". Once you do, the breaking changes are collected per file and each affected file is healed by searching for the appropriate line and replacing the corresponding identifier. Exceptions The following conditions will not trigger code healing: Your license does not suffice. In this case you need to write an email to sales@retest.de. The breaking change has not been accepted. The breaking change has been ignored. As the value in the Golden Master has not been updated, it is not necessary to heal the identifier. The test to be healed has been removed. The line to be healed has been removed or changed. This may be caused by refactoring or manual changes affecting the identifier. The identifier is too complex to be analyzed and healed. Currently only inline identifiers are supported.","title":"Automatic Code Healing"},{"location":"review/usage/healing/#automatic-code-healing","text":"Tip Code healing is an early feature and might not work for every use case. We would love to hear feedback and suggestions from you as we further improve this feature. Warning This feature is only available with the standard license. If you do not own such a license, please write an email to sales@retest.de. Using recheck-web allows tests to be almost unbreakable . With review you can make them truly unbreakable since it will try to automatically healing any accepted breaking change. Breaking changes, as indicated by recheck-web , are displayed via a warning as seen below in the selected line. When you accept breaking changes, they are saved until you press \"Apply changes\". Once you do, the breaking changes are collected per file and each affected file is healed by searching for the appropriate line and replacing the corresponding identifier.","title":"Automatic Code Healing"},{"location":"review/usage/healing/#exceptions","text":"The following conditions will not trigger code healing: Your license does not suffice. In this case you need to write an email to sales@retest.de. The breaking change has not been accepted. The breaking change has been ignored. As the value in the Golden Master has not been updated, it is not necessary to heal the identifier. The test to be healed has been removed. The line to be healed has been removed or changed. This may be caused by refactoring or manual changes affecting the identifier. The identifier is too complex to be analyzed and healed. Currently only inline identifiers are supported.","title":"Exceptions"},{"location":"review/usage/projects/","text":"Projects A project contains the Golden Masters and filters for recheck and is identified by a .retest folder, which should be generated automatically with the first test execution: .retest/ filter/ recheck.ignore Note The Golden Master location and name is determined by the provided configuration . Discovering projects By default, review expects a report to be placed within the project directory. Simply place the report you want to open in the correct project directory (this is not possible when loading reports from rehub). If it cannot find the project and therefore the Golden Masters, it will only allow to ignore the encountered differences. In order to find a project, review automatically tries to find the project relative to the report location, traversing upwards and choosing the first project encountered. If review is unable to find a project it will be considered \"missing\" and review will fall back to the user home and use it similar to a project. Managing projects Warning This feature is only available with the standard license. If you do not own such a license, please buy one here . The project can be viewed and changed by clicking on the menu project button. A banner will appear displaying the currently active project and an optional warning or error message. By clicking on the project, you can select any recently used projects or choose a new project from your file system. Tip You can open the project chooser directly when pressing Shift and clicking on the project or using the shortcut Ctrl + Shift + P when the project banner is visible. When manually selecting a project via the project chooser, review will search for a project relative to the selected location, similar to searching a project for a report. Changing projects Warning Changing a project will discard all ignored changes made to a report. Thus it is recommended to check if the correct project has been found before viewing the report. If review automatically discovers a project, it will intelligently load the discovered project. Should loading the project result in a destructive operation (e.g. overwrite the active project), the discovered project will be set to pending. An error will be displayed and review will ask for confirmation whether to continue or to abort the loading process. If you decide to discard the change, the pending project will not be loaded. A simplified table for changing the project can be found below. Active project Pending project Action missing missing \u2014 ( no action needed ) missing present Load pending project present missing Reset active project ( confirmation needed ) present present Overwrite active project with pending project ( confirmation needed ) Selecting a recently used project from the list, the active project will be overwritten without the need to confirm the change.","title":"Projects"},{"location":"review/usage/projects/#projects","text":"A project contains the Golden Masters and filters for recheck and is identified by a .retest folder, which should be generated automatically with the first test execution: .retest/ filter/ recheck.ignore Note The Golden Master location and name is determined by the provided configuration .","title":"Projects"},{"location":"review/usage/projects/#discovering-projects","text":"By default, review expects a report to be placed within the project directory. Simply place the report you want to open in the correct project directory (this is not possible when loading reports from rehub). If it cannot find the project and therefore the Golden Masters, it will only allow to ignore the encountered differences. In order to find a project, review automatically tries to find the project relative to the report location, traversing upwards and choosing the first project encountered. If review is unable to find a project it will be considered \"missing\" and review will fall back to the user home and use it similar to a project.","title":"Discovering projects"},{"location":"review/usage/projects/#managing-projects","text":"Warning This feature is only available with the standard license. If you do not own such a license, please buy one here . The project can be viewed and changed by clicking on the menu project button. A banner will appear displaying the currently active project and an optional warning or error message. By clicking on the project, you can select any recently used projects or choose a new project from your file system. Tip You can open the project chooser directly when pressing Shift and clicking on the project or using the shortcut Ctrl + Shift + P when the project banner is visible. When manually selecting a project via the project chooser, review will search for a project relative to the selected location, similar to searching a project for a report.","title":"Managing projects"},{"location":"review/usage/projects/#changing-projects","text":"Warning Changing a project will discard all ignored changes made to a report. Thus it is recommended to check if the correct project has been found before viewing the report. If review automatically discovers a project, it will intelligently load the discovered project. Should loading the project result in a destructive operation (e.g. overwrite the active project), the discovered project will be set to pending. An error will be displayed and review will ask for confirmation whether to continue or to abort the loading process. If you decide to discard the change, the pending project will not be loaded. A simplified table for changing the project can be found below. Active project Pending project Action missing missing \u2014 ( no action needed ) missing present Load pending project present missing Reset active project ( confirmation needed ) present present Overwrite active project with pending project ( confirmation needed ) Selecting a recently used project from the list, the active project will be overwritten without the need to confirm the change.","title":"Changing projects"},{"location":"review/usage/reports/","text":"Reports Open Reports You can open reports from two perspectives: First is from the starting page with the Open... button in the middle of the page. Second is from the review reports page, which you can access over the menu or while having another report open. In the top right corner next to the head bar that shows the location of the current report is another Open... button. A window should pop up asking you to choose the report you want to open and shows the last 10 reports from rehub . If you don't see them, but can only search for local reports, the login either did not work or you got logged out. You can open the menu on the burger icon in the top left corner and click on Open Account... . If you've logged in there, reopen review and your reports should appear. You can always search for reports locally if you downloaded them by clicking on Open local file . Maintaining the Golden Master After opening a test report with an existing Golden Master you can view all differences between the actual version and the Golden Master. Yellow means there are changes you didn't accept or ignore yet and green means you did. The differences are sorted by tests in suites. Those contain every single element that changed. By clicking on the test a table appears with all the changes. If you don't have a license there will be only 3 columns: UI element / Attribute , Expected value and Actual value . When there is a 4th and 5th column to accept and ignore changes but you can't click them, the Golden Master file is missing. Both error messages should be displayed right above the table on the right side. If everything is set up correctly you can either accept/ignore all of them at once by clicking the check mark in the head row or go through them individually. You can click on the screenshots to open them in a new window and view them in a larger resolution. After you are done maintaining your Golden Master and accepted/ignored all the elements you wanted to, click on Accept Changes on the bottom. This button will only appear if you did at least one change. This will update the Golden Master and/or the recheck.ignore file automatically and there should nothing be left you have to do. 1-click Test Maintenance When accepting or ignoring differences, review will look through all checks for the same difference on the same element, cutting down the time to maintain the Golden Master significantly. This is especially helpful if you performed multiple tests on the same website (e.g. using multiple resolutions, cross-browser, \u2026) or different websites that share similar elements (e.g. header, footer, \u2026). If a difference was detected on a shared element (e.g. a login button was changed), review will accept this difference across all performed checks. Ignore Elements In the top left corner of the test report, above the navigation for the differences is a box with check marks for different type of elements. By using them you automatically ignore all elements of that type. Below that box is another check mark to filter every accepted/ignored (green) elements from the navigation tree. If you want to manage your ignores manually you can do so by configuring the retest.ignore file in your favorite text editor. Using review with free license If you did not purchase a standard or higher license yet, some functionalities are not available in the free license: You cannot accept or ignore changes directly in the GUI. The checkboxes are hidden, but if you wish to maintain your Golden Master you can still use the recheck.cli which is entirely free. You cannot open local files. The \"Open local file\"-Button will be disabled, file association and starting review over the terminal via review path/to/tests.report will not load the passed report. Logout If you want to logout from review to maybe change accounts or so, you can only do so by going to Sessions in Your account on rehub and click on Log out all sessions .","title":"Reports"},{"location":"review/usage/reports/#reports","text":"","title":"Reports"},{"location":"review/usage/reports/#open-reports","text":"You can open reports from two perspectives: First is from the starting page with the Open... button in the middle of the page. Second is from the review reports page, which you can access over the menu or while having another report open. In the top right corner next to the head bar that shows the location of the current report is another Open... button. A window should pop up asking you to choose the report you want to open and shows the last 10 reports from rehub . If you don't see them, but can only search for local reports, the login either did not work or you got logged out. You can open the menu on the burger icon in the top left corner and click on Open Account... . If you've logged in there, reopen review and your reports should appear. You can always search for reports locally if you downloaded them by clicking on Open local file .","title":"Open Reports"},{"location":"review/usage/reports/#maintaining-the-golden-master","text":"After opening a test report with an existing Golden Master you can view all differences between the actual version and the Golden Master. Yellow means there are changes you didn't accept or ignore yet and green means you did. The differences are sorted by tests in suites. Those contain every single element that changed. By clicking on the test a table appears with all the changes. If you don't have a license there will be only 3 columns: UI element / Attribute , Expected value and Actual value . When there is a 4th and 5th column to accept and ignore changes but you can't click them, the Golden Master file is missing. Both error messages should be displayed right above the table on the right side. If everything is set up correctly you can either accept/ignore all of them at once by clicking the check mark in the head row or go through them individually. You can click on the screenshots to open them in a new window and view them in a larger resolution. After you are done maintaining your Golden Master and accepted/ignored all the elements you wanted to, click on Accept Changes on the bottom. This button will only appear if you did at least one change. This will update the Golden Master and/or the recheck.ignore file automatically and there should nothing be left you have to do.","title":"Maintaining the Golden Master"},{"location":"review/usage/reports/#1-click-test-maintenance","text":"When accepting or ignoring differences, review will look through all checks for the same difference on the same element, cutting down the time to maintain the Golden Master significantly. This is especially helpful if you performed multiple tests on the same website (e.g. using multiple resolutions, cross-browser, \u2026) or different websites that share similar elements (e.g. header, footer, \u2026). If a difference was detected on a shared element (e.g. a login button was changed), review will accept this difference across all performed checks.","title":"1-click Test Maintenance"},{"location":"review/usage/reports/#ignore-elements","text":"In the top left corner of the test report, above the navigation for the differences is a box with check marks for different type of elements. By using them you automatically ignore all elements of that type. Below that box is another check mark to filter every accepted/ignored (green) elements from the navigation tree. If you want to manage your ignores manually you can do so by configuring the retest.ignore file in your favorite text editor.","title":"Ignore Elements"},{"location":"review/usage/reports/#using-review-with-free-license","text":"If you did not purchase a standard or higher license yet, some functionalities are not available in the free license: You cannot accept or ignore changes directly in the GUI. The checkboxes are hidden, but if you wish to maintain your Golden Master you can still use the recheck.cli which is entirely free. You cannot open local files. The \"Open local file\"-Button will be disabled, file association and starting review over the terminal via review path/to/tests.report will not load the passed report.","title":"Using review with free license"},{"location":"review/usage/reports/#logout","text":"If you want to logout from review to maybe change accounts or so, you can only do so by going to Sessions in Your account on rehub and click on Log out all sessions .","title":"Logout"}]}